<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>所有人工智能新闻</title>
    <link>https://allainews.com/</link>
    <description>allainews.com 将所有有关人工智能、机器学习、深度学习、计算机视觉、NLP、数据科学和大数据的热门新闻、播客以及更多内容聚合到一处。</description>
    <lastBuildDate>Tue, 27 Feb 2024 06:21:49 GMT</lastBuildDate>
    <item>
      <title>适应教育的大型语言模型：基础能力、潜力和挑战</title>
      <link>https://allainews.com/item/adapting-large-language-models-for-education-foundational-capabilities-potentials-and-challenges-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.08664v2 公告类型：replace-cross
摘要： 在线教育平台利用互联网分发教育资源，力求提供便捷的教育，但往往无法与学生进行实时交流。他们 …]]></description>
      <guid>https://allainews.com/item/adapting-large-language-models-for-education-foundational-capabilities-potentials-and-challenges-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:13 GMT</pubDate>
    </item>
    <item>
      <title>实现 SKILL 代码自动完成的机器学习方法</title>
      <link>https://allainews.com/item/a-machine-learning-approach-towards-skill-code-autocompletion-2024-02-27/</link>
      <description><![CDATA[arXiv:2312.01921v2 公告类型：replace-cross
摘要：随着摩尔定律不断增加电子系统的复杂性，电子设计自动化（EDA）必须不断进步才能满足全球需求。 EDA 技术的一个重要例子是……]]></description>
      <guid>https://allainews.com/item/a-machine-learning-approach-towards-skill-code-autocompletion-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:13 GMT</pubDate>
    </item>
    <item>
      <title>思考、行动和提问：开放世界交互式个性化机器人导航</title>
      <link>https://allainews.com/item/think-act-and-ask-open-world-interactive-personalized-robot-navigation-2024-02-27/</link>
      <description><![CDATA[arXiv:2310.07968v2 公告类型：replace-cross
摘要：零样本对象导航（ZSON）使智能体能够在未知环境中导航到开放词汇对象。 ZSON现有的工作主要集中在以下个人指导上……]]></description>
      <guid>https://allainews.com/item/think-act-and-ask-open-world-interactive-personalized-robot-navigation-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:12 GMT</pubDate>
    </item>
    <item>
      <title>整合大型语言模型和主动推理来理解阅读和阅读障碍中的眼球运动</title>
      <link>https://allainews.com/item/integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia-2024-02-27/</link>
      <description><![CDATA[arXiv:2308.04941v2 公告类型：replace-cross
摘要：我们提出了一种新颖的计算模型，采用分层主动推理来模拟阅读和眼球运动。该模型将语言处理描述为对层次弧的推理……]]></description>
      <guid>https://allainews.com/item/integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:11 GMT</pubDate>
    </item>
    <item>
      <title>Airavata：介绍印地语教学调整的法学硕士</title>
      <link>https://allainews.com/item/airavata-introducing-hindi-instruction-tuned-llm-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.15006v2 公告类型：替换
摘要：我们宣布首次发布“Airavata”，这是一种经过指令调整的印地语法学硕士。 Airavata 是通过使用各种指令调整印地语数据集对 OpenHathi 进行微调而创建的，以使其更好......]]></description>
      <guid>https://allainews.com/item/airavata-introducing-hindi-instruction-tuned-llm-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:10 GMT</pubDate>
    </item>
    <item>
      <title>代码提示激发文本+代码法学硕士的条件推理能力</title>
      <link>https://allainews.com/item/code-prompting-elicits-conditional-reasoning-abilities-in-textcode-llms-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.10065v2 公告类型：替换
摘要：推理是语言理解的基本组成部分。最近的提示技术，例如思维链，不断提高了法学硕士在各种推理任务上的表现。绝不 …]]></description>
      <guid>https://allainews.com/item/code-prompting-elicits-conditional-reasoning-abilities-in-textcode-llms-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:09 GMT</pubDate>
    </item>
    <item>
      <title>INACIA：在巴西审计法庭中集成大型语言模型：机遇与挑战</title>
      <link>https://allainews.com/item/inacia-integrating-large-language-models-in-brazilian-audit-courts-opportunities-and-challenges-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.05273v3 公告类型：替换
摘要：本文介绍了 INACIA (Instru\c{c}\~ao Assistida com Intelig\^encia Artificial)，这是一个突破性的系统，旨在将大型语言模型 (LLM) 集成到……的操作框架中。]]></description>
      <guid>https://allainews.com/item/inacia-integrating-large-language-models-in-brazilian-audit-courts-opportunities-and-challenges-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:08 GMT</pubDate>
    </item>
    <item>
      <title>LAMPAT：使用对抗性训练进行多语言释义的低阶适应</title>
      <link>https://allainews.com/item/lampat-low-rank-adaption-for-multilingual-paraphrasing-using-adversarial-training-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.04348v2 公告类型：替换
摘要：释义是使用不同的单词或句子结构传达相同含义的文本。它可以用作许多自然语言处理任务的自动数据增强工具……]]></description>
      <guid>https://allainews.com/item/lampat-low-rank-adaption-for-multilingual-paraphrasing-using-adversarial-training-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:08 GMT</pubDate>
    </item>
    <item>
      <title>PIXAR：像素空间中的自回归语言建模</title>
      <link>https://allainews.com/item/pixar-auto-regressive-language-modeling-in-pixel-space-2024-02-27/</link>
      <description><![CDATA[arXiv:2401.03321v2 公告类型：替换
摘要：最近的工作表明了构建直接对像素表示进行操作的开放词汇大语言模型（LLM）的可能性。这些模型被实现为自动编码器，可以重构……]]></description>
      <guid>https://allainews.com/item/pixar-auto-regressive-language-modeling-in-pixel-space-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:07 GMT</pubDate>
    </item>
    <item>
      <title>混合蒸馏有助于更小的语言模型更好的推理</title>
      <link>https://allainews.com/item/mixed-distillation-helps-smaller-language-model-better-reasoning-2024-02-27/</link>
      <description><![CDATA[arXiv:2312.10730v2 公告类型：替换
摘要：虽然大型语言模型（LLM）在最近的自然语言处理（NLP）任务中表现出了卓越的性能，但由于高计算量，它们的部署带来了巨大的挑战……]]></description>
      <guid>https://allainews.com/item/mixed-distillation-helps-smaller-language-model-better-reasoning-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:06 GMT</pubDate>
    </item>
    <item>
      <title>Ge'ez Language 的机器翻译</title>
      <link>https://allainews.com/item/machine-translation-for-geez-language-2024-02-27/</link>
      <description><![CDATA[arXiv:2311.14530v2 公告类型：替换
摘要：针对诸如 Ge&#39;ez 等低资源语言的机器翻译（MT），一种不再是任何社区的母语的古老语言，面临着词汇表外的单词、doma 等挑战。]]></description>
      <guid>https://allainews.com/item/machine-translation-for-geez-language-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:05 GMT</pubDate>
    </item>
    <item>
      <title>“我们要求正义！”：走向政治文本的社会背景</title>
      <link>https://allainews.com/item/we-demand-justice-towards-social-context-grounding-of-political-texts-2024-02-27/</link>
      <description><![CDATA[arXiv:2311.09106v2 公告类型：替换
摘要：社交媒体话语经常由“政治光谱对立双方使用的看似相似的语言”组成，通常会转化为截然不同的观点。例如，“想法……”]]></description>
      <guid>https://allainews.com/item/we-demand-justice-towards-social-context-grounding-of-political-texts-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:05 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 对基于描述逻辑的上下文进行推理</title>
      <link>https://allainews.com/item/reasoning-over-description-logic-based-contexts-with-transformers-2024-02-27/</link>
      <description><![CDATA[arXiv:2311.08941v2 公告类型：替换
摘要：当前最先进的衡量基于 Transformer 的模型推理能力的一种方法是评估下游任务的准确性，例如逻辑问题回答或证明生成......]]></description>
      <guid>https://allainews.com/item/reasoning-over-description-logic-based-contexts-with-transformers-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:04 GMT</pubDate>
    </item>
    <item>
      <title>使用基础模型进行无需调整的对象命名</title>
      <link>https://allainews.com/item/tuning-less-object-naming-with-a-foundation-model-2024-02-27/</link>
      <description><![CDATA[arXiv:2311.04924v2 公告类型：替换
摘要：我们实现了一个实时对象命名系统，可以学习一组从未见过的命名实体。我们的方法采用了现有的基础模型，我们认为该模型已经准备好在……之前看到任何东西。]]></description>
      <guid>https://allainews.com/item/tuning-less-object-naming-with-a-foundation-model-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:03 GMT</pubDate>
    </item>
    <item>
      <title>人们做出更好的编辑：衡量法学硕士生成的反事实增强数据对有害语言检测的功效</title>
      <link>https://allainews.com/item/people-make-better-edits-measuring-the-efficacy-of-llm-generated-counterfactually-augmented-data-for-harmful-language-detection-2024-02-27/</link>
      <description><![CDATA[arXiv:2311.01270v3 公告类型：替换
摘要：NLP 模型用于各种关键的社会计算任务，例如检测性别歧视、种族主义或其他仇恨内容。因此，这些模型必须足够强大才能刺激……]]></description>
      <guid>https://allainews.com/item/people-make-better-edits-measuring-the-efficacy-of-llm-generated-counterfactually-augmented-data-for-harmful-language-detection-2024-02-27/</guid>
      <pubDate>Tue, 27 Feb 2024 05:51:03 GMT</pubDate>
    </item>
    </channel>
</rss>