<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>所有人工智能新闻</title>
    <link>https://allainews.com/</link>
    <description>allainews.com 将所有有关人工智能、机器学习、深度学习、计算机视觉、NLP、数据科学和大数据的热门新闻、播客以及更多内容聚合到一处。</description>
    <lastBuildDate>Wed, 28 Feb 2024 06:23:06 GMT</lastBuildDate>
    <item>
      <title>EvalLM：大型语言模型的交互式评估提示用户定义的标准</title>
      <link>https://allainews.com/item/evallm-interactive-evaluation-of-large-language-model-prompts-on-user-defined-criteria-2024-02-28/</link>
      <description><![CDATA[arXiv:2309.13633v2 公告类型：replace-cross
摘要：通过简单地编写提示，开发人员可以使用大型语言模型（LLM）构建新颖的生成应用程序原型。然而，要将原型细化为产品，开发人员必须迭代……]]></description>
      <guid>https://allainews.com/item/evallm-interactive-evaluation-of-large-language-model-prompts-on-user-defined-criteria-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:59 GMT</pubDate>
    </item>
    <item>
      <title>生成查询和文档扩展何时失败？跨方法、检索器和数据集的综合研究</title>
      <link>https://allainews.com/item/when-do-generative-query-and-document-expansions-fail-a-comprehensive-study-across-methods-retrievers-and-datasets-2024-02-28/</link>
      <description><![CDATA[arXiv:2309.08541v2 公告类型：replace-cross
摘要：使用大型语言模型（LM）进行查询或文档扩展可以提高信息检索的泛化能力。然而，尚不清楚这些技术是否普遍有益……]]></description>
      <guid>https://allainews.com/item/when-do-generative-query-and-document-expansions-fail-a-comprehensive-study-across-methods-retrievers-and-datasets-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:59 GMT</pubDate>
    </item>
    <item>
      <title>NevIR：神经信息检索中的否定</title>
      <link>https://allainews.com/item/nevir-negation-in-neural-information-retrieval-2024-02-28/</link>
      <description><![CDATA[arXiv:2305.07614v2 公告类型：replace-cross
摘要：否定是一种常见的日常现象，并且一直是语言模型（LM）的弱点。尽管信息检索 (IR) 社区已采用 LM 作为骨干……]]></description>
      <guid>https://allainews.com/item/nevir-negation-in-neural-information-retrieval-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:58 GMT</pubDate>
    </item>
    <item>
      <title>看起来正确有时就是正确的：研究纯解码器 LLM 的序列标记能力</title>
      <link>https://allainews.com/item/looking-right-is-sometimes-right-investigating-the-capabilities-of-decoder-only-llms-for-sequence-labeling-2024-02-28/</link>
      <description><![CDATA[arXiv:2401.14556v2 公告类型：替换
摘要：基于掩码语言建模（MLM）的预训练语言模型在自然语言理解（NLU）任务中表现出色。虽然经过微调的基于 MLM 的编码器始终优于因果语言……]]></description>
      <guid>https://allainews.com/item/looking-right-is-sometimes-right-investigating-the-capabilities-of-decoder-only-llms-for-sequence-labeling-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:57 GMT</pubDate>
    </item>
    <item>
      <title>足够公平：我们如何为大型语言模型训练开发和评估符合公平标准的数据集？</title>
      <link>https://allainews.com/item/fair-enough-how-can-we-develop-and-assess-a-fair-compliant-dataset-for-large-language-models-training-2024-02-28/</link>
      <description><![CDATA[arXiv:2401.11033v3 公告类型：替换
摘要：大型语言模型（LLM）的快速发展强调了人工智能开发中道德考虑和数据完整性的至关重要性，强调了 FAIR（Findable、Access…]]></description>
      <guid>https://allainews.com/item/fair-enough-how-can-we-develop-and-assess-a-fair-compliant-dataset-for-large-language-models-training-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:56 GMT</pubDate>
    </item>
    <item>
      <title>人们在哪里在线讲故事？在线社区中的故事检测</title>
      <link>https://allainews.com/item/where-do-people-tell-stories-online-story-detection-across-online-communities-2024-02-28/</link>
      <description><![CDATA[arXiv:2311.09675v2 公告类型：替换
摘要：在线社区中的故事检测是一项具有挑战性的任务，因为故事分散在社区中，并与单个文本中的非讲故事的跨度交织在一起。我们通过……来应对这一挑战]]></description>
      <guid>https://allainews.com/item/where-do-people-tell-stories-online-story-detection-across-online-communities-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:55 GMT</pubDate>
    </item>
    <item>
      <title>用于知识库问答的小样本迁移学习：将监督模型与上下文学习融合</title>
      <link>https://allainews.com/item/few-shot-transfer-learning-for-knowledge-base-question-answering-fusing-supervised-models-with-in-context-learning-2024-02-28/</link>
      <description><![CDATA[arXiv:2311.08894v2 公告类型：替换
摘要：现有的知识库问答（KBQA）架构需要带注释的数据，这使得它们的部署成本高昂且耗时。我们介绍一下少投转租的问题……]]></description>
      <guid>https://allainews.com/item/few-shot-transfer-learning-for-knowledge-base-question-answering-fusing-supervised-models-with-in-context-learning-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:54 GMT</pubDate>
    </item>
    <item>
      <title>小语言模型经过微调以协调较大的语言模型，提高复杂推理能力</title>
      <link>https://allainews.com/item/small-language-models-fine-tuned-to-coordinate-larger-language-models-improve-complex-reasoning-2024-02-28/</link>
      <description><![CDATA[arXiv:2310.18338v2 公告类型：替换
摘要：促使生成思维链（CoT）的大型语言模型（LLM）表现出令人印象深刻的推理能力。最近尝试快速分解以解决复杂的、多步骤的原因……]]></description>
      <guid>https://allainews.com/item/small-language-models-fine-tuned-to-coordinate-larger-language-models-improve-complex-reasoning-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:54 GMT</pubDate>
    </item>
    <item>
      <title>将大型语言模型与进化算法连接起来可以产生强大的提示优化器</title>
      <link>https://allainews.com/item/connecting-large-language-models-with-evolutionary-algorithms-yields-powerful-prompt-optimizers-2024-02-28/</link>
      <description><![CDATA[arXiv:2309.08532v2 公告类型：替换
摘要：大型语言模型 (LLM) 在各种任务中表现出色，但它们依赖于精心设计的提示，而这些提示通常需要大量的人力。为了自动化这个过程，在本文中，我们提出了一种新的……]]></description>
      <guid>https://allainews.com/item/connecting-large-language-models-with-evolutionary-algorithms-yields-powerful-prompt-optimizers-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:53 GMT</pubDate>
    </item>
    <item>
      <title>人类对齐的偏好排名优化</title>
      <link>https://allainews.com/item/preference-ranking-optimization-for-human-alignment-2024-02-28/</link>
      <description><![CDATA[arXiv:2306.17492v2 公告类型：替换
摘要：大型语言模型（LLM）通常包含误导性内容，强调需要使其与人类价值观保持一致，以确保人工智能系统的安全。来自人类反馈的强化学习 (RLHF) ha …]]></description>
      <guid>https://allainews.com/item/preference-ranking-optimization-for-human-alignment-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:52 GMT</pubDate>
    </item>
    <item>
      <title>DecodingTrust：GPT 模型可信度的综合评估</title>
      <link>https://allainews.com/item/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models-2024-02-28/</link>
      <description><![CDATA[arXiv:2306.11698v5 公告类型：替换
摘要：生成式预训练 Transformer（GPT）模型在其能力方面表现出了令人兴奋的进步，引起了从业者和公众的兴趣。然而，虽然有关……的文献]]></description>
      <guid>https://allainews.com/item/decodingtrust-a-comprehensive-assessment-of-trustworthiness-in-gpt-models-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:52 GMT</pubDate>
    </item>
    <item>
      <title>自适应变色龙或顽固树懒：揭示大型语言模型在知识冲突中的行为</title>
      <link>https://allainews.com/item/adaptive-chameleon-or-stubborn-sloth-revealing-the-behavior-of-large-language-models-in-knowledge-conflicts-2024-02-28/</link>
      <description><![CDATA[arXiv:2305.13300v4 公告类型：替换
摘要：通过向大型语言模型 (LLM) 提供外部信息，工具增强（包括检索增强）已成为解决 LLM 的局限性的有前景的解决方案……]]></description>
      <guid>https://allainews.com/item/adaptive-chameleon-or-stubborn-sloth-revealing-the-behavior-of-large-language-models-in-knowledge-conflicts-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:51 GMT</pubDate>
    </item>
    <item>
      <title>“根据……”：提示语言模型改进对预训练数据的引用</title>
      <link>https://allainews.com/item/according-to-prompting-language-models-improves-quoting-from-pre-training-data-2024-02-28/</link>
      <description><![CDATA[arXiv:2305.13252v2 公告类型：替换
摘要：尽管对事实数据进行了预训练，大型语言模型（LLM）可能会产生幻觉并生成虚假信息。受到“根据消息来源”的新闻手段的启发，我们建议根据……]]></description>
      <guid>https://allainews.com/item/according-to-prompting-language-models-improves-quoting-from-pre-training-data-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:50 GMT</pubDate>
    </item>
    <item>
      <title>一种极其简单的神经文本生成解码方法</title>
      <link>https://allainews.com/item/a-frustratingly-simple-decoding-method-for-neural-text-generation-2024-02-28/</link>
      <description><![CDATA[arXiv:2305.12675v2 公告类型：替换
摘要：我们引入了一种用于神经文本生成的极其简单、超级高效且令人惊讶的有效解码方法，我们称之为令人沮丧的简单解码（FSD）。 FSD 背后的想法是……]]></description>
      <guid>https://allainews.com/item/a-frustratingly-simple-decoding-method-for-neural-text-generation-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:50 GMT</pubDate>
    </item>
    <item>
      <title>用于逻辑推理的基于抽象意义表示的逻辑驱动数据增强</title>
      <link>https://allainews.com/item/abstract-meaning-representation-based-logic-driven-data-augmentation-for-logical-reasoning-2024-02-28/</link>
      <description><![CDATA[arXiv:2305.12599v3 公告类型：替换
摘要：将大型语言模型与逻辑推理相结合可以增强其以稳健可靠的方式解决问题的能力。然而，逻辑推理的复杂性带来了问题……]]></description>
      <guid>https://allainews.com/item/abstract-meaning-representation-based-logic-driven-data-augmentation-for-logical-reasoning-2024-02-28/</guid>
      <pubDate>Wed, 28 Feb 2024 05:49:49 GMT</pubDate>
    </item>
    </channel>
</rss>