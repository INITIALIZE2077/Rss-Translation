<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 06 Jan 2024 03:19:14 GMT</lastBuildDate>
    <item>
      <title>TTS HD 与 TTS 有什么区别？</title>
      <link>https://community.openai.com/t/what-is-difference-between-tts-hd-vs-tts/578537#post_4</link>
      <description><![CDATA[同意@_j
文档状态：
&lt;块引用&gt;
对于实时应用程序，标准 tts-1 模型可提供最低的延迟，但质量低于 tts-1-hd 模型。由于音频的生成方式，tts-1 在某些情况下可能会生成比 tts-1-hd 更静态的内容。在某些情况下，音频可能没有明显差异，具体取决于您的收听设备和个人。
]]></description>
      <guid>https://community.openai.com/t/what-is-difference-between-tts-hd-vs-tts/578537#post_4</guid>
      <pubDate>Sat, 06 Jan 2024 03:17:18 GMT</pubDate>
    </item>
    <item>
      <title>您对 GPT 商店有何期望？</title>
      <link>https://community.openai.com/t/what-are-your-hopes-for-the-gpt-store/549534?page=2#post_22</link>
      <description><![CDATA[


某人Sysop：
&lt;块引用&gt;
但是，代币不是仍然是 GPT 存储的一部分吗？


不，对于 GPT 的用户或构建者来说，这并不重要。



某人Sysop：
&lt;块引用&gt;
如果是这样，它怎么可能是免费的？谁将为每个查询使用的代币付费？


ChatGPT Plus 订阅者每月支付 20 美元，就像他们为与 ChatGPT 中的基本 GPT-4 模型交互时使用的代币付费一样。]]></description>
      <guid>https://community.openai.com/t/what-are-your-hopes-for-the-gpt-store/549534?page=2#post_22</guid>
      <pubDate>Sat, 06 Jan 2024 03:13:24 GMT</pubDate>
    </item>
    <item>
      <title>您对 GPT 商店有何期望？</title>
      <link>https://community.openai.com/t/what-are-your-hopes-for-the-gpt-store/549534#post_21</link>
      <description><![CDATA[但是，代币不是仍然是 GPT 存储的一部分吗？如果是这样，它怎么可能是免费的？谁将为每个查询使用的代币付费？而且，如果人们知道它是免费的，那不是会导致大量代币被消耗吗？]]></description>
      <guid>https://community.openai.com/t/what-are-your-hopes-for-the-gpt-store/549534#post_21</guid>
      <pubDate>Sat, 06 Jan 2024 03:06:09 GMT</pubDate>
    </item>
    <item>
      <title>开发LLM应用程序的最大困难</title>
      <link>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_68</link>
      <description><![CDATA[


史蒂文尼克：
&lt;块引用&gt;
我有一个测试语料库，我称之为 Bowl Season，目前包含 42 个文档（周一后为 43 个），每个文档对应每场大学橄榄球比赛。我可以要求该语料库“告诉我每场比赛的得分以及每场比赛中接球码数最多的球员”。使用我的系统，我可以使用 8k 上下文窗口让 GPT-3.5 或 4 准确回答该问题。借助传统的 RAG 和 128k 上下文窗口，即使是 GPT 4 也会陷入困境。


对于这项特定的工作来说，这听起来像是错误的工具。
这看起来应该是一些相当结构化的数据，可以使用更传统的方式进行解析和查询。]]></description>
      <guid>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_68</guid>
      <pubDate>Sat, 06 Jan 2024 03:02:59 GMT</pubDate>
    </item>
    <item>
      <title>新的 gpt-3.5-turbo-1106 (API) 太可怕了</title>
      <link>https://community.openai.com/t/new-gpt-3-5-turbo-1106-api-is-horrific/496732#post_17</link>
      <description><![CDATA[与 0613 相比，我还发现此 API 版本的函数调用响应有所下降。4 更好，但速度更慢且更昂贵。为什么 gpt-3.5-turbo-1106 与 3.5 0613 和 gpt-4-1106-preview 如此不同？]]></description>
      <guid>https://community.openai.com/t/new-gpt-3-5-turbo-1106-api-is-horrific/496732#post_17</guid>
      <pubDate>Sat, 06 Jan 2024 02:59:58 GMT</pubDate>
    </item>
    <item>
      <title>我对 OpenAI 会议纪要教程的看法</title>
      <link>https://community.openai.com/t/my-take-on-the-openai-meeting-minutes-tutorial/546427#post_6</link>
      <description><![CDATA[@alexrosen，如果没有 10K 字符指令，我看不出有多大区别。我记得在 OpenAI 文档中的某个地方读过，搜索在 10K 字符或更少的情况下效果更好，但我现在找不到参考。我实际上以为在发布代码之前我已经删除了它 - 我不再包含它。
您可能也对这篇文章感兴趣：通过 API 搜索大型文本文件的技巧？]]></description>
      <guid>https://community.openai.com/t/my-take-on-the-openai-meeting-minutes-tutorial/546427#post_6</guid>
      <pubDate>Sat, 06 Jan 2024 02:57:37 GMT</pubDate>
    </item>
    <item>
      <title>我对 OpenAI 会议纪要教程的看法</title>
      <link>https://community.openai.com/t/my-take-on-the-openai-meeting-minutes-tutorial/546427#post_5</link>
      <description><![CDATA[@benasterisk，是的，这就是我的看法 - OpenAI 教程代码没有除非您还实现了分割文件功能，否则不能使用他们提供的 EarningsCall.wav 演示文件。这里提到了 pydub 分割功能，教程至少应该指出： https://platform.openai.com/docs/guides/speech-to-text/longer-inputs]]></description>
      <guid>https://community.openai.com/t/my-take-on-the-openai-meeting-minutes-tutorial/546427#post_5</guid>
      <pubDate>Sat, 06 Jan 2024 02:53:05 GMT</pubDate>
    </item>
    <item>
      <title>当文档数量增加时，RAG 会失败</title>
      <link>https://community.openai.com/t/rag-is-failing-when-the-number-of-documents-increase/578498#post_5</link>
      <description><![CDATA[


 Joyasree78：
&lt;块引用&gt;
当我们的文档数量较少时，嵌入会根据阈值获取 n 个文档，然后我们从其中取出前 n 个文档，这些文档具有问题的潜在答案。当文档数量增加时，包含答案的块会被下推到 n-k 位置，当我们获取前 n 个块时，该块将被排除。我可以增加 top-n，但这不是一个可持续的解决方案，它会在其他地方失败。


在处理非常大的知识库数据集时，我面临着同样的挑战。与您类似，我有时最终得到的是一个很好的答案，但不是最全面的答案。如前所述，您可能想要查看的第一件事是您的嵌入策略。
我总是使用语义分块来确保每个块尽可能与其上下文相关：https://youtu .be/w_veb816Asg
接下来，我尽可能使用元数据来识别每个嵌入块在整个文档中所属的位置：

我有一个名为“问题”的对象属性，这是该特定块回答的问题。事实证明，这有助于显着提高 SNR（信噪比）。
对于嵌入本身，我使用 text-embedding-ada-002 生成具有 1536 维的向量
我不能谈论使用多个嵌入模型，因为我没有这样做过，但我使用 Wea​​viate 作为我的矢量存储，它有一个嵌入转换器 text2vec-openai，几个月来一直对我来说运行良好现在。
现在，尽管如此，有时会得到大约 50 个结果，但我仍然无法通过某些文档集（特别是劳工协议和宗教布道）获得最全面的答案。我发现将文档检索限制提高到 50 以上并不总能产生预期的结果。本例中的模型（gpt-4-turbo）可能具有更大的输入上下文窗口，但是您放入其中的文本越多，理解该文本的效率就越低。请参阅：Anthropic 最好的 Claude 2.1 功能遭遇与 GPT-4 Turbo 相同的命运
因此，我提出了自己的策略，我称之为“深入研究”。它类似于这种方法，我们使用法学硕士来提取更全面的结果：开发 LLM 应用程序的最大困难 - #41 byplasmatoid
但是地雷更加简单：我运行余弦相似度搜索并返回前 50 - 100 个检索，如前所述。但是，我没有将这些返回给主要的 LLM 进行评估，而是使用更便宜的模型（具有较低的上下文窗口）来评估 10-15 个批次的结果，并为我提供最相关的匹配。一旦该法学硕士评估了所有结果，我就会将其结果以及最相关的文件发送给主法学硕士。从这里，我做两件事之一：要么返回辅助法学硕士的串联结果，要么让主法学硕士评估最相关的文档。还不确定哪一个效果最好。
无论如何，我的两分钱。]]></description>
      <guid>https://community.openai.com/t/rag-is-failing-when-the-number-of-documents-increase/578498#post_5</guid>
      <pubDate>Sat, 06 Jan 2024 02:47:54 GMT</pubDate>
    </item>
    <item>
      <title>TTS HD 与 TTS 有什么区别？</title>
      <link>https://community.openai.com/t/what-is-difference-between-tts-hd-vs-tts/578537#post_3</link>
      <description><![CDATA[质量优化的价格是速度优化的两倍。
我上次检查时，它们具有相同的音频带宽和采样率，并且由于连续运行的各代并不相同，因此很难比较质量。
这可能是一些微妙的东西，比如人工智能模型的内部维度或参数的数量。训练量或困惑度。这会导致“速度”降低，尽管这似乎也没有明显不同。]]></description>
      <guid>https://community.openai.com/t/what-is-difference-between-tts-hd-vs-tts/578537#post_3</guid>
      <pubDate>Sat, 06 Jan 2024 02:26:47 GMT</pubDate>
    </item>
    <item>
      <title>ArduPilot UAV（又称无人机）和 ChatGPT-4 使用 MAVProxy 的聊天模块</title>
      <link>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_9</link>
      <description><![CDATA[安全着陆功能是个好主意，但通过 API 调用来实现这一点可能不是最好的主意，因为地面条件可能会以不可预测的方式快速变化。 （考虑避开车辆和人员）



 rmackay999：
&lt;块引用&gt;
我们正计划支持任务规划！我正在争论接下来是否要关注这个或车辆设置（例如传感器校准等）。


我只需要设置一次飞行器，但每次需要飞行时我都需要计划一个新的任务，所以我的票肯定投给了任务规划。]]></description>
      <guid>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_9</guid>
      <pubDate>Sat, 06 Jan 2024 02:24:44 GMT</pubDate>
    </item>
    <item>
      <title>开发LLM应用程序的最大困难</title>
      <link>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_67</link>
      <description><![CDATA[我有一个测试语料库，我称之为 Bowl Season，目前包含 42 个文档（周一后为 43 个），每个文档对应每场大学橄榄球比赛。我可以要求该语料库“告诉我每场比赛的得分以及每场比赛中接球码数最多的球员”。使用我的系统，我可以使用 8k 上下文窗口让 GPT-3.5 或 4 准确回答该问题。借助传统的 RAG 和 128k 上下文窗口，即使是 GPT 4 也会陷入困境。
这是我的小语料库。我最大的语料库有超过 100 万个文档和 5 亿个令牌。对于较小的语料库，我让模型对语料库中的每个文档进行推理。它需要这样做才能回答“告诉我每场比赛的得分”之类的问题，但对于较大的语料库，我只让模型“可能”看到约 25% 的语料库。我的算法通常能够回答任何规模的语料库的复杂问题。这实际上只是您想让它运行多长时间（推理超过 100 万份文档可能需要多达 100 个 LLM 调用）以及您愿意花多少钱。]]></description>
      <guid>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_67</guid>
      <pubDate>Sat, 06 Jan 2024 02:04:12 GMT</pubDate>
    </item>
    <item>
      <title>ArduPilot UAV（又称无人机）和 ChatGPT-4 使用 MAVProxy 的聊天模块</title>
      <link>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_8</link>
      <description><![CDATA[嗨@N2U，
非常感谢您的积极反馈！添加这个功能真的很有趣。
我使用了 CubePilot CubeOrange，但我们的任何 &lt; a href=&quot;https://ardupilot.org/copter/docs/common-autopilots.html&quot; rel=&quot;noopener nofollow ugc&quot;&gt;支持的自动驾驶仪将起作用。
重新运行“将聊天模块移动到无人机上运行”时，我应该更清楚地知道我希望还允许自动驾驶仪直接与 OpenAI 的助手进行某些任务的通信不涉及地面站。我特别想尝试添加“安全着陆”功能，自动驾驶仪会发送从无人机的朝下摄像头万向节拍摄的图像，并询问助手最安全的着陆地点在哪里。
我确实考虑过添加文本转语音功能，MAVProxy 实际上已经有了这个功能，但它是多年前编写的，听起来非常机械化。由于延迟，我一直犹豫是否使用 OpenAI 的 TTS……我想要听起来自然的语音，但希望最终能实现！
是的，我们正计划支持任务规划！我正在争论下一步是否关注这个或车辆设置（例如传感器校准等）。我怀疑我们会同时做这两件事，我认为这只是一个优先问题。
再次感谢您的反馈！]]></description>
      <guid>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_8</guid>
      <pubDate>Sat, 06 Jan 2024 02:00:45 GMT</pubDate>
    </item>
    <item>
      <title>开发LLM应用程序的最大困难</title>
      <link>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_66</link>
      <description><![CDATA[


史蒂文尼克：
&lt;块引用&gt;
整个推理问题是一个压缩问题，因此它实际上是了解如何有效地将 10 亿个内容标记压缩到 8k - 16k 上下文窗口中，模型可以使用该窗口生成答案。


根据我的经验，好的旧 RAG 1.0 仍然解决了在 16K 上下文窗口（gpt-4-turbo 现在只是 4K 输出窗口）内回答来自 10 亿个内容标记的问题的问题，并具有老式的余弦相似性。问题不在于理解返回的文档，而在于对问题提供全面的答案。
同样，根据我的经验，这是两个限制的结果：

没有返回足够的上下文文档
模型无法有效读取所有上下文文档（即在中间丢失详细信息）。

这些问题都不能通过摘要或压缩来解决，特别是当您处理的法律文档中的每个细节都必须逐字分析和呈现时。
现在，我只是根据我自己有限的经验来谈谈。如果我错了，请多多指教。如果我正在处理一份 750 页长的劳动协议，并且我不仅需要了解有关假期工资的规则，而且还需要了解影响每个可能的工人分类的每个可能的规则，我只是不知道汇总将如何获得作为雇主，我需要全面而详细的答案才能做出充分知情的决定。]]></description>
      <guid>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=4#post_66</guid>
      <pubDate>Sat, 06 Jan 2024 01:57:28 GMT</pubDate>
    </item>
    <item>
      <title>响应具有有效的 json，但它嵌套在损坏的 json 中</title>
      <link>https://community.openai.com/t/response-has-valid-json-but-its-nested-in-broken-json/578322#post_16</link>
      <description><![CDATA[您可以使用我的 AlphaWave 客户端 来显着提高从模型获取 JSON 的可靠性。 AlphaWave 允许您提供一个 JSON 模式，该模式不仅用于验证您是否返回 JSON，还用于验证您是否返回所有必填字段。这是 AlphaWave 的 Python 版本。我显然有点偏见，但我怀疑你会找到比 AlphaWave 更可靠的 JSON 输出的东西。我很高兴详细了解为什么会出现这种情况……即使是 OpenAI 的新 JSON 模式与 AlphaWave 相比也很糟糕。
您的架构看起来足够简单，使用 AlphaWave 您应该会看到模型输出的可靠性超过 99%。即使使用 GPT 3.5]]></description>
      <guid>https://community.openai.com/t/response-has-valid-json-but-its-nested-in-broken-json/578322#post_16</guid>
      <pubDate>Sat, 06 Jan 2024 01:48:51 GMT</pubDate>
    </item>
    <item>
      <title>ArduPilot UAV（又称无人机）和 ChatGPT-4 使用 MAVProxy 的聊天模块</title>
      <link>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_7</link>
      <description><![CDATA[嗨@Foxabilo，
太好了，是的，您可能与 Andrew “Tridge” Tridgell 交谈过，他是我们的系统领导者和飞机“维护者”。
重新流模式，我非常期待它，但我认为它还不能通过 Assistant API 使用（相关讨论在这里）。一旦可用，我一定会使用它！
发送有关费用的建议和最新信息。我将研究按功能等对令牌使用情况进行细分。我认为这可能主要来自助手消耗我们的 1400 个飞行代码参数:-)。]]></description>
      <guid>https://community.openai.com/t/ardupilot-uavs-aka-drones-and-chatgpt-4-using-mavproxys-chat-module/578292#post_7</guid>
      <pubDate>Sat, 06 Jan 2024 01:44:31 GMT</pubDate>
    </item>
    </channel>
</rss>