<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sun, 04 Feb 2024 12:29:03 GMT</lastBuildDate>
    <item>
      <title>访问外部 api 时出现 Action API 错误 [紧急]</title>
      <link>https://community.openai.com/t/error-with-action-api-in-accessing-an-external-api-urgent/613661#post_1</link>
      <description><![CDATA[]]></description>
      <guid>https://community.openai.com/t/error-with-action-api-in-accessing-an-external-api-urgent/613661#post_1</guid>
      <pubDate>Sun, 04 Feb 2024 12:27:10 GMT</pubDate>
    </item>
    <item>
      <title>gpt-4-1106-vision-preview 也变得懒惰了吗</title>
      <link>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_5</link>
      <description><![CDATA[注意到有时 Vision 预览拒绝实际读取网站屏幕截图中的文本。这以前没有发生过。我设法用一些提示魔法解决了这个问题，但这仍然很奇怪。]]></description>
      <guid>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_5</guid>
      <pubDate>Sun, 04 Feb 2024 12:22:52 GMT</pubDate>
    </item>
    <item>
      <title>助手API可以读取元数据吗？</title>
      <link>https://community.openai.com/t/can-the-assistants-api-read-the-metadata/513796?page=2#post_25</link>
      <description><![CDATA[


 salmansadiq1015：
&lt;块引用&gt;
我们可以提供一些默认问题


我执行此操作的方法是使用运行的additional_instructions 参数。
原因是线程对话历史有一个点会被截断，而且 AI 一次性阅读的质量也不是很好，并且你不希望用户多次提示用户输入个人信息信息。
当人工智能最终返回带有个人信息的工具调用时，或经过多次循环后，您可以禁用附加指令。
说明本身只会包含纠缠用户的方法和理由，以及提供之前的禁令。]]></description>
      <guid>https://community.openai.com/t/can-the-assistants-api-read-the-metadata/513796?page=2#post_25</guid>
      <pubDate>Sun, 04 Feb 2024 12:18:58 GMT</pubDate>
    </item>
    <item>
      <title>256 维 v3 小嵌入模型的 MTEB 基准</title>
      <link>https://community.openai.com/t/mteb-benchmark-for-v3-small-embedding-model-with-256-dimensions/613369#post_3</link>
      <description><![CDATA[


 qweruiop316：
&lt;块引用&gt;
官方帖子显示MTEB在512和1536维度下的得分，有人知道256维度下的表现如何吗？


如上所示，3-small 没有 256 维输出。
如果您制作自己的自定义截断或降维算法，我预计结果会低于 ada-002 水平。
基准测试的性能可能与您实际执行的相似性任务无关，因此您可以通过试验来了解在您的特定应用程序中将 2k 字节嵌入减少到 1k 是否真的值得。您无需重新嵌入即可比较 dot-512 与 dot-256 的质量或速度。]]></description>
      <guid>https://community.openai.com/t/mteb-benchmark-for-v3-small-embedding-model-with-256-dimensions/613369#post_3</guid>
      <pubDate>Sun, 04 Feb 2024 12:14:36 GMT</pubDate>
    </item>
    <item>
      <title>聊天历史记录关闭 =“未找到对话密钥”错误</title>
      <link>https://community.openai.com/t/chat-history-off-conversation-key-not-found-error/594342?page=4#post_78</link>
      <description><![CDATA[自 2 月 2 日以来，我遇到了同样的问题。我希望他们能够解决这个错误，似乎很多人都面临着这个问题。]]></description>
      <guid>https://community.openai.com/t/chat-history-off-conversation-key-not-found-error/594342?page=4#post_78</guid>
      <pubDate>Sun, 04 Feb 2024 12:12:51 GMT</pubDate>
    </item>
    <item>
      <title>gpt-4-1106-vision-preview 也变得懒惰了吗</title>
      <link>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_4</link>
      <description><![CDATA[


 utsav15.goel:
&lt;块引用&gt;
我使用的是 gpt-4-1106-vision-preview


从名字上就可以看出，这仍然是一个懒惰的拒绝机器。
特别是，它没有被训练有视觉，但有大量微调训练来否认人们查看和处理图像的能力。
您需要一个强大的系统提示来告诉它所有关于其视觉功能以及它可以用它们做什么。然后继续在用户被拒绝的情况下提供履行说明。
系统指令跟随性较差。在大多数情况下，您会希望让用户指定 AI 应该做什么。]]></description>
      <guid>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_4</guid>
      <pubDate>Sun, 04 Feb 2024 12:07:13 GMT</pubDate>
    </item>
    <item>
      <title>谁在申请 Converge 2？</title>
      <link>https://community.openai.com/t/whos-applying-to-converge-2/564181?page=5#post_92</link>
      <description><![CDATA[@tobiasadane 祝你好运，感谢你的好话！这确实意义重大。让我们满怀希望！ ]]></description>
      <guid>https://community.openai.com/t/whos-applying-to-converge-2/564181?page=5#post_92</guid>
      <pubDate>Sun, 04 Feb 2024 12:03:00 GMT</pubDate>
    </item>
    </channel>
</rss>