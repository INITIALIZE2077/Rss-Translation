<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 14 Dec 2023 15:18:26 GMT</lastBuildDate>
    <item>
      <title>主题：有关通过 API 访问自定义 GPT 模型的查询</title>
      <link>https://community.openai.com/t/subject-inquiry-about-accessing-custom-gpt-models-via-api/493810#post_7</link>
      <description><![CDATA[您是否能够在这里找到一种解决方案，将助手的性能提高到与 customGPT 相当的程度？我正在尝试与数据库进行类似的接口。 customGPT 运行良好，但尚未尝试移植到助手。]]></description>
      <guid>https://community.openai.com/t/subject-inquiry-about-accessing-custom-gpt-models-via-api/493810#post_7</guid>
      <pubDate>Thu, 14 Dec 2023 15:17:54 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT (GPT-4) 无法使用，因为“我们的系统检测到您的系统存在异常活动。请稍后重试。”</title>
      <link>https://community.openai.com/t/chatgpt-gpt-4-unusable-due-to-our-systems-have-detected-unusual-activity-from-your-system-please-try-again-later/557407#post_2</link>
      <description><![CDATA[更新：在使用 OpenAI 支持开票后，部分企业用户遇到了问题，回滚后现在一切正常。]]></description>
      <guid>https://community.openai.com/t/chatgpt-gpt-4-unusable-due-to-our-systems-have-detected-unusual-activity-from-your-system-please-try-again-later/557407#post_2</guid>
      <pubDate>Thu, 14 Dec 2023 15:17:30 GMT</pubDate>
    </item>
    <item>
      <title>Mistral-Medium 与 GPT-3.5 Turbo？</title>
      <link>https://community.openai.com/t/mistral-medium-versus-gpt-3-5-turbo/556898#post_10</link>
      <description><![CDATA[本地在 2x4090 上，使用 LoneStriker 的 4.65 位 exl2 量化
（exllamav2 支持模型内的变量量化，具体取决于测试数据集对其量化的一组权重的敏感性）
每 4090 需要约 22GB vram，足够快（每秒 10 秒的令牌，尚未测量），8k 上下文。]]></description>
      <guid>https://community.openai.com/t/mistral-medium-versus-gpt-3-5-turbo/556898#post_10</guid>
      <pubDate>Thu, 14 Dec 2023 15:17:25 GMT</pubDate>
    </item>
    <item>
      <title>为什么 OpenAI 让“使用情况”页面变得更糟？</title>
      <link>https://community.openai.com/t/why-did-openai-make-the-usage-page-worse/549377#post_6</link>
      <description><![CDATA[就我个人而言，我确实认为这是一件相当大的事情。我认为解决 OpenAI 关于我们支出的透明度问题至关重要。之前的“使用情况”页面提供了有价值的见解，但他们从该页面中删除了有用的功能，这意味着管理我们的支出更加困难。这是不选择 OpenAI 的另一个原因，因为其他服务提供深入、详细的活动页面，帮助管理支出并决定使用哪些模型。
我喜欢 OpenAI 提供的服务，但重要的是能够看到每个请求使用了多少输入令牌、输出令牌和总令牌，并且能够查看每天和每个小时的详细信息像以前一样的一天。我不明白为什么他们必须删除这些功能，我希望可以重新添加它们。]]></description>
      <guid>https://community.openai.com/t/why-did-openai-make-the-usage-page-worse/549377#post_6</guid>
      <pubDate>Thu, 14 Dec 2023 15:14:40 GMT</pubDate>
    </item>
    <item>
      <title>在 chatGPT3.5 中仅使用一次关键字</title>
      <link>https://community.openai.com/t/use-keyword-only-once-with-chatgpt3-5/558684#post_1</link>
      <description><![CDATA[如何创建提示来要求 chatgpt 将关键字限制为仅在文本开头出现一次。我已经尝试了 20 多个选项，但文本中仍然出现 3-5 次该关键字。 chatpt 3.5有这样的问题，4版本好像不存在。]]></description>
      <guid>https://community.openai.com/t/use-keyword-only-once-with-chatgpt3-5/558684#post_1</guid>
      <pubDate>Thu, 14 Dec 2023 15:12:48 GMT</pubDate>
    </item>
    <item>
      <title>是否可以微调并嵌入相同的 gpt3.5 模型？</title>
      <link>https://community.openai.com/t/is-it-possible-to-fine-tune-and-embedd-the-same-gpt3-5-model/558678#post_1</link>
      <description><![CDATA[我正在尝试训练一个 GPT 模型来回答像我班上的学生一样的 A level 问题，但它不具备所需的知识。我知道我可以为此训练两个单独的机器人，但理想情况下我希望一次性完成所有工作。
可能吗？]]></description>
      <guid>https://community.openai.com/t/is-it-possible-to-fine-tune-and-embedd-the-same-gpt3-5-model/558678#post_1</guid>
      <pubDate>Thu, 14 Dec 2023 15:09:32 GMT</pubDate>
    </item>
    <item>
      <title>重新微调现有微调时是否会更改超参数？</title>
      <link>https://community.openai.com/t/do-you-change-hyperparams-when-re-finetuning-an-existing-fine-tune/558504#post_2</link>
      <description><![CDATA[继续微调基于模型中已有的权重和训练。之前的fine-tuning机器学习不再重做。]]></description>
      <guid>https://community.openai.com/t/do-you-change-hyperparams-when-re-finetuning-an-existing-fine-tune/558504#post_2</guid>
      <pubDate>Thu, 14 Dec 2023 15:07:01 GMT</pubDate>
    </item>
    <item>
      <title>令牌率限制估算澄清</title>
      <link>https://community.openai.com/t/token-rate-limit-estimation-clarification/558665#post_1</link>
      <description><![CDATA[我正在寻找有关如何计算代币速率限制的一些说明。
对于使用而言，当我使用输入提示发出请求并生成完成时，都会计算输入/完成提示令牌长度。
对于速率限制，文档指出：
&lt;块引用&gt;
您的速率限制的计算方式为 max_tokens 的最大值以及根据您请求的字符数估计的令牌数量

如果我理解正确的话，这就是说在处理请求之前，它将检查 max(input_prompt_token_length, max_tokens) 是否会让您超过速率限制，然后拒绝该请求。

这种理解正确吗？
请求完成后 - 总令牌长度（输入提示和输出完成）是否用于计算下一个请求的速率限制，还是仍使用之前计算的估计令牌数量？

例如，如果我请求完成并且我的输入提示是 100 个令牌，而我的 max_tokens 参数是 200 个令牌 - 出于速率限制的目的，它将检查 200 个令牌是否会超出速率限制，并且如果愿意的话，请拒绝该请求。
如果请求有效且服务正常，下一个请求是否会假设我已使用速率限制中的 200 个令牌或速率限制中的 300 个令牌？]]></description>
      <guid>https://community.openai.com/t/token-rate-limit-estimation-clarification/558665#post_1</guid>
      <pubDate>Thu, 14 Dec 2023 15:05:50 GMT</pubDate>
    </item>
    </channel>
</rss>