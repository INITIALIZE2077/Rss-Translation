<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 30 Dec 2023 18:22:42 GMT</lastBuildDate>
    <item>
      <title>iOS 应用程序的更改 - 模型翻转</title>
      <link>https://community.openai.com/t/changes-to-ios-app-model-flipping/575610#post_2</link>
      <description><![CDATA[我最近（上周）也注意到了这一点。我向 chatGPT 询问了它的版本，得到了 4.0 响应（并且，这在顶部的横幅中指出），然后提出了一个实质性问题并观察横幅切换到 3.5。然后我再次询问 chatGPT 它是什么版本。有时它会显示 4.0，然后按下时会显示 3.5。有时它会立即显示 3.5。这个错误足以终止该应用程序的实用性。我暂时将使用网络界面，但很高兴看到有人解决这个问题。]]></description>
      <guid>https://community.openai.com/t/changes-to-ios-app-model-flipping/575610#post_2</guid>
      <pubDate>Sat, 30 Dec 2023 18:16:20 GMT</pubDate>
    </item>
    <item>
      <title>知道 gpt-4 微调什么时候会为大家发布吗？</title>
      <link>https://community.openai.com/t/any-idea-when-gpt-4-fine-tuning-will-be-released-for-everyone/576294#post_1</link>
      <description><![CDATA[对我来说，3.5 Turbo 微调经常会陷入无限循环或无法处理复杂的场景
某些国家/地区会首先获得访问权限吗？
希望获得更多详细信息]]></description>
      <guid>https://community.openai.com/t/any-idea-when-gpt-4-fine-tuning-will-be-released-for-everyone/576294#post_1</guid>
      <pubDate>Sat, 30 Dec 2023 18:12:00 GMT</pubDate>
    </item>
    <item>
      <title>模型“gpt-4-vision-preview”有函数调用吗？</title>
      <link>https://community.openai.com/t/does-the-model-gpt-4-vision-preview-have-function-calling/490197#post_4</link>
      <description><![CDATA[（帖子已被作者删除）]]></description>
      <guid>https://community.openai.com/t/does-the-model-gpt-4-vision-preview-have-function-calling/490197#post_4</guid>
      <pubDate>Sat, 30 Dec 2023 17:59:05 GMT</pubDate>
    </item>
    <item>
      <title>自动保存文件图片并分析</title>
      <link>https://community.openai.com/t/automatic-save-files-pictures-and-analyse/576274#post_1</link>
      <description><![CDATA[你好
有没有任何插件/工具可以用来在 chatgtp、数据分析和 dalle 中自动保存我的通信文件、图片等？
我是首发。
您真诚的]]></description>
      <guid>https://community.openai.com/t/automatic-save-files-pictures-and-analyse/576274#post_1</guid>
      <pubDate>Sat, 30 Dec 2023 17:47:43 GMT</pubDate>
    </item>
    <item>
      <title>如何在 Playground（或类似）环境中使用 text-davinci-002？</title>
      <link>https://community.openai.com/t/how-can-i-use-text-davinci-002-in-a-playground-or-similar-environment/576273#post_1</link>
      <description><![CDATA[大家好。诚然，我对 OpenAI API 的工作原理不太了解，我只是喜欢使用 OpenAI Playground 进行提示。我现在发现模型列表中缺少 text-davinci-002 以及所有其他旧模型。 text-davinci-002 是我个人的最爱，所以我想在 1 月 4 日之前最后一次使用它。
有什么方法可以让 text-davinci-002 重新出现在完成模型列表中吗？如果没有，是否有某种使用 OpenAI API 密钥的替代方案仍然可以使用 text-davinci-002？我真的很感激一些指导。谢谢大家。]]></description>
      <guid>https://community.openai.com/t/how-can-i-use-text-davinci-002-in-a-playground-or-similar-environment/576273#post_1</guid>
      <pubDate>Sat, 30 Dec 2023 17:47:40 GMT</pubDate>
    </item>
    <item>
      <title>如何通过API同时生成图片和文字？谢谢</title>
      <link>https://community.openai.com/t/how-to-generate-an-image-and-text-at-the-same-time-by-api-thanks/576264#post_1</link>
      <description><![CDATA[例如，当使用 web gpt-4v 时，我们可以要求 gpt-4v 围绕某个主题创建图像，并要求它生成有关该主题的文本解释。是否可以使用 API 来做同样的事情？文档说这是不可能的，因为我们只能使用Dall E3创建图像，然后使用GPT-3.5或4来解释图像。任何评论都将受到高度赞赏。]]></description>
      <guid>https://community.openai.com/t/how-to-generate-an-image-and-text-at-the-same-time-by-api-thanks/576264#post_1</guid>
      <pubDate>Sat, 30 Dec 2023 17:42:05 GMT</pubDate>
    </item>
    </channel>
</rss>