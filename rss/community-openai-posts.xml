<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 10 Feb 2024 03:19:19 GMT</lastBuildDate>
    <item>
      <title>函数调用的 action_required 中的“运行”，但为函数调用提供的参数无效</title>
      <link>https://community.openai.com/t/a-run-in-action-required-for-a-function-call-but-provided-arguments-for-function-call-is-invalid/620809#post_1</link>
      <description><![CDATA[我定义了一个函数，供聊天代理在必要时调用。该函数具有必填字段，预计将从添加到线程的用户聊天中提取。在测试时，我注意到从用户输入中提取的函数调用参数是错误的。在此阶段，“run”操作处于“action_required”状态，并请求我提交函数调用的输出。但 LLM 为函数调用提取了错误的参数。因此我无法进行函数调用。从文档中我也无法取消此状态的运行。如果提取并返回到我的应用程序以使函数调用无效的参数，我该如何继续。接下来我可以做什么？]]></description>
      <guid>https://community.openai.com/t/a-run-in-action-required-for-a-function-call-but-provided-arguments-for-function-call-is-invalid/620809#post_1</guid>
      <pubDate>Sat, 10 Feb 2024 02:59:47 GMT</pubDate>
    </item>
    <item>
      <title>新的 GPT 3.5 Turbo 模型 (gpt-3.5-turbo-0125) 的上下文窗口是什么？</title>
      <link>https://community.openai.com/t/what-is-the-context-window-of-the-the-new-gpt-3-5-turbo-model-gpt-3-5-turbo-0125/609532#post_5</link>
      <description><![CDATA[我明确地将模型设置为“gpt-3.5-turbo-0125”并在您显示的页面上（https://platform.openai.com/docs/models/gpt-3-5-turbo) ，文档引用了 16k 窗口，但它只接受 4k代币。
]]></description>
      <guid>https://community.openai.com/t/what-is-the-context-window-of-the-the-new-gpt-3-5-turbo-model-gpt-3-5-turbo-0125/609532#post_5</guid>
      <pubDate>Sat, 10 Feb 2024 02:51:34 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_33</link>
      <description><![CDATA[


_j：
&lt;块引用&gt;
256 x 4 字节 = 1k，而 1024 x 1 字节 = 1k，


您也可以为更长的向量争取更大的量化。因此，“级别 1”的每个向量条目 4 位，“级别 2”的每个向量条目 8 位，依此类推，直到达到最高量化状态（16/32/64 位）
我之所以选择更短、更多位的原因是，我有一个理论，新 OpenAI 模型中的向量维度是有序的，因此您希望将更多位投入到较低维度以保持性能。
因此，更加量化的 3072 暗淡向量就像 256 维度的相同量化一样，因为更高的维度只会增加修饰，而没有太多实质内容。至少这是我目前的假设。
为了好玩，你可以进行多位量化。因此变暗 1:256，32 位。调暗 257:1024，16 位。调暗 1025:3072，8 位。类似的事情。使相关性变得复杂，因为您现在有 3 个块，但您重新调整并组合以形成整体答案，同时仅在信息内容所在的位置分配位。
您还可以并行运行这些多位块以获得额外的加速收益。
这种多位架构“扁平化”了整个事情，使其变得更容易，并且您可以避免多个阶段，这会增加延迟。
顺便说一句，您可以使用任何嵌入模型来完成此操作。嵌入一​​堆对您来说重要的东西后，您将使用 PCA 对每个维度进行排名，以形成您的排列向量，因此您现在可以决定您的位边界。]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_33</guid>
      <pubDate>Sat, 10 Feb 2024 02:49:13 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_11</link>
      <description><![CDATA[实际上，据我所知，它是阿拉伯精度（尽管由于 OAI 价格也具有更高的精度，因此可能有一定道理。让我们将其提高到 25,000.005 美元）。
想要赠送 125k，而不是 25k，但想将其分配给多个项目。
不涉及彩票。]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_11</guid>
      <pubDate>Sat, 10 Feb 2024 02:41:34 GMT</pubDate>
    </item>
    <item>
      <title>请为桌面用户提供更宽的文本区域</title>
      <link>https://community.openai.com/t/please-accommodate-desktop-users-with-a-wider-text-area/620797#post_1</link>
      <description><![CDATA[本身并不是一个“错误”，但 ChatGPT 的移动优先设计确实是“仅限移动设备”，因为它浪费了大量的屏幕空间和无用的空白。更糟糕的是，查看基于代码的响应通常需要的水平滚动条并不总是出现；请参阅所附示例。请考虑调整 ChatGPT 主页面以支持使用实际 PC 显示器（而不仅仅是手机）的用户。谢谢！
]]></description>
      <guid>https://community.openai.com/t/please-accommodate-desktop-users-with-a-wider-text-area/620797#post_1</guid>
      <pubDate>Sat, 10 Feb 2024 02:39:03 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_10</link>
      <description><![CDATA[Lmao 
以 3 位数的精度数钱，这就是德国的精度！ &lt;img alt=&quot;:rofl:&quot; class=&quot;emoji&quot; height=&quot;20&quot; src=&quot;https://emoji.discourse-cdn.com/twitter/rofl.png?v=12&quot; title=&quot;:rofl: “宽度=“20”/&gt;
你中奖了吗？或者您的某个帐户上是否有价值 25k 的积分？ &lt;img alt=&quot;:laughing:&quot; class=&quot;emoji&quot; height=&quot;20&quot; src=&quot;https://emoji.discourse-cdn.com/twitter/laughing.png?v=12&quot; title=&quot;:laughing: “宽度=“20”/&gt;]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_10</guid>
      <pubDate>Sat, 10 Feb 2024 02:38:31 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_9</link>
      <description><![CDATA[顺便说一句，我会说 14 种语言。所以有时你可能会变得有点困惑。]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_9</guid>
      <pubDate>Sat, 10 Feb 2024 02:35:17 GMT</pubDate>
    </item>
    <item>
      <title>CustomGPT Action API 连接工作 - 这是我的做法</title>
      <link>https://community.openai.com/t/customgpt-action-api-connection-working-heres-how-i-did-it/583221#post_6</link>
      <description><![CDATA[您的 api 密钥是在标头或查询中传递的吗？
我使用了代码，但它不起作用：
组件：
安全方案：
ApiKeyAuth：
类型：apiKey
在：标题
名称：X-Api-Key
安全性：

ApiKeyAuth：
]]></description>
      <guid>https://community.openai.com/t/customgpt-action-api-connection-working-heres-how-i-did-it/583221#post_6</guid>
      <pubDate>Sat, 10 Feb 2024 02:33:53 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_8</link>
      <description><![CDATA[但是，然后将其作为测试，以便更容易选择 ]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_8</guid>
      <pubDate>Sat, 10 Feb 2024 02:31:29 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_32</link>
      <description><![CDATA[


 curt.kennedy:
&lt;块引用&gt;
在 python/numpy 中，乘法比 16 位浮点数快 163 倍


或者一些 GPU...
 cosine_sim = tf.keras.losses.cosine_similarity(tensor1，tensor2，axis=-1)

但是，我只是在考虑实时向量存储的内存大小。 256 x 4 字节 = 1k，而 1024 x 1 字节 = 1k，后者可能会更好地进行基准测试以获得结果。
然后您考虑一下，4k 向量对应 4k 数据块？]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_32</guid>
      <pubDate>Sat, 10 Feb 2024 02:31:22 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_7</link>
      <description><![CDATA[哈哈，我想的是 25 美元，而不是 25000 美元。]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_7</guid>
      <pubDate>Sat, 10 Feb 2024 02:29:36 GMT</pubDate>
    </item>
    <item>
      <title>有人有什么商业想法吗？</title>
      <link>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_6</link>
      <description><![CDATA[是的，没错。数字格式可能有误 - 我很抱歉我不是母语人士。但假设有人愿意投资 25.00 美元来发帖，那就太搞笑了。
如果我对某个特定的利基市场感兴趣，我也会把它放进去。无需解释。
您有一个项目或一个想法（并且您是愿意构建它的开发人员），需要 oai 模型积分，然后给我发消息。]]></description>
      <guid>https://community.openai.com/t/anyone-has-any-business-idea/620267#post_6</guid>
      <pubDate>Sat, 10 Feb 2024 02:26:02 GMT</pubDate>
    </item>
    <item>
      <title>Assistant API 功能的时间表？</title>
      <link>https://community.openai.com/t/timeline-for-assistants-api-features/620524#post_4</link>
      <description><![CDATA[让我再添加一项确实有助于增强 Assistant API 的改进，这非常棒，因为它允许我们一对一地为用户社区提供服务：为 Assistant API 启用 JSON 模式]]></description>
      <guid>https://community.openai.com/t/timeline-for-assistants-api-features/620524#post_4</guid>
      <pubDate>Sat, 10 Feb 2024 02:25:28 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_31</link>
      <description><![CDATA[此外，您应该考虑 16 位有符号整数。在 python/numpy 中，乘法比 16 位浮点数快 163 倍，至少根据 ChatGPT  听起来很疯狂，我必须测试一下才能确定。

ChatGPT 的 32/16 位乘法比较代码基准 （点击查看更多详情）
但想法是获取向量，将其乘以 32767 并重新转换为 16 位有符号整数。使用像 numpy 这样的东西，它使用优化的库，或者用 C 或 Rust 等较低级别的东西进行编码。
您可以调整阈值，或者将最终答案除以 32767 并使用常规阈值。
关于 16 位，唯一的一点是，表示的最小值大约为 3.05185×10
^{−5}。这可能位于嵌入信息的边缘。如果这是一个问题，则在乘以 2^{31}−1=2,147,483,647 后重新转换为 32 位有符号整数
应该可以解决这个问题。  显然，计算上的时间差异很小，但您的内存占用量增加了一倍。
另一个技巧是根本不做乘法！如何？使用曼哈顿指标或 L1 范数。
d(\mathbf{a}, \mathbf{b}) = \sum_{i=1}^{n} |a_i - b_i|
因此改变第二个向量的符号，添加到第一个向量，绝对值，总和。没有任何乘法。
应该超级快，对于整数甚至更快。]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276?page=2#post_31</guid>
      <pubDate>Sat, 10 Feb 2024 02:17:35 GMT</pubDate>
    </item>
    </channel>
</rss>