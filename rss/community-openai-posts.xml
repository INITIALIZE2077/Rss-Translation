<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 19 Feb 2024 15:18:34 GMT</lastBuildDate>
    <item>
      <title>Gpt-4-0125-preview 比 3.5 Turbo 慢得多</title>
      <link>https://community.openai.com/t/gpt-4-0125-preview-incredibly-slower-than-3-5-turbo/640146#post_9</link>
      <description><![CDATA[我可以确认速度很慢。 （ChatGPT 的愿景，基于 1106 的愿景，在早期测试时生产速度也非常慢。）
虽然上面提到的 1106 模型没有被评估，但代币生产率一直在向低水平迈进：

  &lt;标题类=“来源”&gt;
      

      openai-status.llm-utils.org


  &lt;文章类=“onebox-body”&gt;
    

非官方 OpenAI 状态
查看 OpenAI 的当前状态和历史表现。





我自己的单个请求：
—gpt-4-1106-预览—
[3.3 秒内 32 个代币。 9.6 tps]
[32.0 秒内 600 个代币。 18.8 tps]
—gpt-4-turbo-preview—
[3.0 秒内 32 个代币。 10.6 tps]
[45.2 秒内 600 个代币。 13.3 tps]
—gpt-3.5-turbo—
[0.9 秒内 32 个代币。 33.7 tps]
[11.7 秒内 600 个代币。 51.4 tps]
这是一个带有写入请求的小型输入上下文。
&lt;小时/&gt;
另请注意，过去（对于那些在实施减速时认识到其帐户上发生重大变化的人），代币生产率对于那些 API 付款历史记录的第 1 层。]]></description>
      <guid>https://community.openai.com/t/gpt-4-0125-preview-incredibly-slower-than-3-5-turbo/640146#post_9</guid>
      <pubDate>Mon, 19 Feb 2024 15:15:25 GMT</pubDate>
    </item>
    <item>
      <title>我生成了很多内容，但无法形成文档供下载</title>
      <link>https://community.openai.com/t/i-generated-a-lot-of-content-but-couldnt-form-a-document-for-download/640334#post_1</link>
      <description><![CDATA[我创建了一个新的 GPT。正当我惊叹它的有效性时，我意识到虽然我生成了很多内容，但我无法轻松下载它们。





]]></description>
      <guid>https://community.openai.com/t/i-generated-a-lot-of-content-but-couldnt-form-a-document-for-download/640334#post_1</guid>
      <pubDate>Mon, 19 Feb 2024 15:15:22 GMT</pubDate>
    </item>
    <item>
      <title>GPT 不再读取消息中的 PDF</title>
      <link>https://community.openai.com/t/gpts-not-reading-pdfs-in-messages-anymore/632599?page=2#post_32</link>
      <description><![CDATA[我总是启用代码解释器，但这并不能解决问题。我认为这对他们来说是一个更大的问题]]></description>
      <guid>https://community.openai.com/t/gpts-not-reading-pdfs-in-messages-anymore/632599?page=2#post_32</guid>
      <pubDate>Mon, 19 Feb 2024 15:13:28 GMT</pubDate>
    </item>
    <item>
      <title>如何克服响应延迟</title>
      <link>https://community.openai.com/t/how-to-overcome-latency-in-response/594000#post_3</link>
      <description><![CDATA[我非常确定，为了获得良好的电话通话体验，语音转文本必须在电话呼叫类型应用程序的本地运行。因为延迟非常重要。语音转文本并不复杂。
其次，对于(2)。这已经是可能的了。您已经可以检查响应需要多长时间。
在您的服务器上，检查自您请求以来的时间是否超过 X 秒，如果是，请使用填充词。
此外，您还可以流式传输法学硕士的回复，这样即使尚未完成完整的回复，您也可以开始对第一句话进行文本到语音转换。
希望这有帮助！但您必须为此做一些工作。]]></description>
      <guid>https://community.openai.com/t/how-to-overcome-latency-in-response/594000#post_3</guid>
      <pubDate>Mon, 19 Feb 2024 15:11:24 GMT</pubDate>
    </item>
    <item>
      <title>Gpt-4-0125-preview 比 3.5 Turbo 慢得多</title>
      <link>https://community.openai.com/t/gpt-4-0125-preview-incredibly-slower-than-3-5-turbo/640146#post_8</link>
      <description><![CDATA[不，前端直接命中路由。它只是该路线上的一个提示，除了 open ai api 调用之外没有其他任何事情发生。互联网也不是问题，下载速度大约为 700mbps，上传速度为 100mbps。]]></description>
      <guid>https://community.openai.com/t/gpt-4-0125-preview-incredibly-slower-than-3-5-turbo/640146#post_8</guid>
      <pubDate>Mon, 19 Feb 2024 15:09:53 GMT</pubDate>
    </item>
    <item>
      <title>本次对话中使用的先前模型不可用。我们已将您切换到最新的默认模型</title>
      <link>https://community.openai.com/t/the-previous-model-used-in-this-conversation-is-unavailable-weve-switched-you-to-the-latest-default-model/166371?page=2#post_28</link>
      <description><![CDATA[我也可以确认这个问题。看来团队计划中并没有复制这个问题。
无论如何，我只能希望它能在短期内得到解决。]]></description>
      <guid>https://community.openai.com/t/the-previous-model-used-in-this-conversation-is-unavailable-weve-switched-you-to-the-latest-default-model/166371?page=2#post_28</guid>
      <pubDate>Mon, 19 Feb 2024 15:09:35 GMT</pubDate>
    </item>
    </channel>
</rss>