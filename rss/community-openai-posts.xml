<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 16 Dec 2023 15:16:21 GMT</lastBuildDate>
    <item>
      <title>GPT 不比直接使用 GPT 好多少吗？</title>
      <link>https://community.openai.com/t/gpts-not-much-better-than-using-gpt-directly/495209?page=3#post_54</link>
      <description><![CDATA[
文档采用什么格式？ .txt、.pdf
内容的文本大纲、表格和叙述是否组织良好？ （文字是关键）。一个推论是内容是否被分块。
(a) 各个文档的字符数（不是字数）是多少； (b) 所有文档合并？
您是否精心设计了一个“做这做那，但不做这个或那个”的提示模板来指导学生？
您的说明设置正确吗？ （如果你不知道如何设置它们，这是一个愚蠢的问题，但研究过许多 GPT 指令集的人会知道......）
对上述各个主题领域的任何问题进行搜索，您都会获得大量真实的见解。

最后，
您尝试过 Google 的 NotebookLM 吗？它可能是一种更好的类似 GPT 的应用程序。我已经构建了 20 个 GPT 并研究了其他几十个。他们分为两类：老练（也许 10%）和愚蠢（90%）。
恕我直言，NotebookLM 超越了 GPT，具有足够的复杂性，可以灵活地访问多达 20 个文档和 20 万个单词。但它通过包括引文在内的强有力的摘要来做到这一点。一个人（学生）可以对精确信息进行深入研究，创建固定笔记，并更有效地跳过无用的内容。]]></description>
      <guid>https://community.openai.com/t/gpts-not-much-better-than-using-gpt-directly/495209?page=3#post_54</guid>
      <pubDate>Sat, 16 Dec 2023 15:15:59 GMT</pubDate>
    </item>
    <item>
      <title>不会从 Actions GET 请求下载 CSV 文件</title>
      <link>https://community.openai.com/t/wont-download-csv-file-from-actions-get-request/512277#post_5</link>
      <description><![CDATA[我也有同样的问题！我做了一个操作来使用返回大型 CSV 文件的 API。我希望这些内容能够被下载到代码解释器使用的环境中，但 CSV 内容会被插入到 GPT 的上下文窗口中。当 CSV 有数千行时，这显然不起作用。
目标是让 GPT 绘制 API 返回的 CSV 的内容。
如果目前无法做到这一点，我们是否应该以某种方式提出功能请求？]]></description>
      <guid>https://community.openai.com/t/wont-download-csv-file-from-actions-get-request/512277#post_5</guid>
      <pubDate>Sat, 16 Dec 2023 15:14:49 GMT</pubDate>
    </item>
    <item>
      <title>API 助手 VS GPT：主要区别是什么？</title>
      <link>https://community.openai.com/t/api-assistant-vs-gpts-whats-the-main-difference/499523?page=2#post_21</link>
      <description><![CDATA[我询问自定义 GPT 是否执行向量检索。这是回应：
不，我不会对您上传的文档执行矢量检索。相反，我使用不同的方法来处理和分析文档。以下是我如何处理您上传的文档的简要概述：


文档上传和存储：当您上传文档时，它们会以我可以在对话期间访问的方式安全存储。


文件浏览工具：我使用名为 myfiles_browser 的专用工具与您的文档进行交互。该工具允许我搜索文档中的特定术语、浏览文档并引用相关部分以为我的回复提供上下文。


手动分析：我不会自动处理或分析您上传的文档的全部内容。相反，我依靠您的询问来指导我。当您提出问题或索取信息时，我会使用 myfiles_browser 工具在文档中搜索相关信息。


上下文理解：我的回复基于您查询的上下文和文档中包含的信息。我使用文档中的信息，结合我训练有素的知识库，提供准确且相关的答案。


限制：我遵守文档和我的培训中包含的信息。我不会推测或提供超出文档和我的培训范围之外的信息。


总而言之，我会根据您的具体问题手动搜索和解释您上传的文档内容，并使用这些信息以及我的基线知识来提供准确且相关的答复。]]></description>
      <guid>https://community.openai.com/t/api-assistant-vs-gpts-whats-the-main-difference/499523?page=2#post_21</guid>
      <pubDate>Sat, 16 Dec 2023 15:05:42 GMT</pubDate>
    </item>
    <item>
      <title>我的自定义 GPT 刚刚消失</title>
      <link>https://community.openai.com/t/my-custom-gpt-just-dissapeared/556942#post_4</link>
      <description><![CDATA[谢谢您的回复。确实，customgpt 又出现了。虽然看起来已经过时了。当您从不同设备并行聊天时，该平台似乎不太喜欢。]]></description>
      <guid>https://community.openai.com/t/my-custom-gpt-just-dissapeared/556942#post_4</guid>
      <pubDate>Sat, 16 Dec 2023 15:00:05 GMT</pubDate>
    </item>
    <item>
      <title>GPT 3.5 Turbo API 响应缓慢</title>
      <link>https://community.openai.com/t/slow-responce-from-gpt-3-5-turbo-api/561153#post_4</link>
      <description><![CDATA[


埃弗利：
&lt;块引用&gt;
大家好，
我正在开发一个应用程序，该应用程序依赖于将中等大小的 Word 文档传递给 Gpt3.5 Turbo API 并接收响应，问题是处理一个请求需要大约 80 秒，这是巨大的，因为我打算将其设为企业级应用程序这需要处理数百个文档，因此对于用户来说太慢了，有什么线索可以加快速度吗？


确实，速度和性能可能会有很大波动。以下是一些您可以查看的提示和参考链接：

数据分块：为了处理大型文本，请考虑将其分块为更小的、可管理的片段，而不会丢失上下文。我记得发现这个视频非常有用：关于法学硕士数据准备的视频。
异步处理：在后台处理 API 响应。 异步编程。
企业解决方案：阅读这篇 NVIDIA 博客文章，了解他们的检索增强生成应用程序的方法。 博客文章。
]]></description>
      <guid>https://community.openai.com/t/slow-responce-from-gpt-3-5-turbo-api/561153#post_4</guid>
      <pubDate>Sat, 16 Dec 2023 14:56:49 GMT</pubDate>
    </item>
    <item>
      <title>Assistants API - 获得给定用户消息回复的最佳方式？</title>
      <link>https://community.openai.com/t/assistants-api-best-way-to-get-the-reply-to-a-given-user-message/561214#post_1</link>
      <description><![CDATA[嘿！我正在尝试使用 Assistants API 构建一个聊天机器人，并且有一些关于使用 API 的“最佳实践”的问题。

获取助理回复给定消息的预期方式是什么？

我们当前的流程是：

在话题中创建新的用户消息
为线程创建新的运行
等待运行状态为“完成”
查询线程中的消息，并筛选出 run_id 与我们之前创建的运行 ID 匹配的消息

这似乎在大多数情况下都有效，但有时会导致运行处于完成状态，但我们得到一组空消息作为助手的响应。我们的流程是否有问题，是否有更好的方法来获得助理响应？

助理是否可以使用多条助理消息来响应给定的用户消息？

到目前为止，助手似乎总是仅使用单个 Message 对象来响应任何给定的用户消息。在文档中找不到任何与此相关的内容，因此可以安全地假设情况总是如此吗？如果助理响应分为多个部分，这将反映在 message.content 数组中，对吗？如果有人能够提供一些实际的示例案例，其中 message.content 数组中将包含多个项目，我们将不胜感激 ]]></description>
      <guid>https://community.openai.com/t/assistants-api-best-way-to-get-the-reply-to-a-given-user-message/561214#post_1</guid>
      <pubDate>Sat, 16 Dec 2023 14:55:55 GMT</pubDate>
    </item>
    <item>
      <title>GPT 3.5 Turbo API 响应缓慢</title>
      <link>https://community.openai.com/t/slow-responce-from-gpt-3-5-turbo-api/561153#post_3</link>
      <description><![CDATA[非常感谢，我以为 OPenAI azure 会更贵]]></description>
      <guid>https://community.openai.com/t/slow-responce-from-gpt-3-5-turbo-api/561153#post_3</guid>
      <pubDate>Sat, 16 Dec 2023 14:55:16 GMT</pubDate>
    </item>
    <item>
      <title>您已达到 GPT-4 的当前使用上限，请在下午 2:04 后重试</title>
      <link>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=7#post_130</link>
      <description><![CDATA[今天早上我正在使用 DALL-E，并不断提示我输入一个刮胡子的男人的图像。输出是一个留着胡子的男人，无论提示中的具体情况如何，我都无法获得一个刮胡子的男人的图像。]]></description>
      <guid>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=7#post_130</guid>
      <pubDate>Sat, 16 Dec 2023 14:48:53 GMT</pubDate>
    </item>
    </channel>
</rss>