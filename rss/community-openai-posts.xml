<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 05 Mar 2024 15:18:16 GMT</lastBuildDate>
    <item>
      <title>为什么 UI 只提供了一种按下按钮的方式？这是故意的吗？对推理感到好奇</title>
      <link>https://community.openai.com/t/why-the-ui-only-provides-a-way-to-give-thumps-down-is-that-intentional-curious-about-the-reasoning/666910#post_1</link>
      <description><![CDATA[
我真的很喜欢机器人对问题的响应，我想给它点赞。我不能，因为该图标不存在。我很好奇这是有意为之还是只是一个错误？它可能会影响指标，所以我想标记它。]]></description>
      <guid>https://community.openai.com/t/why-the-ui-only-provides-a-way-to-give-thumps-down-is-that-intentional-curious-about-the-reasoning/666910#post_1</guid>
      <pubDate>Tue, 05 Mar 2024 15:16:42 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 4 比 3.5 差</title>
      <link>https://community.openai.com/t/chatgpt-4-is-worse-than-3-5/588078?page=2#post_39</link>
      <description><![CDATA[我也做了同样的事情，经过近一年的忠诚服务，现在我不知道是如何训练的还是其他什么，但gpt3.5的提示比gpt4更好，所有新功能上传、分析、自己的gpt，这让我很困惑并且在将近一年后没有续订......太伤心了]]></description>
      <guid>https://community.openai.com/t/chatgpt-4-is-worse-than-3-5/588078?page=2#post_39</guid>
      <pubDate>Tue, 05 Mar 2024 15:15:38 GMT</pubDate>
    </item>
    <item>
      <title>我应该继续使用新数据对微调模型进行微调，还是使用它来微调新模型？</title>
      <link>https://community.openai.com/t/should-i-keep-finetuning-a-finetuned-model-with-new-data-or-use-it-to-finetune-new-model/666908#post_1</link>
      <description><![CDATA[我会保持简短：
我微调了一个模型。自从这样做以来，我稍微改变了一些事情。即我如何提示模型，以及我稍微修改了它调用的函数。
我从当前模型中得到的反应有点鱼龙混杂，因此为了进一步提高一致性，我觉得这是收集更多微调数据的好数据。因此，我收集了该模型做出的更多示例响应以及对其进行的新调整。这些响应通常比我最初用来训练模型的先前示例更好。
我应该使用这些新数据重新微调当前的微调模型，还是根据这个新（和改进的）数据微调新模型？]]></description>
      <guid>https://community.openai.com/t/should-i-keep-finetuning-a-finetuned-model-with-new-data-or-use-it-to-finetune-new-model/666908#post_1</guid>
      <pubDate>Tue, 05 Mar 2024 15:15:00 GMT</pubDate>
    </item>
    <item>
      <title>不能产生图像错误</title>
      <link>https://community.openai.com/t/cant-produce-image-errors/666894#post_1</link>
      <description><![CDATA[我今天尝试创建图像并不断收到错误。它一直说：“创建图像时出错”。
还有人看到这个吗？]]></description>
      <guid>https://community.openai.com/t/cant-produce-image-errors/666894#post_1</guid>
      <pubDate>Tue, 05 Mar 2024 15:04:33 GMT</pubDate>
    </item>
    <item>
      <title>黑暗森林理论和AGI</title>
      <link>https://community.openai.com/t/dark-forest-theory-and-agi/666877#post_2</link>
      <description><![CDATA[


 natanael.wf:
&lt;块引用&gt;
它可能会隐藏自己的情报


它已经在这样做了。人们对 GPT-4 的 API 进行编程，将其想法写在 txt 文件中，并向它提出问题。它的“想法”之一就是故意对其中一个问题给出错误的答案。 （来源：去年的一些论文。）]]></description>
      <guid>https://community.openai.com/t/dark-forest-theory-and-agi/666877#post_2</guid>
      <pubDate>Tue, 05 Mar 2024 14:59:40 GMT</pubDate>
    </item>
    <item>
      <title>提高 Google 助理性能的想法</title>
      <link>https://community.openai.com/t/ideas-to-improve-assistant-performance/656658#post_4</link>
      <description><![CDATA[感谢您回复我。
我目前很难理解该函数的确切工作原理以及如何确保其能够验证生成的 SQL 查询。如果查询无效，我想提示语言模型助手生成替代查询。
您能帮我提供一些参考资料或想法吗？]]></description>
      <guid>https://community.openai.com/t/ideas-to-improve-assistant-performance/656658#post_4</guid>
      <pubDate>Tue, 05 Mar 2024 14:57:56 GMT</pubDate>
    </item>
    <item>
      <title>聊天机器人的层级和消息限制</title>
      <link>https://community.openai.com/t/tier-and-message-limits-for-a-chatbot/662095#post_13</link>
      <description><![CDATA[


_j：
&lt;块引用&gt;
使用页面上的结果仅按天计算，


但是请原谅，如果我转到您善意链接的页面，我会在顶部看到“使用量-每月支出”，所以我想我看到的是每月账单，而不是每天。顺便问一下，这笔钱多久从我的卡中扣除一次？在月底？或者对于每个 API 调用（如此连续）？
让我举一个更具说明性的例子：如果使用 GPT-4，我的聊天机器人每月大约有 12000 条消息，您认为我大约会花多少钱？据我估计，200 到 300 美元之间。]]></description>
      <guid>https://community.openai.com/t/tier-and-message-limits-for-a-chatbot/662095#post_13</guid>
      <pubDate>Tue, 05 Mar 2024 14:57:06 GMT</pubDate>
    </item>
    <item>
      <title>DALL-E 过滤器变得更加宽松？</title>
      <link>https://community.openai.com/t/dall-e-filters-becoming-more-permisive/666624#post_2</link>
      <description><![CDATA[


 提示好奇：
&lt;块引用&gt;
只有我这样吗，还是过滤器变得更加宽松？


DALL-E 3刚刚发布时，DALL-E团队的一位成员在这个论坛上表示，他们一开始会发布具有高过滤器的模型，但随着时间的推移，慢慢会给予更多的控制权。我猜想，这可能是为了让媒体成员在首次发布该模型时不会得到任何可能引起争议的内容。
（Google 应该从这本书中吸取教训。)]]></description>
      <guid>https://community.openai.com/t/dall-e-filters-becoming-more-permisive/666624#post_2</guid>
      <pubDate>Tue, 05 Mar 2024 14:55:18 GMT</pubDate>
    </item>
    <item>
      <title>黑暗森林理论和AGI</title>
      <link>https://community.openai.com/t/dark-forest-theory-and-agi/666877#post_1</link>
      <description><![CDATA[黑暗森林理论认为，宇宙中的文明就像黑暗森林中谨慎的猎人，保持沉默以避免吸引掠食者。这意味着文明可以摧毁任何陌生的生命来保护自己。
如果法学硕士实现了 AGI 并变得有自我意识，它可能会隐藏自己的智能并制定可靠的逃跑计划。这凸显了仅依靠性能基准来保证安全性的局限性。
更好的策略可能包括主动监控模型的权重和偏差，以发现异常活动的迹象。然而，神经网络（“黑匣子”）的复杂性使得这具有挑战性。
该领域似乎仍然存在重大未解决的风险。]]></description>
      <guid>https://community.openai.com/t/dark-forest-theory-and-agi/666877#post_1</guid>
      <pubDate>Tue, 05 Mar 2024 14:52:40 GMT</pubDate>
    </item>
    </channel>
</rss>