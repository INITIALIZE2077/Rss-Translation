<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 21 Mar 2024 01:11:11 GMT</lastBuildDate>
    <item>
      <title>本地主机开发已删除？</title>
      <link>https://community.openai.com/t/localhost-development-removed/692072#post_3</link>
      <description><![CDATA[知道了，谢谢。
如果可以恢复此状态，或者您可以解释此决定背后的原因，那就太好了。
无论如何，谢谢！]]></description>
      <guid>https://community.openai.com/t/localhost-development-removed/692072#post_3</guid>
      <pubDate>Thu, 21 Mar 2024 00:53:04 GMT</pubDate>
    </item>
    <item>
      <title>通过 ChatGPT 上传文件 - 幕后花絮</title>
      <link>https://community.openai.com/t/uploading-files-through-chatgpt-under-the-hood/692135#post_1</link>
      <description><![CDATA[当我通过 UI (ChatGPT4) 上传文件（例如 pdf）并提出相关问题时，它实际上是如何工作的？ RAG（检索增强生成）是否在幕后发生？或者只是多模态模型可以解释pdf？好奇它是如何“在幕后”工作的]]></description>
      <guid>https://community.openai.com/t/uploading-files-through-chatgpt-under-the-hood/692135#post_1</guid>
      <pubDate>Thu, 21 Mar 2024 00:28:53 GMT</pubDate>
    </item>
    <item>
      <title>API 调用后通信持续缓慢</title>
      <link>https://community.openai.com/t/consistent-slow-communication-after-api-call/691798#post_7</link>
      <description><![CDATA[没有提到的一件事是 detail 参数，它确保只使用一个“图块”，并且 OpenAI 会缩小图像以适合 512px 的框。否则，大图像仍然会被调整为更大的尺寸，并被分成几个图块，作为进行更高质量检查的一种方式。
调整大小和重新压缩自己（WebP 有人吗？）当然是可能的，如果它是一个快速的 CPU 设备，很容易就能提高速度。
我不同意“使用 URL”而不是发送您自己的 Base64 作为加速的想法。如果您已经拥有该图像（并且您可以发挥创意，在用户输入框获取位置后立即预取和调整大小），那么让 OpenAI 自行从另一个站点（图像可能位于此处）不可靠地下载会更快吗？更大并且超出你的控制？或者甚至让您花时间先将其上传到另一个网站，而不是直接以所需的目标尺寸发送到模型？您可能会看到一些加速的唯一情况是，如果您继续在聊天历史记录中包含过去的图像并为其付费，那么可能会有一些网络缓存服务器端。
视觉 AI 模型的速度实在是太慢了；即使只是与它聊天也有很短的延迟和令牌生产率。]]></description>
      <guid>https://community.openai.com/t/consistent-slow-communication-after-api-call/691798#post_7</guid>
      <pubDate>Thu, 21 Mar 2024 00:16:41 GMT</pubDate>
    </item>
    <item>
      <title>如何正确处理助手流中的函数调用(node.js)></title>
      <link>https://community.openai.com/t/how-to-properly-handle-the-function-call-in-assistant-streaming-node-js/687193#post_5</link>
      <description><![CDATA[我能够让函数调用正常工作，并且能够使用 openai.beta.threads.runs.submitToolOutputs() 提交工具输出。然而在那之后，我不确定如何获取包含输出的流响应。我可以确认响应正在发生，因为如果我列出历史线程消息，它确实包含新响应。我只是不知道如何在触发 submitToolOutputs() 后将其流式传输。任何见解将不胜感激。]]></description>
      <guid>https://community.openai.com/t/how-to-properly-handle-the-function-call-in-assistant-streaming-node-js/687193#post_5</guid>
      <pubDate>Thu, 21 Mar 2024 00:11:26 GMT</pubDate>
    </item>
    </channel>
</rss>