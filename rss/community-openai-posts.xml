<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sat, 27 Jan 2024 06:21:11 GMT</lastBuildDate>
    <item>
      <title>为什么 GPT-4-1106-preview 输入令牌仍然限制为 32K？ （2级）</title>
      <link>https://community.openai.com/t/why-gpt-4-1106-preview-input-token-is-still-limited-to-32k-tier-2/603482#post_3</link>
      <description><![CDATA[这是我一直在使用的代码。
我通过调用我在 OpenAI 网站上预先配置的 Assistant_id 来使用 Assistant Request。 Assistant 使用的是 GPT-4-1106-preview 的基本模型。有什么想法吗……？
openai.api_key = &#39;...&#39;

助理 ID = &#39;...&#39;

def create_thread(ass_id,提示):
    #找助理
    #assistant = openai.beta.assistants.retrieve(ass_id)

    #创建一个线程
    线程 = openai.beta.threads.create()
    my_thread_id = 线程.id


    #创建一条消息
    消息 = openai.beta.threads.messages.create(
        thread_id=my_thread_id,
        角色=“用户”，
        内容=提示
    ）

    ＃跑步
    运行 = openai.beta.threads.runs.create(
        thread_id=my_thread_id,
        Assistant_id=ass_id,
    ）

    返回run.id，线程.id


def check_status(run_id,thread_id):
    运行 = openai.beta.threads.runs.retrieve(
        线程_id=线程_id,
        运行_id=运行_id,
    ）
    返回运行状态



my_run_id, my_thread_id = create_thread(assistant_id,complete_prompt)


状态 = check_status(my_run_id,my_thread_id)

while（状态！=“已完成”）：
    状态 = check_status(my_run_id,my_thread_id)
    时间.睡眠(2)


响应 = openai.beta.threads.messages.list(
  thread_id = my_thread_id
）


如果响应.数据：
    print(response.data[0].content[0].text.value)```]]></description>
      <guid>https://community.openai.com/t/why-gpt-4-1106-preview-input-token-is-still-limited-to-32k-tier-2/603482#post_3</guid>
      <pubDate>Sat, 27 Jan 2024 06:15:40 GMT</pubDate>
    </item>
    <item>
      <title>Whisper 在 vs code 上显示文件未找到错误</title>
      <link>https://community.openai.com/t/whisper-showing-file-not-found-error-on-vs-code/596572#post_5</link>
      <description><![CDATA[“Insanely Fast Whisper”版本也会出现这种情况。]]></description>
      <guid>https://community.openai.com/t/whisper-showing-file-not-found-error-on-vs-code/596572#post_5</guid>
      <pubDate>Sat, 27 Jan 2024 05:51:45 GMT</pubDate>
    </item>
    <item>
      <title>Whisper 在 vs code 上显示文件未找到错误</title>
      <link>https://community.openai.com/t/whisper-showing-file-not-found-error-on-vs-code/596572#post_4</link>
      <description><![CDATA[谢谢，但我使用的是 11 月份的同一个 CoLab 笔记本，它成功运行了大约 50 次。但是，当我将 WAV 或 MP3 文件拖到文件夹图标进行上传然后运行代码时，我总是会遇到这些奇怪的文件错误。我无法指定路径，因为它已上传到 Google 驱动器的某个位置：
!whisper“TRF2402_Dennis.wav”--模型小
回溯（最近一次调用最后一次）：
文件“/usr/lib/python3.10/urllib/request.py”，第 1348 行，在 do_open
h.request(req.get_method(), req.selector, req.data, headers,
文件“/usr/lib/python3.10/http/client.py”，第 1283 行，请求中
self._send_request(方法、url、正文、标头、encode_chunked)
文件“/usr/lib/python3.10/http/client.py”，第 1329 行，在 _send_request
self.endheaders(body,encode_chunked=encode_chunked)
文件“/usr/lib/python3.10/http/client.py”，第 1278 行，在 endheaders
self._send_output(message_body,encode_chunked=encode_chunked)
文件“/usr/lib/python3.10/http/client.py”，第 1038 行，在 _send_output
self.send(msg)
文件“/usr/lib/python3.10/http/client.py”，第 976 行，发送
self.connect()
文件“/usr/lib/python3.10/http/client.py”，第 1455 行，连接
self.sock = self._context.wrap_socket(self.sock,
文件“/usr/lib/python3.10/ssl.py”，第 513 行，wrap_socket
返回 self.sslsocket_class._create(
文件“/usr/lib/python3.10/ssl.py”，第 1100 行，在 _create
self.do_handshake()
文件“/usr/lib/python3.10/ssl.py”，第 1371 行，在 do_handshake
self._sslobj.do_handshake()
ConnectionResetError：[Errno 104] 连接被对等方重置
在处理上述异常的过程中，又发生了一个异常：
回溯（最近一次调用最后一次）：
文件“/usr/local/bin/whisper”，第 8 行，位于 
sys.exit(cli())
文件“/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py”，第 577 行，在 cli
model = load_model(model_name, device=device, download_root=model_dir)
文件“/usr/local/lib/python3.10/dist-packages/whisper/init.py”，第 133 行，位于 load_model
checkpoint_file = _download(_MODELS[名称], download_root, in_memory)
文件“/usr/local/lib/python3.10/dist-packages/whisper/init.py”，第 69 行，位于 _download
以 urllib.request.urlopen(url) 作为源， open(download_target, “wb”) 作为输出：
文件“/usr/lib/python3.10/urllib/request.py”，第 216 行，在 urlopen
return opener.open(url, data, timeout)
文件“/usr/lib/python3.10/urllib/request.py”，第 519 行，打开
响应 = self._open(req, 数据)
文件“/usr/lib/python3.10/urllib/request.py”，第 536 行，在 _open
结果 = self._call_chain(self.handle_open, 协议, 协议 +
文件“/usr/lib/python3.10/urllib/request.py”，第 496 行，在 _call_chain
结果 = func(*args)
文件“/usr/lib/python3.10/urllib/request.py”，第 1391 行，位于 https_open
返回 self.do_open(http.client.HTTPSConnection, 请求,
文件“/usr/lib/python3.10/urllib/request.py”，第 1351 行，在 do_open
引发 URLError(err)
urllib.error.URLError: ]]></description>
      <guid>https://community.openai.com/t/whisper-showing-file-not-found-error-on-vs-code/596572#post_4</guid>
      <pubDate>Sat, 27 Jan 2024 05:50:50 GMT</pubDate>
    </item>
    <item>
      <title>使用标记/提示限制答案长度</title>
      <link>https://community.openai.com/t/limiting-answer-length-with-tokens-prompting/603492#post_4</link>
      <description><![CDATA[我发现它非常可靠。我确实通过手动验证过程定期检查样式，然后根据需要进行更改。
创建摘要后，我有额外的控件用于验证，但它们并不关注样式等，而是关注其他方面，例如无法正确生成摘要的情况。但从技术上讲，您可以部署让第二个模型根据某些标准审查摘要的策略。]]></description>
      <guid>https://community.openai.com/t/limiting-answer-length-with-tokens-prompting/603492#post_4</guid>
      <pubDate>Sat, 27 Jan 2024 05:50:27 GMT</pubDate>
    </item>
    </channel>
</rss>