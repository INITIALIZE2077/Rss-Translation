<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 12 Feb 2024 06:22:53 GMT</lastBuildDate>
    <item>
      <title>我想创建一个个人帐户，与我在雇主组织下拥有的帐户完全无关。我只有一个电话号码</title>
      <link>https://community.openai.com/t/i-want-to-create-a-personal-account-completely-unassociated-from-the-one-i-have-under-my-employers-organisation-i-only-have-one-phone-number/605197#post_6</link>
      <description><![CDATA[注册后立即获取电话号码。我不确定这是如何完成的以及您的手机是如何提供的。听起来这可能是在引入团队或企业版之前完成的，在这种情况下，这并不是真正的错误，您的公司应该适当升级。
如何使用您的电话号码为您创建帐户？同一家公司中已经拥有个人帐户的员工又如何？如果这一切都是正确的，我会和你的老板解释这一点。
也就是说，有一些只花费几美元的燃烧器编号也可以工作，但我无法负责链接。或者尝试将个人帐户的所有权授予您的工作帐户，并将组织从个人帐户中移出。我知道有人这样做并获得了无限的 gpt-3.5-turbo]]></description>
      <guid>https://community.openai.com/t/i-want-to-create-a-personal-account-completely-unassociated-from-the-one-i-have-under-my-employers-organisation-i-only-have-one-phone-number/605197#post_6</guid>
      <pubDate>Mon, 12 Feb 2024 06:17:26 GMT</pubDate>
    </item>
    <item>
      <title>RAG 的快速工程设计</title>
      <link>https://community.openai.com/t/prompt-engineering-for-rag/621495#post_17</link>
      <description><![CDATA[是的，我同意及时的工程可以产生很大的影响，特别是当用例涉及复杂语言或复杂任务的高风险时。我有 2 个不同的基于 RAG 的系统，用于两种不同类型的法律文件。对于每个系统，我的说明都是 5-6 句话长。对于我的系统来说，最重要的是严格根据可用文档回答问题。以下是我学到的一些东西：

作为说明的一部分，准确解释文档是什么以及文本来自何处会很有帮助。这为任务奠定了基础。例如，“以下是关于主题 X 的几条法律规则，它们是回答该问题最相关的规则。”
解释为什么应该做或不做某事非常有帮助。例如，一开始我指示我的系统要简洁，不要逐字重复法律术语。看起来这是一个很容易遵循的说明，对吧？然而，在我添加“因为读者可以访问所有文档的全文，并且如果他们愿意的话可以阅读整个内容”之后，反应要好得多。立刻，人工智能生成的答案变得更加简洁，措辞也更加简单。因为系统知道为什么我只需要一个简短的总结。
3.指导系统“如果你不知道答案”该说什么几乎会引发幻觉。相反，通过这样的指示将所需的响应与任务紧密联系起来：如果材料不相关或不够完整，无法自信地回答用户的问题，那么您的最佳响应是“材料似乎不足以提供良好的答案” .”
在撰写提示时，假装任务正在交给学生，而你是老师。为了得到你想要的回应，你会给出什么指示？更一般地说，我发现想象我的系统知道它是一个人工智能代理并没有什么帮助。将系统想象成一个人与另一个人交谈会更有帮助。
在一次迭代中，我什至试图通过说这是一项阅读理解测试来提示我的系统。就像 SAT 考试一样，学生只需根据前面的段落作答。仔细想想，RAG 系统与阅读理解测试有很多相似之处。我的提示不断演变，我放弃了 SAT 范式，但我发现在我的反复试验过程中以这种方式构建它非常有帮助，最终达到非常有效的提示。

希望这对您有所帮助。在指示系统产生您想要的输出类型时，这绝对是反复试验。]]></description>
      <guid>https://community.openai.com/t/prompt-engineering-for-rag/621495#post_17</guid>
      <pubDate>Mon, 12 Feb 2024 06:14:52 GMT</pubDate>
    </item>
    <item>
      <title>Chatgpt 没有从响应中删除几句话</title>
      <link>https://community.openai.com/t/chatgpt-not-removing-few-sentences-from-response/622948#post_1</link>
      <description><![CDATA[我希望 chatGPT 充当 slack-bot 来帮助解决 CICD 中的构建错误。我将以前的错误及其解决方案嵌入到矢量数据库中。这些决议也几乎没有内部文档链接。在我的提示中，我要求包含任何相关文档 URL，不包括 Jenkins URL（如果适用）。但是，当文档 URL 在上下文/引用中不可用时，chatgpt 会明确提及“不幸的是，与此确切错误相关的特定文档 URL 不可用。” 。我想避免在响应中出现此类或类似的行。
我试图明确要求 gpt 避免出现此类行，但它一直给出一些其他示例。
我应该如何调整我的提示以避免这种情况？]]></description>
      <guid>https://community.openai.com/t/chatgpt-not-removing-few-sentences-from-response/622948#post_1</guid>
      <pubDate>Mon, 12 Feb 2024 06:14:19 GMT</pubDate>
    </item>
    <item>
      <title>源代码字符数到标记的经验规则</title>
      <link>https://community.openai.com/t/rules-of-thumb-for-number-of-source-code-characters-to-tokens/622947#post_1</link>
      <description><![CDATA[我正在尝试估计各种编程语言的源代码文件（摘要）需要多少个令牌。
此映射有任何经验规则吗？对于自然语言来说，平均 1 个 token ~ 4 个字符。对于源代码来说这也合理吗？]]></description>
      <guid>https://community.openai.com/t/rules-of-thumb-for-number-of-source-code-characters-to-tokens/622947#post_1</guid>
      <pubDate>Mon, 12 Feb 2024 06:13:01 GMT</pubDate>
    </item>
    <item>
      <title>助理在会议之间坚持吗？并使用检索插件，即。让助手对其进行 api 调用</title>
      <link>https://community.openai.com/t/assistants-persist-between-sessions-and-using-the-retrieval-plugin-ie-getting-assistant-to-make-api-calls-to-it/622180#post_13</link>
      <description><![CDATA[这些答案只是复制粘贴还是您有经验？因为你听起来有点像个傻瓜，而人们只是在寻求帮助。该公司在那里推出产品和宣传的方式有点令人困惑。一切都被称为助手，所以根据人们何时参与，官方文档有点令人困惑。就连chatgpt也无法理解人们在说assistant和gpt时所指的是什么。
在寻求帮助时让人们感到难过并不是对齐人。未对齐。]]></description>
      <guid>https://community.openai.com/t/assistants-persist-between-sessions-and-using-the-retrieval-plugin-ie-getting-assistant-to-make-api-calls-to-it/622180#post_13</guid>
      <pubDate>Mon, 12 Feb 2024 06:07:28 GMT</pubDate>
    </item>
    <item>
      <title>助理在会议之间坚持吗？并使用检索插件，即。让助手对其进行 api 调用</title>
      <link>https://community.openai.com/t/assistants-persist-between-sessions-and-using-the-retrieval-plugin-ie-getting-assistant-to-make-api-calls-to-it/622180#post_12</link>
      <description><![CDATA[我不确定这意味着什么。如果您指的是端点助手，您可以将以前的线程包含到当前历史记录中以使模型能够感知，但如果您希望模型能够感知，则必须在当前提示中或作为对话历史记录的一部分发送训练数据之外的任何数据。&lt; /p&gt;
无状态意味着它不理解它所说的内容。或者没有记忆就意味着不知道。]]></description>
      <guid>https://community.openai.com/t/assistants-persist-between-sessions-and-using-the-retrieval-plugin-ie-getting-assistant-to-make-api-calls-to-it/622180#post_12</guid>
      <pubDate>Mon, 12 Feb 2024 06:00:31 GMT</pubDate>
    </item>
    <item>
      <title>GPT 不遵循说明</title>
      <link>https://community.openai.com/t/gpt-doesnt-follow-instructions/611259#post_14</link>
      <description><![CDATA[储备冷冻食品，以减轻 GPT 引起的沮丧造成的头部外伤后的肿胀。
答案是显而易见的，但我认为错误地提供数据来源是违反准则和道德实践的。也许购买企业模型并指导为新产品提供客户服务就是其价值的体现。]]></description>
      <guid>https://community.openai.com/t/gpt-doesnt-follow-instructions/611259#post_14</guid>
      <pubDate>Mon, 12 Feb 2024 05:56:55 GMT</pubDate>
    </item>
    <item>
      <title>最新功能（GPT 和助手）的数据隐私</title>
      <link>https://community.openai.com/t/data-privacy-for-latest-features-gpts-and-assistants/493023#post_8</link>
      <description><![CDATA[所有 OpenAI 条款和政策的入口点。
大部分 API 都遵循业务条款和使用政策。
ChatGPT GPT 和操作包含在单独的消费者条款中，因此无法直接比较。]]></description>
      <guid>https://community.openai.com/t/data-privacy-for-latest-features-gpts-and-assistants/493023#post_8</guid>
      <pubDate>Mon, 12 Feb 2024 05:54:40 GMT</pubDate>
    </item>
    <item>
      <title>GPT讨论——真的能赚钱吗？</title>
      <link>https://community.openai.com/t/gpts-discussion-can-you-really-make-money/596880?page=2#post_33</link>
      <description><![CDATA[数字如此之低，因为免责声明称数据被用于改进产品，这意味着他们只是审查信息，然后先发布它。 0.001 可能是 sams gpts。
他们在对我们撒谎，只是利用了人们一起玩的事实。]]></description>
      <guid>https://community.openai.com/t/gpts-discussion-can-you-really-make-money/596880?page=2#post_33</guid>
      <pubDate>Mon, 12 Feb 2024 05:46:02 GMT</pubDate>
    </item>
    <item>
      <title>为什么 ChatGPT 的情况每况愈下？</title>
      <link>https://community.openai.com/t/why-is-chatgpt-getting-from-bad-to-worst/617490#post_10</link>
      <description><![CDATA[我也经历了 GPT-4 的响应质量大幅下降（截至 2024 年 1 月）。为什么会发生这种情况？从它推出的第一天起，我就一直是付费客户（我的许多同事也是如此）。我们都很专业，并在工作中使用它，但看到回复质量大幅下降非常令人失望。请修复它！让它回到早期表现出色的日子。]]></description>
      <guid>https://community.openai.com/t/why-is-chatgpt-getting-from-bad-to-worst/617490#post_10</guid>
      <pubDate>Mon, 12 Feb 2024 05:45:30 GMT</pubDate>
    </item>
    <item>
      <title>谁在申请 Converge 2？</title>
      <link>https://community.openai.com/t/whos-applying-to-converge-2/564181?page=7#post_162</link>
      <description><![CDATA[有没有其他人意识到，在人工智能安全的情况下要求生成器进行预测与无意义是一样的。追求扩展知识通常超出了能力范围，而人工智能安全限制了该模型。我们本质上是要求重新考虑人们不同意的原始想法和陈述是错误的。现在请原谅我，因为我也很兴奋。即使在讨论超出培训日期但目前存在的新产品并且该模型也是有争议的。想象一下我们希望学到的东西。
这是一种炒作，人工智能安全是危险的。]]></description>
      <guid>https://community.openai.com/t/whos-applying-to-converge-2/564181?page=7#post_162</guid>
      <pubDate>Mon, 12 Feb 2024 05:42:44 GMT</pubDate>
    </item>
    </channel>
</rss>