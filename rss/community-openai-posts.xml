<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 14 Dec 2023 09:17:09 GMT</lastBuildDate>
    <item>
      <title>使用 chatgpt 获取 openai 文档</title>
      <link>https://community.openai.com/t/use-chatgpt-for-openai-documentation/548377#post_3</link>
      <description><![CDATA[&#39;…恐怕我必须积极地|不同意|有了这个……”]]></description>
      <guid>https://community.openai.com/t/use-chatgpt-for-openai-documentation/548377#post_3</guid>
      <pubDate>Thu, 14 Dec 2023 09:16:49 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 和 3.5 Turbo...不理解自己的 API</title>
      <link>https://community.openai.com/t/gpt-4-and-3-5-turbo-doesnt-understand-its-own-api/558250#post_1</link>
      <description><![CDATA[我会授予你【训练数据】和【训练数据】
当然……
那么为什么它不能浏览自己的文档呢？]]></description>
      <guid>https://community.openai.com/t/gpt-4-and-3-5-turbo-doesnt-understand-its-own-api/558250#post_1</guid>
      <pubDate>Thu, 14 Dec 2023 09:15:25 GMT</pubDate>
    </item>
    <item>
      <title>QQ：在tool_calls期间返回内容文本</title>
      <link>https://community.openai.com/t/qq-return-content-text-during-tool-calls/547000#post_3</link>
      <description><![CDATA[感谢您的回复，对于我迟到的回复深表歉意。
我正在测试您的示例，但我不喜欢当 GTP 触发多个函数时有多个 waiting_messages。
因此，进一步挖掘，我找到了另一种可能的解决方案（但会增加成本，因为完成了多次调用）：
当有函数需要排队时（因此还没有响应），我会在对这些函数的响应中使用以下文本重新提示 GPT：
“行动尚未完成。强制：通知用户此操作将需要几秒钟。”
通过这种方式，对于多个函数，我将只有一个响应，并且它位于同一输出流中，因此我不必单独管理这些东西。
然后，在该功能完成后，我再次使用新信息重新触发 GPT 交互，并且在我的测试中一切顺利。
如果有不清楚的地方或您的想法，请告诉我。]]></description>
      <guid>https://community.openai.com/t/qq-return-content-text-during-tool-calls/547000#post_3</guid>
      <pubDate>Thu, 14 Dec 2023 09:14:39 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 与主要新闻出版商 Axel Springer 合作</title>
      <link>https://community.openai.com/t/openai-partners-with-major-news-publisher-axel-springer/557375?page=2#post_34</link>
      <description><![CDATA[让我们尝试回答一些迄今为止我们收集到的最常见的问题：

还会有其他发布商与 OpenAI 合作吗？


该交易不具有排他性，其他发布商也可以签订类似协议。
显然，新闻集团目前正在深入讨论，以就如何将其内容用于生成人工智能达成一致。
我们已经与美联社 (AP) 达成了另一项协议，该协议已于 7 月达成。但是，情况有所不同，因为美联社正在许可其部分档案用于模型训练。反过来，AP 将“作为交易的一部分获得 OpenAI 的技术和产品专业知识”。这与与阿克塞尔·施普林格的交易不同，它与内容无关。但与 Axel Springer 的交易还包括 OpenAI 可以选择许可其模型训练内容。


这将如何实施？
我们只能在 2024 年第一季度真正知道何时推出。截至今天，我们可以从媒体报道中获得以下信息：


ChatGPT 将有权访问“选定的全球新闻内容”进行摘要，并提供来源链接。链接的来源实际上可能位于付费墙后面。
新闻摘要将实时更新。用户可以通过访问 ChatGPT 并询问最近的事件来取代互联网使用的其他部分。

我们了解到

目的之一是为合作伙伴增加流量。以这种方式包含内容的所有附加含义与赞助内容类似。
该解决方案与向发布商支付模型培训内容费用的解决方案集成。
这可能是将广告集成到常规 ChatGPT 对话中的一种前进方式

来源：

路透社
https ://www.reuters.com/business/media-telecom/global-news-publisher-axel-springer-partners-with-openai-landmark-deal-2023-12-13/
Politico（未由 ChatGPT 添加  )
媒体公司 Axel Springer 和 OpenAI 启动全球合作伙伴关系 – POLITICO&lt; /a&gt;
阿克塞尔·施普林格
Axel Springer 和 OpenAI 合作深化人工智能在新闻业中的有益应用 – Axel Springer SE
]]></description>
      <guid>https://community.openai.com/t/openai-partners-with-major-news-publisher-axel-springer/557375?page=2#post_34</guid>
      <pubDate>Thu, 14 Dec 2023 09:11:26 GMT</pubDate>
    </item>
    <item>
      <title>有谁知道如何删除我创建的微调模型？</title>
      <link>https://community.openai.com/t/does-anyone-know-how-to-delete-the-fine-tuning-models-i-created/558147#post_3</link>
      <description><![CDATA[我还可以确认无法删除它们。但同意这将是一个有用的功能。]]></description>
      <guid>https://community.openai.com/t/does-anyone-know-how-to-delete-the-fine-tuning-models-i-created/558147#post_3</guid>
      <pubDate>Thu, 14 Dec 2023 09:04:43 GMT</pubDate>
    </item>
    <item>
      <title>你能感觉到chatgpt-4变得又笨又懒吗？与以前相比，速度慢且答案质量低</title>
      <link>https://community.openai.com/t/can-you-feel-that-chatgpt-4-become-dumb-and-lazy-the-speed-is-slow-and-the-answer-is-low-quality-compared-before/558234#post_1</link>
      <description><![CDATA[你能感觉到chatgpt-4变得又笨又懒吗？与之前相比，速度慢且答案质量低]]></description>
      <guid>https://community.openai.com/t/can-you-feel-that-chatgpt-4-become-dumb-and-lazy-the-speed-is-slow-and-the-answer-is-low-quality-compared-before/558234#post_1</guid>
      <pubDate>Thu, 14 Dec 2023 09:03:07 GMT</pubDate>
    </item>
    </channel>
</rss>