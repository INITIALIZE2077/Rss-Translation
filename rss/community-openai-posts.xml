<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Fri, 09 Feb 2024 18:22:35 GMT</lastBuildDate>
    <item>
      <title>如何评估聊天对话（不仅仅是问答对）</title>
      <link>https://community.openai.com/t/how-to-evaluate-chat-conversations-not-just-question-answer-pairs/550023#post_2</link>
      <description><![CDATA[我们正在构建一个专门用于测试和评估动态对话的模拟测试平台。很想了解有关您的用例的更多信息并交流想法。]]></description>
      <guid>https://community.openai.com/t/how-to-evaluate-chat-conversations-not-just-question-answer-pairs/550023#post_2</guid>
      <pubDate>Fri, 09 Feb 2024 18:22:09 GMT</pubDate>
    </item>
    <item>
      <title>带response_format的Gpt-4-vision-preview</title>
      <link>https://community.openai.com/t/gpt-4-vision-preview-with-response-format/620476#post_1</link>
      <description><![CDATA[有谁知道是否有计划在 gpt-4-vision-preview 模型上包含 response_format 参数？我正在尝试从图像中提取结构化数据。]]></description>
      <guid>https://community.openai.com/t/gpt-4-vision-preview-with-response-format/620476#post_1</guid>
      <pubDate>Fri, 09 Feb 2024 18:16:31 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347?page=2#post_21</link>
      <description><![CDATA[


 wclayf：
&lt;块引用&gt;
但我想说的是，如果我知道问题的答案是什么，我就不需要问这个问题。


我假设他们这样做是为了测试模型。我有一整套充满针的文档语料库，用于评估我的系统性能]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347?page=2#post_21</guid>
      <pubDate>Fri, 09 Feb 2024 18:13:52 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_20</link>
      <description><![CDATA[您没有插入答案。大海捞针是一种在不同级别插入答案并查看模型能够检索答案的频率以确定模型失败的深度的技术（如图所示 @trenton.dambrowitz显示）
这个想法并不是要在最佳水平上“插入答案”，而是要意识到法学硕士倾向于“跳过”的深度]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_20</guid>
      <pubDate>Fri, 09 Feb 2024 18:12:50 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_19</link>
      <description><![CDATA[我知道，如果我在上下文（提示）中间插入我的问题的“答案”，人工智能更有可能找到该答案。但我想说的是，如果我知道问题的答案是什么，我就不需要问这个问题。]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_19</guid>
      <pubDate>Fri, 09 Feb 2024 18:11:38 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_18</link>
      <description><![CDATA[


 jr.2509：
&lt;块引用&gt;
对大量且可能多样化的文档库进行定制分析，对我个人而言，这就是法学硕士真正的增值来源。


这似乎是嵌入模型通过不同级别的文档捕获潜在关系的初步工作。然后，您可以使用法学硕士来尝试识别嵌入模型发现的关系。
请记住，某些嵌入模型（指示）可以被赋予与您希望找到的任何见解相匹配的“任务”
# 每个查询必须带有描述任务的一句话指令
任务=“给定一个网络搜索查询，检索回答该查询的相关段落”
查询 = [
   get_detailed_instruct(task, &#39;如何烘烤巧克力蛋糕&#39;),
   get_detailed_instruct(task, &#39;流感症状&#39;)
]
# 无需添加检索文档指令
段落=[
   “要烘焙美味的巧克力蛋糕，您需要以下成分：通用面粉、糖、可可粉、发酵粉、小苏打、盐、鸡蛋、牛奶、植物油和香草精。首先预热烤箱至 350°F (175°C)。在搅拌碗中，混合干成分（面粉、糖、可可粉、泡打粉、小苏打和盐）。在另一个碗中，将湿成分（鸡蛋、牛奶、植物油和香草精)。逐渐将湿混合物添加到干成分中，搅拌直至充分混合。将面糊倒入涂有油脂的蛋糕盘中，烘烤 30-35 分钟。让它冷却，然后撒上您最喜欢的巧克力糖霜糖霜。享受你自制的巧克力蛋糕吧！&quot;,
   “流感或流行性感冒是由流感病毒引起的疾病。流感的常见症状包括高烧、发冷、咳嗽、喉咙痛、流鼻涕或鼻塞、身体疼痛、头痛、疲劳，有时还包括恶心和呕吐。这些症状可能会突然出现，通常比普通感冒更严重。充分休息、补充水分非常重要，如果您怀疑自己患有流感，请咨询医疗保健专业人员。在某些情况下，抗病毒药物可以帮助缓解症状并缩短病程。”
]


  &lt;标题类=“来源”&gt;

      huggingface.co


  &lt;文章类=“onebox-body”&gt;
    
Salesforce/SFR-Embedding-Mistral · 拥抱脸
我们正在通过开源和开放科学推进人工智能并使之民主化。





我认为图形数据库在这里也可以创造奇迹。我曾考虑过创建角色表和环境的图形数据库，然后让法学硕士“抓取”它们，进行假设并创建“事件”（如果佛罗多在末日山遇到妖精并且他拥有魔戒，会发生什么） ）]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_18</guid>
      <pubDate>Fri, 09 Feb 2024 18:11:19 GMT</pubDate>
    </item>
    <item>
      <title>快准备好了，GTP 崩溃了，让我的自定义毫无价值</title>
      <link>https://community.openai.com/t/almost-ready-and-gtp-crashes-leaving-my-custom-worthless/618203#post_3</link>
      <description><![CDATA[它自行恢复，所以这是一个 chatgpt 打嗝。
这是个好主意，我也有一个表单保护程序/恢复插件，我也可以使用，想想看。保存并重命名，然后恢复就像打开并单击一样简单。我将它用于重要的事情，例如当我必须打印指纹并且不想丢失我输入的信息，因为我必须匆忙离开时。我很庆幸自己这么做了，因为回来后我必须重新开始。我将把它用于我的 gpt。
我想，如果你对它感兴趣的话，它被称为表单保护程序。当我可以回到电脑并仔细检查时，我会编辑此内容]]></description>
      <guid>https://community.openai.com/t/almost-ready-and-gtp-crashes-leaving-my-custom-worthless/618203#post_3</guid>
      <pubDate>Fri, 09 Feb 2024 18:08:24 GMT</pubDate>
    </item>
    <item>
      <title>我无法使用 GPT-4 版本。我正在付款</title>
      <link>https://community.openai.com/t/i-cant-use-the-gpt-4-version-i-am-paying/169061?page=4#post_70</link>
      <description><![CDATA[我已连续第四个月成为付费客户，并且我的付款顺利进行。现在 chatgpt 建议我升级到付费（但我已经付费了！）。
我从昨天开始就没有使用过，所以不可能超出配额。
另外，我付的是 24，现在好像是 20。]]></description>
      <guid>https://community.openai.com/t/i-cant-use-the-gpt-4-version-i-am-paying/169061?page=4#post_70</guid>
      <pubDate>Fri, 09 Feb 2024 17:58:52 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_17</link>
      <description><![CDATA[我对某些问答方法的挑战是它们着眼于狭隘定义的问题。通常，我并不是在寻找高度具体问题的答案，而是目标是根据文档中或跨文档中不同位置的信息创建见解，并需要了解信息之间的关系。
对大量且可能多样化的文档库进行定制分析，对我个人而言，这就是法学硕士真正的增值来源。]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_17</guid>
      <pubDate>Fri, 09 Feb 2024 17:58:28 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中存在强烈的种族偏见是怎么回事？</title>
      <link>https://community.openai.com/t/whats-with-the-strong-racial-bias-programmed-into-ai/619205#post_5</link>
      <description><![CDATA[如果总是存在造成分裂的偏见，你就不能期望平等和任何事情。某人的白色皮肤或棕色皮肤或红色头发或任何东西不应该以不会冒犯他人的方式被过滤或改写。现实和事实不会对任何人的感受产生任何想法或担忧。你认为狮子在攻击之前会考虑斑马的感受吗？不，这就是现实生活。]]></description>
      <guid>https://community.openai.com/t/whats-with-the-strong-racial-bias-programmed-into-ai/619205#post_5</guid>
      <pubDate>Fri, 09 Feb 2024 17:55:16 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_16</link>
      <description><![CDATA[


 wclayf：
&lt;块引用&gt;
但是我不明白如何利用它来改进所有可能问题的查询。 [...]这意味着您需要预先确定无限数量的答案并将其注入到内容中。


我不确定我明白你的意思



 wclayf：
&lt;块引用&gt;
但是我不明白如何利用它来改进所有可能问题的查询。


这个概念很简单。如果您要发送 118k 令牌的上下文，并且知道从 10% - 50% 的文档深度无法正确检索信息，那么您可以重复它。
这并不完美，但它肯定胜过幻觉/不正确的答案。
正如 @stevenic 已经暗示的那样，最好使用较小的上下文大小。但我们发现了一个问题，并找到了一个“不完整”的解决方案。
如果您花更多时间查看 Github，您会看到可以运行的 Jupyter Notebooks，它将回答您的所有问题。]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_16</guid>
      <pubDate>Fri, 09 Feb 2024 17:55:02 GMT</pubDate>
    </item>
    <item>
      <title>人工智能中存在强烈的种族偏见是怎么回事？</title>
      <link>https://community.openai.com/t/whats-with-the-strong-racial-bias-programmed-into-ai/619205#post_4</link>
      <description><![CDATA[给我一​​张照片，照片上是一个拥有强壮腹肌的白人男性骑着一头黑豹。黑豹在咆哮。轰鸣声呈心电图扫描心跳的形状。
它不会将白人输入任何内容，甚至很难输入白人，然后在照片上显示一个黑人种族的人。怎样才算没有偏见呢？这并不是基于当今政治正确性的任何现实。这不是人工智能，而是高级智能，因为它是用展望和偏见进行编程的。现实一点]]></description>
      <guid>https://community.openai.com/t/whats-with-the-strong-racial-bias-programmed-into-ai/619205#post_4</guid>
      <pubDate>Fri, 09 Feb 2024 17:53:28 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_15</link>
      <description><![CDATA[如果特定问题的特定答案恰好位于文档中，就在文档的中间，这是有道理的。然而，我不知道如何利用它来改进所有可能问题的查询。这意味着您需要预先确定并注入内容中的无数答案。也许我读得太快了，但我不明白它如何用于一般用途。]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_15</guid>
      <pubDate>Fri, 09 Feb 2024 17:50:57 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 与 Google Gemini Ultra</title>
      <link>https://community.openai.com/t/chatgpt-vs-googles-gemini-ultra/620454#post_1</link>
      <description><![CDATA[刚刚订阅了 Google Gemini Ultra，我非常失望，这绝对是个笑话。有人试过吗？]]></description>
      <guid>https://community.openai.com/t/chatgpt-vs-googles-gemini-ultra/620454#post_1</guid>
      <pubDate>Fri, 09 Feb 2024 17:50:23 GMT</pubDate>
    </item>
    <item>
      <title>处理大型文档 - 128K 限制</title>
      <link>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_14</link>
      <description><![CDATA[我希望有一个技巧可以让您回答针对如此大的文档的复杂查询，但我们使用了十几个技巧。例如，年度报告中可能有财务表格。这些模型缺乏空间意识，因此它们可能会混淆所有数字。我们有一些技巧可以弥补这一点。从我们的数据摄取管道到向量数据库再到推理层，所有内容都是自定义的，并针对您指定的特定类型的复杂查询进行了调整。]]></description>
      <guid>https://community.openai.com/t/processing-large-documents-128k-limit/620347#post_14</guid>
      <pubDate>Fri, 09 Feb 2024 17:44:49 GMT</pubDate>
    </item>
    </channel>
</rss>