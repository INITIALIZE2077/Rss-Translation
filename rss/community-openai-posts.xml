<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 20 Feb 2024 15:17:58 GMT</lastBuildDate>
    <item>
      <title>Chatgpt 韩语语音功能很糟糕</title>
      <link>https://community.openai.com/t/chatgpt-voice-feature-in-korean-is-pretty-bad/643307#post_1</link>
      <description><![CDATA[我构建了一个自定义 gpt，其操作使用 ChatGPT 检索插件 FastAPI 服务器来查询包含来自 TOPIK 测试（韩语水平）的语法和词汇的 Supabase 数据库，这样我就可以在 Chrome 浏览器中练习使用 Talk-to-GPT，从键盘上将 Google 语音转为文本（这会拾取语音转文本，唯一的问题是没有语音回复），然后尝试使用 ChatGPT 提供的语音（未检查是否添加了韩语头像）。
我还将矢量化材料作为 .txt 文件上传，它会查找语法以开始课程，然后查询数据库以提供更多形式的课程。
不，选择了以韩语为主要语言的 Juniper，这听起来像是一个非常流利的外国人，即。口音依然存在。而且我讨厌语音气泡动画，为什么不像卡拉 OK 那样，声音跟踪输出文本呢？]]></description>
      <guid>https://community.openai.com/t/chatgpt-voice-feature-in-korean-is-pretty-bad/643307#post_1</guid>
      <pubDate>Tue, 20 Feb 2024 15:12:53 GMT</pubDate>
    </item>
    <item>
      <title>人工智能虚拟现实（AIVR）和研究可能吗？</title>
      <link>https://community.openai.com/t/is-ai-virtual-reality-aivr-and-research-possible/643305#post_1</link>
      <description><![CDATA[问题：

有人可以订购吗？在营利性公司中播放一段10分钟的视频，其内容（专业或教育或娱乐或治疗等内容。）由他确定，以便在在线收到视频后，佩戴一副VR眼镜和耳机（有或没有交互），他能否沉浸在虚拟的三维世界中，并拥有日常生活中真实尺寸的 3D 图像？
我们知道，如果我们向每只眼睛发送与其自己的观察角度相关的相应图像，即两个略有不同的图像（立体镜-立体镜），而不是一个图像，那么这很容易实现。是不是也可以在电影院、培训室集体进行，有集体参与的乐趣？
是否可以借助几分钟的人工智能视频，制作各种语言的互动个性化课程，以扫除文盲并进行专业培训？例如个性化的机器和车辆操作培训；
ASI 是否有可能在 10 或 20 年后解决未解决的问题，例如在医学、物理、数学、化学、生物学、社会学、心理学、政治学以及人文和艺术领域，今天都无法找到解决方案；例如未解决的数学问题、超弦理论、癌症等疑难杂症、热热聚变等？
10 到 20 年后，AGI 能否凭借一批机器人将沙漠改造成巨大的光伏园区，为全球能源问题提供解决方案？
ASI 可以通过检查过多的数据来回答我们宇宙中众多智慧生物的问题吗？
等等，等等，等等？
]]></description>
      <guid>https://community.openai.com/t/is-ai-virtual-reality-aivr-and-research-possible/643305#post_1</guid>
      <pubDate>Tue, 20 Feb 2024 15:11:47 GMT</pubDate>
    </item>
    <item>
      <title>图片提示限制</title>
      <link>https://community.openai.com/t/image-prompting-limitation/643256#post_3</link>
      <description><![CDATA[


杰西罗梅利：
&lt;块引用&gt;
底部是 ATOMS，分支应仅标记为：
元素：
分子：
离子和共价化合物：
金属和金属粘接：
混合物：
水晶：
高分子和聚合物：


也许让人工智能使用确定性工具来绘制此类事物会更好。
图 TD
    原子 --&gt;元素
    元素--&gt;分子
    分子 --&gt;|“两种类型”|离子和共价化合物
    离子和共价化合物 --&gt;离子化合物
    离子和共价化合物 --&gt;共价化合物
    分子 --&gt;|“也导致”|金属和金属结合
    金属和金属结合 --&gt;金属
    金属和金属结合 --&gt;金属接合
    分子--&gt;混合物
    混合物--&gt;水晶
    分子--&gt;高分子与聚合物
    高分子和聚合物 --&gt;高分子
    高分子和聚合物 --&gt;聚合物

    classDef 分支填充：#f9f，描边：#333，描边宽度：2px；
    原子、元素、分子、离子和共价化合物、金属和金属键合、混合物、晶体、高分子和聚合物分支；

]]></description>
      <guid>https://community.openai.com/t/image-prompting-limitation/643256#post_3</guid>
      <pubDate>Tue, 20 Feb 2024 15:09:24 GMT</pubDate>
    </item>
    <item>
      <title>GPT 突然无法读取其知识库中的文件</title>
      <link>https://community.openai.com/t/gpt-suddenly-cant-read-files-in-its-knowledge-base/578576?page=3#post_48</link>
      <description><![CDATA[是的，仍然是“我目前无法直接搜索文档。但是，根据标准实践和我现有的知识......”这是我在过去 3 天得到的答复。令人惊讶的是，这种情况持续了这么长时间，OpenAI 却没有任何回应。
专用 GPT 非常棒，我的工作流程已经越来越依赖它们来快速有效地管理大量信息。希望这个问题尽快得到解决]]></description>
      <guid>https://community.openai.com/t/gpt-suddenly-cant-read-files-in-its-knowledge-base/578576?page=3#post_48</guid>
      <pubDate>Tue, 20 Feb 2024 15:03:13 GMT</pubDate>
    </item>
    <item>
      <title>无效 api 密钥的问题</title>
      <link>https://community.openai.com/t/issues-with-invalid-api-key/642946#post_2</link>
      <description><![CDATA[我建议使用 API 参考中的一些非常简单的 Python 示例来完成聊天，以便在转移到另一个平台或未知代码并诊断使用情况之前在本地计算机上进行调用。


检查您正在使用的 API 密钥是否位于您的 OpenAI 资金账户中。它们以“sk-...”https://platform.openai.com/api-keys 开头


从官方下载安装程序或操作系统包管理器安装 Python 3.8-3.11


尝试我发布的聊天机器人演示，不需要更多的库。 无法获取 openai python 包工作...请帮忙！ - #11 by _j - 将其保存到 chatbot.py 并运行。


最后，您可以将操作系统环境变量 OPENAI_API_KEY 设置为密钥值，也可以将整个 {os.environ.get(&#39;OPENAI_API_KEY&#39;)} 替换为实际密钥文本。
然后你可以帮助我们弄清楚“即使是在replit上上传的文档在OpenAI平台上也是可见的”可能意味着什么，或者你在哪里看到这样的事情。不要将您的 API 密钥放入其他不受信任的网站或软件中......]]></description>
      <guid>https://community.openai.com/t/issues-with-invalid-api-key/642946#post_2</guid>
      <pubDate>Tue, 20 Feb 2024 15:03:03 GMT</pubDate>
    </item>
    </channel>
</rss>