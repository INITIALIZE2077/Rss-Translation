<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Fri, 26 Jan 2024 06:23:06 GMT</lastBuildDate>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_6</link>
      <description><![CDATA[


 curt.kennedy:
&lt;块引用&gt;
这将允许您以任意的一次一维的粒度调整延迟和交易质量，这非常疯狂！


读到这里，我的第一个想法是不要进行截断，而是如果您在最高维度上有足够大的嵌入向量集，这些向量都来自相同（或相似）的知识领域，您可能会采用一些标准（但比截断更复杂）降维技术。
这可能有利于在较低维度上保持相对较高的性能，以便在该知识领域内进行嵌入。
而且，由于您保留了所有原始的全维向量，因此当您收集更多嵌入时，您可以定期离线重新计算向量约简......]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_6</guid>
      <pubDate>Fri, 26 Jan 2024 06:19:39 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_5</link>
      <description><![CDATA[这让我想起我们必须检查的另一件事，就是这些新模型是否具有真正相关的嵌入。
这将影响“不相关”的阈值，因为 ada-002 的阈值曾经接近 &lt;0.9。
但现在空间可能更加各向同性，锥体也更大。我们拭目以待！]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_5</guid>
      <pubDate>Fri, 26 Jan 2024 06:16:44 GMT</pubDate>
    </item>
    <item>
      <title>请取消您的付费客户的 Plus 限制！</title>
      <link>https://community.openai.com/t/please-remove-the-plus-limit-for-your-paying-customers/587997#post_12</link>
      <description><![CDATA[我同意你的观点，当我只支付 20 美元进行升级，几个小时后我得到“您已达到当前使用上限”时，我感到多么惊讶，就像 WTF 我只支付 20 美元一样，这将是他们从我这里得到了第一和最后 20 美元，这是肯定的。]]></description>
      <guid>https://community.openai.com/t/please-remove-the-plus-limit-for-your-paying-customers/587997#post_12</guid>
      <pubDate>Fri, 26 Jan 2024 06:16:33 GMT</pubDate>
    </item>
    <item>
      <title>ChatGPT 中家长控制子账户的提案</title>
      <link>https://community.openai.com/t/proposal-for-parent-controlled-sub-accounts-in-chatgpt/602308#post_1</link>
      <description><![CDATA[“亲爱的 OpenAI 团队，我建议在 ChatGPT 中引入家长控制的帐户系统。该系统将允许家长为孩子创建和管理子帐户，从而在独立学习和家长监督之间提供平衡。这样该功能将确保儿童以教育和安全的方式使用 ChatGPT，同时防止误用，例如使用人工智能进行不适当的活动或在没有适当学习的情况下完成家庭作业。这可能是现代数字育儿的一个有价值的工具，鼓励负责任地使用人工智能教育技术。您将来有计划实现这样的功能吗？感谢您考虑我的建议。最诚挚的问候，Sigmar]]></description>
      <guid>https://community.openai.com/t/proposal-for-parent-controlled-sub-accounts-in-chatgpt/602308#post_1</guid>
      <pubDate>Fri, 26 Jan 2024 06:11:47 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_4</link>
      <description><![CDATA[所以……
我们需要多长时间才能计算出嵌入空间的锥角？]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_4</guid>
      <pubDate>Fri, 26 Jan 2024 06:11:37 GMT</pubDate>
    </item>
    <item>
      <title>助手 API - 访问多个助手</title>
      <link>https://community.openai.com/t/assistants-api-access-to-multiple-assistants/480503?page=2#post_26</link>
      <description><![CDATA[我在实现类似解决方案时面临的一个主要问题是延迟，这种来回通信和自定义函数调用占用了很多时间。
我什至通过聊天完成实现了类似的流程，以便我可以进行流式传输，但到达第一个令牌的时间仍然在 20 秒左右。]]></description>
      <guid>https://community.openai.com/t/assistants-api-access-to-multiple-assistants/480503?page=2#post_26</guid>
      <pubDate>Fri, 26 Jan 2024 05:59:47 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_3</link>
      <description><![CDATA[是的，您可以屏蔽，但您必须将未屏蔽的子向量长度重新调整为 1，然后才能使用余弦相似度（点积）。在屏蔽之后，这只是内存结构中每个向量的 1 个附加数字，所以没什么大不了的。 &lt;img alt=&quot;:rofl:&quot; class=&quot;emoji&quot; height=&quot;20&quot; src=&quot;https://emoji.discourse-cdn.com/twitter/rofl.png?v=12&quot; title=&quot;:rofl: “宽度=“20”/&gt;
只是新模型都是继承自同一个大“母模型”，并且可以很容易地从这个大模型派生出来。
我不确定这对 MTEB 有何影响，但该出版物表明，随着尺寸的下降，MTEB 会逐渐退化。这意味着任意维度都是相似的。
这表明，OpenAI 以向量的开头包含最多信息的方式传播信息，并且随着维度变大，它会逐渐减少，或者可能是均匀的，我可以&#39;不告诉。也许它是锥形的，以提供良好的低暗性能。
但是信息不仅仅集中在大向量的远端，这就是为什么它们可以简单地截断。
您可能会尝试使用其他嵌入模型进行此操作，并且它也可能适用于该模型，但如果信息集中在向量中意想不到的地方，并且没有正确设计，就像这些 OpenAI 向量一样，您可能会得到奇怪的结果。
从 DevOps 的角度来看。只需将所有内容嵌入 3072（或任何最高暗度），当您创建内存中分片时，只需截断/重新缩放即可创建具有该暗度的系统。
对于传入的查询，执行相同的操作，截断/重新缩放以匹配您选择的任意维度的 RAG 向量集。
这将允许您以任意的一次一维的粒度调整延迟和交易质量，这非常疯狂！]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_3</guid>
      <pubDate>Fri, 26 Jan 2024 05:58:06 GMT</pubDate>
    </item>
    <item>
      <title>看起来“text-embedding-3”嵌入是从更高的暗淡版本中截断/缩放的版本</title>
      <link>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_2</link>
      <description><![CDATA[这是一个很酷的想法，使用掩码来预先计算较小尺寸的距离。如果你受CPU限制，如果你在N个暗淡之后没有接近你的截止点，你可以中止余弦相似度操作 ]]></description>
      <guid>https://community.openai.com/t/it-looks-like-text-embedding-3-embeddings-are-truncated-scaled-versions-from-higher-dim-version/602276#post_2</guid>
      <pubDate>Fri, 26 Jan 2024 05:47:17 GMT</pubDate>
    </item>
    <item>
      <title>设置输出问题的最大令牌</title>
      <link>https://community.openai.com/t/setting-max-tokens-for-output-issues/601731#post_5</link>
      <description><![CDATA[


_j：
&lt;块引用&gt;
因为该设置不会以任何方式告知模型要构造什么类型的响应。


很公平。



_j：
&lt;块引用&gt;
如果你想要一个长度，分解任务的最好方法是“三段，平均每段十个单词”或类似的指令。


对于针对特定长度的更多人来说，这是可靠的建议。就我个人而言，对于简短的回复，我通常会采取类似的措辞，“你的回复必须尖锐、简洁、简洁。”]]></description>
      <guid>https://community.openai.com/t/setting-max-tokens-for-output-issues/601731#post_5</guid>
      <pubDate>Fri, 26 Jan 2024 05:46:41 GMT</pubDate>
    </item>
    <item>
      <title>开源正在快速进步</title>
      <link>https://community.openai.com/t/open-source-is-making-rapid-progress/593393#post_10</link>
      <description><![CDATA[开源与“专有”模型的​​争论将永远持续 …我最近刚刚参加了供应商培训，这是课程的一部分。比较和对比，列出开源模型和供应商特定模型（专有）之间的优缺点……作为“专有”模型的​​示例，例如 OpenAi 提供的模型，其优点如下：

开发速度
质量
持续更新和支持
集成且易于使用
]]></description>
      <guid>https://community.openai.com/t/open-source-is-making-rapid-progress/593393#post_10</guid>
      <pubDate>Fri, 26 Jan 2024 05:44:18 GMT</pubDate>
    </item>
    </channel>
</rss>