<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 05 Feb 2024 15:18:31 GMT</lastBuildDate>
    <item>
      <title>兼具“检索”与“功能”的助手</title>
      <link>https://community.openai.com/t/assistants-with-both-retrieval-and-function/530158?page=2#post_23</link>
      <description><![CDATA[感谢您分享这些有用的提示和技巧。]]></description>
      <guid>https://community.openai.com/t/assistants-with-both-retrieval-and-function/530158?page=2#post_23</guid>
      <pubDate>Mon, 05 Feb 2024 15:18:09 GMT</pubDate>
    </item>
    <item>
      <title>我的训练数据需要与我的提示排序有多接近才能使微调有效？</title>
      <link>https://community.openai.com/t/how-closely-does-my-training-data-need-to-match-my-prompt-sequencing-for-fine-tuning-to-be-effective/615172#post_1</link>
      <description><![CDATA[我有一个生成博客文章的系统。用户流程以关键字开始，然后建议标题，然后是大纲，最后是最终草稿。其间还有其他阶段。
早期我们在输出超过 1,000 字的长篇文章时遇到了问题，所以现在我们逐节生成它们，然后在最后将它们缝合在一起。一直运作良好。
我的问题是，训练数据需要与我们当前的提示结构/排序有多紧密地映射？
考虑到我们当前的逐节方法，我们似乎需要对文章部分进行训练，而不是整篇文章。我其实很喜欢。然而，我不确定的是我是否可以在没有“系统”和“用户”提示的情况下单独训练这些部分（因为有很多。）
我需要向 GPT 提供多少上下文（如果有）以及我的训练数据？我的 GPT 负载中的 [messages] 元素需要与我当前的实际结构有多接近？]]></description>
      <guid>https://community.openai.com/t/how-closely-does-my-training-data-need-to-match-my-prompt-sequencing-for-fine-tuning-to-be-effective/615172#post_1</guid>
      <pubDate>Mon, 05 Feb 2024 15:15:59 GMT</pubDate>
    </item>
    <item>
      <title>gpt-4-1106-vision-preview 也变得懒惰了吗</title>
      <link>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_6</link>
      <description><![CDATA[突然，我遇到了 gpt-4-1106-vision-preview 的问题。与我早期使用该模型时相比，数据准确性较低。我该如何解决这个问题？]]></description>
      <guid>https://community.openai.com/t/is-gpt-4-1106-vision-preview-also-getting-lazy/611557#post_6</guid>
      <pubDate>Mon, 05 Feb 2024 15:14:42 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 每次更新都变得越来越糟糕</title>
      <link>https://community.openai.com/t/gpt-4-is-getting-worse-and-worse-every-single-update/508470?page=11#post_216</link>
      <description><![CDATA[今年太糟糕了…一直在用它曾经擅长的代码完成任务（比如简单的查询，或者修复非常快速的脚本，它永远不会记住事情，它提供了大量的解释和选项，没有代码…甚至当被明确告知否则......然后当你让它按照你想要的格式明智地执行时，它实际上会忘记所有重要的上下文哈哈 - 我希望他们尽快解决这个问题......]]></description>
      <guid>https://community.openai.com/t/gpt-4-is-getting-worse-and-worse-every-single-update/508470?page=11#post_216</guid>
      <pubDate>Mon, 05 Feb 2024 15:11:09 GMT</pubDate>
    </item>
    <item>
      <title>如何将现有团队关联到 ChatGPT+ 的团队工作区</title>
      <link>https://community.openai.com/t/how-do-i-associate-my-existing-team-to-a-team-workspace-for-chatgpt/612913#post_3</link>
      <description><![CDATA[所以，本质上，我必须管理两个不同的团队？咬人。
为什么不简化我们双方的簿记工作，让我拥有的单一组织同时为这两项服务工作？
这并不难，我们在这里做。 &lt;img alt=&quot;:wink:&quot; class=&quot;emoji&quot; height=&quot;20&quot; src=&quot;https://emoji.discourse-cdn.com/twitter/wink.png?v=12&quot; title=&quot;:wink: “宽度=“20”/&gt;
这不仅会让我的生活更轻松，也会让你们团队的生活更轻松。
斯科特·约翰逊]]></description>
      <guid>https://community.openai.com/t/how-do-i-associate-my-existing-team-to-a-team-workspace-for-chatgpt/612913#post_3</guid>
      <pubDate>Mon, 05 Feb 2024 15:06:47 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 每次更新都变得越来越糟糕</title>
      <link>https://community.openai.com/t/gpt-4-is-getting-worse-and-worse-every-single-update/508470?page=10#post_215</link>
      <description><![CDATA[来这里是为了同意其他人的观点。我已经使用 GPT-4 来处理软件工程、人工智能和机器学习方面的一些繁重任务，以及总结科学论文已有 5 个月了。我注意到今年一月份以来情况出现了巨大的退化。我偶尔会收到一些随机回复，例如“我无法满足您的要求”，只有在我回答“嗯？”后才能得到正确的答案。类似 GPT3 的幻觉也开始出现在不缺乏信息或背景的地方。最后，仅在几条消息中讨论了请求的一些选择性内存丢失。
我是一名人工智能硕士学生，GPT-4 的明显退化一直是最近课堂上讨论的话题。]]></description>
      <guid>https://community.openai.com/t/gpt-4-is-getting-worse-and-worse-every-single-update/508470?page=10#post_215</guid>
      <pubDate>Mon, 05 Feb 2024 15:05:46 GMT</pubDate>
    </item>
    <item>
      <title>每个 GPT 模型的最大响应长度（输出令牌）是多少？</title>
      <link>https://community.openai.com/t/what-is-the-maximum-response-length-output-tokens-for-each-gpt-model/524066#post_5</link>
      <description><![CDATA[对此的一些新发现：
可用的文档来源不一致


模型文档提到了4096输出令牌许多型号。


游乐场最多提供 4095 个输出令牌。


向 API 传递过大的 max_tokens 值时，错误消息提到 4097 输出令牌：
$curl https://api.openai.com/v1/chat/completions -H“内容类型：application/json”-H“授权：承载$OPENAI_API_KEY” -d&#39;{
    “型号”：“gpt-3.5-turbo-0613”，
    “消息”：[
      {
        “角色”：“系统”，
        “内容”：“嗨”
      }
    ],
    “最大令牌”：4097
  }&#39;
{
  “错误”： {
    &quot;message&quot;: &quot;此模型的最大上下文长度为 4097 个令牌。但是，您请求了 4105 个令牌（消息中为 8 个，完成中为 4097 个）。请减少消息或完成中的长度。&quot;,
    “类型”：“无效请求错误”，
    “参数”：“消息”，
    “代码”：“超过上下文长度”
  }
}



最大响应长度取决于输入的大小
与我假设的不同，输入和输出共享相同的 max_tokens 限制。正如游乐场所说：
&lt;块引用&gt;
提示和完成之间共享的生成令牌的最大数量。确切的限制因型号而异。

尝试根据经验确定最大响应长度
到目前为止，我尝试了两种方法但没有成功：

使用 logit_bias 在任何地方强制使用单个标记（例如 {&#39;70540&#39;: 100}）：不幸的是，当我使用 100 个标记时，输出总是被截断使用 gpt-3.5-turbo 模型（即使将 max_tokens 设置为更高的值）。
提供随机输入并将温度设置为2：虽然这通常会导致“无限”输出，因为模型会在没有良好停止点的情况下生成令人难以置信的文本，但我无法达到完整响应长度为 4096 个令牌。
]]></description>
      <guid>https://community.openai.com/t/what-is-the-maximum-response-length-output-tokens-for-each-gpt-model/524066#post_5</guid>
      <pubDate>Mon, 05 Feb 2024 15:05:05 GMT</pubDate>
    </item>
    <item>
      <title>指令大小和线程长度对 OpenAI Assistant 中令牌使用的影响</title>
      <link>https://community.openai.com/t/impact-of-instruction-size-and-thread-length-on-token-usage-in-openai-assistant/581099#post_7</link>
      <description><![CDATA[不确定何时添加，但现在我看到特定运行中的令牌使用情况。
您正在接收有关检索运行端点的使用数据（运行必须完成）： https://platform.openai.com/docs/api-reference/runs/object#runs/object-usage。
现在看起来计算起来非常简单。
根据我的测试，说明+附加文件在每次运行时都算作输入令牌。]]></description>
      <guid>https://community.openai.com/t/impact-of-instruction-size-and-thread-length-on-token-usage-in-openai-assistant/581099#post_7</guid>
      <pubDate>Mon, 05 Feb 2024 15:01:55 GMT</pubDate>
    </item>
    <item>
      <title>您已达到 GPT-4 的当前使用上限，请在下午 2:04 后重试</title>
      <link>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=14#post_275</link>
      <description><![CDATA[15！！！提示，我数了一下，现在又要等两个小时才能使用？！！
更改此设置，否则我将取消并仅使用 3.5 模型，这对我来说没有太大区别]]></description>
      <guid>https://community.openai.com/t/youve-reached-the-current-usage-cap-for-gpt-4-please-try-again-after-2-04-pm/494628?page=14#post_275</guid>
      <pubDate>Mon, 05 Feb 2024 14:52:43 GMT</pubDate>
    </item>
    <item>
      <title>我正在创建一个 gpt，但它一直在胡言乱语</title>
      <link>https://community.openai.com/t/i-am-creating-a-gpt-and-it-keeps-spewing-nonsense/615141#post_1</link>
      <description><![CDATA[每次我回家后，无论我是否刷新，它都会在聊天窗口中喷出命令，而不是显示“正在更新 gpt...”的小扳手图标
*剪断*
})

接收者必须采用“工具名称.函数名称”的形式。

我目前无法按预期更新行为。让我们继续执行您想要的下一个任务，我将继续协助您完成该任务。
]]></description>
      <guid>https://community.openai.com/t/i-am-creating-a-gpt-and-it-keeps-spewing-nonsense/615141#post_1</guid>
      <pubDate>Mon, 05 Feb 2024 14:52:11 GMT</pubDate>
    </item>
    </channel>
</rss>