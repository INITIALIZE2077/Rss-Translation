<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 28 Mar 2024 01:11:13 GMT</lastBuildDate>
    <item>
      <title>Chatgpt 助理直播</title>
      <link>https://community.openai.com/t/chatgpt-assistant-streaming/700038#post_1</link>
      <description><![CDATA[我在使用 chatgpt 助手（在流式传输时）调用函数时遇到问题。
我无法获取函数的参数，它总是返回空。
这是我的一些代码片段
我正在尝试调用一个名为 image_describe 的函数
这是我获得的快照
FunctionToolCall(id=&#39;call_************&#39;, function=Function(arguments=&#39;{&quot;&#39;, name=&#39;image_describe&#39;, 输出=None), type=&#39;function&#39;, index= 0)
类EventHandler(AssistantEventHandler):
  @覆盖
  def on_text_created(self, text) -&gt;;没有任何：
    打印（f“\ nassistant＆gt;”，结束=“”，flush=True）
      
  @覆盖
  def on_text_delta(自身、增量、快照)：
    打印（delta.value，end =“”，flush = True）
      
  def on_tool_call_created(self, tool_call):
    打印（工具调用）
    print(f&quot;\nassistant &gt; {tool_call.type}\n&quot;,flush=True)

  def on_tool_call_delta(自身，增量，快照)：
    运行=client.assistant.retrieve(
       Assistant_id=助理ID
    ）
    打印（运行）
    参数=json.loads(snapshot.function.arguments)
    arg=delta.函数
    参数=自身
    打印（自己）
    工具输出=[]
    如果 delta.type == &#39;code_interpreter&#39;:
      如果 delta.code_interpreter.input：
        打印（delta.code_interpreter.input，end =“”，flush = True）
      如果 delta.code_interpreter.outputs：
        打印（f“\n\n输出&gt;”，flush=True）
        对于 delta.code_interpreter.outputs 中的输出：
          如果输出类型==“日志”：
            打印(f&quot;\n{output.logs}&quot;,flush=True)
            
    如果 delta.type == &quot;函数&quot;:
        function_name=快照.函数.名称
        参数=快照.函数.参数
        如果函数名称==“图像描述”：
                图像路径=参数[“图像路径”]




与 client.beta.threads.runs.create_and_stream(
  thread_id=线程.id,
  Assistant_id=助手.id,
  event_handler=EventHandler(),
) 作为流：
  流.until_done()



  而真实：

    # 用户输入=get_input()
    user_input=input(&quot;\n 你:&quot;)
    消息 = client.beta.threads.messages.create(
        thread_id = 线程.id,
        角色=“用户”，
        内容=用户输入
    ）

    与 client.beta.threads.runs.create_and_stream(
        thread_id=线程.id,
        Assistant_id=助理.id,
        event_handler=EventHandler(),
    ) 作为流：
        对于流中的事件：
        # 打印文本增量事件中的文本
            尝试 ：
                如果 event.type == &quot;thread.message.delta&quot; 和 event.data.delta.content:
                    打印（事件.data.delta.content[0].text）
            除了 ：
                  流.until_done()

]]></description>
      <guid>https://community.openai.com/t/chatgpt-assistant-streaming/700038#post_1</guid>
      <pubDate>Thu, 28 Mar 2024 00:55:42 GMT</pubDate>
    </item>
    <item>
      <title>无法购买 API 积分</title>
      <link>https://community.openai.com/t/unable-to-purchase-api-credits/700027#post_1</link>
      <description><![CDATA[我是一名 5 级用户，过去曾多次成功付款。但是当我尝试在新系统下购买 OpenAI API 积分时，出现错误：
&lt;块引用&gt;
我们无法处理您的付款。如果此问题仍然存在，请通过我们的帮助中心联系我们：https://help.openai.com。 

我尝试了多张信用卡，但所有信用卡都抛出此错误。
有人解决了吗？]]></description>
      <guid>https://community.openai.com/t/unable-to-purchase-api-credits/700027#post_1</guid>
      <pubDate>Thu, 28 Mar 2024 00:34:05 GMT</pubDate>
    </item>
    <item>
      <title>RAG 并不是真正的解决方案</title>
      <link>https://community.openai.com/t/rag-is-not-really-a-solution/599291#post_14</link>
      <description><![CDATA[


 vidyasagar.mundroy：
&lt;块引用&gt;
事实上，我已经使用 LlamaIndex 实现了一个基于 RAG 的快速玩具聊天机器人，提供了四个肯定用于训练 LLM (gemini-pro) 的 PDF 文档，并且聊天机器人正确回答了七个问题中的五个。


几个月以来，我一直致力于相当传统的 RAG 实现。很少有正确格式的问题没有得到回答的情况，也从来没有出现幻觉的情况。但是，这不会凭空发生——开发 RAG 系统可以产生始终如一的良好结果，为此我们付出了大量的工作。
首先，执行 @curt.kennedy 建议的所有操作。
您不能只是以任何旧的方式分割文本，然后期待智能答案。我个人使用我自己版本的语义分块 https: //www.youtube.com/watch?v=w_veb816Asg&amp;t=1s&amp;pp=ygUOc2VtYW50aWMgY2h1bms%3D
但是，如果您在 YouTube 上搜索“语义分块”，您会发现许多不同的教程，介绍如何对数据进行分块，从而使其在查询中更加有用。
此外，当您说它回答了 7 个问题中的 5 个问题时，它没有回答的两个问题是什么？而且，是什么让您说这些问题没有得到答复或者可以在给定的文本中得到答复？您必须查看所提出问题的确切措辞以及您期望回答该问题的确切文本。您可能应该温习一下提示工程 101，但我敢打赌，要么您的问题不够具体（基于实际存在的文本），要么您的分块以某种方式分割了文本的想法与您认为应该的方式不匹配余弦相似度搜索。再说一遍，你的分块方法。
最后，这个问题是具体的还是笼统的？根据定义，RAG 系统非常适合大海捞针类型的查询——通常是谁、什么、何时、何地？当涉及到笼统的问题以及涉及如何以及在更大程度上涉及为什么的问题时，他们开始表现不佳。
我发现很多人认为，因为这些机器的反应看起来非常像人类，所以他们实际上“思考”了他们所武断的数据。他们不知道。他们只是在反省文字。他们不是人类，所以他们不具备人类的直觉——他们无法推理。因此，当你问它一个模糊的、笼统的问题，而这个问题没有在返回给它的一个或多个块中具体回答时，它要么会产生幻觉，要么告诉你它无法回答这个问题（如果你已经写了系统提示）正确）。
所有这些都表明，RAG，即使是简单的 RAG，也不仅仅是将 PDF 转储到矢量存储中并提出问题，而很少考虑模型实际上如何能够响应。]]></description>
      <guid>https://community.openai.com/t/rag-is-not-really-a-solution/599291#post_14</guid>
      <pubDate>Thu, 28 Mar 2024 00:12:51 GMT</pubDate>
    </item>
    <item>
      <title>关于customGPT知识截止的问题</title>
      <link>https://community.openai.com/t/question-about-customgpt-knowledge-cutoffs/699650#post_3</link>
      <description><![CDATA[感谢您的澄清，简短而甜蜜！如果有的话，将写回其他相关问题 ]]></description>
      <guid>https://community.openai.com/t/question-about-customgpt-knowledge-cutoffs/699650#post_3</guid>
      <pubDate>Thu, 28 Mar 2024 00:11:30 GMT</pubDate>
    </item>
    <item>
      <title>视觉模型拒绝翻译我自己的文档</title>
      <link>https://community.openai.com/t/vision-model-refuses-to-translate-my-own-documents/700018#post_1</link>
      <description><![CDATA[使用 python 在目录上运行循环，使用视觉预览或 gpt-4 将一些账单 (jpeg) 从法语翻译成英语，但由于存在帐户信息、付款参考等，因此即使可以，模型也会保持沉默查看信息。
我尝试修改提示...“他们是我的文档”，我有 POA，我很绝望，它不是个人的，等等，等等，它似乎引用了“不共享”的隐藏系统提示个人信息”……在这种情况下，它不会翻译并为我提供我需要的完整文档信息。该代码通常可以工作，但对于某些正常“公用事业账单”格式的文档，它只是彻底否认。
有人有任何解决方法或建议吗？谢谢！]]></description>
      <guid>https://community.openai.com/t/vision-model-refuses-to-translate-my-own-documents/700018#post_1</guid>
      <pubDate>Thu, 28 Mar 2024 00:10:51 GMT</pubDate>
    </item>
    <item>
      <title>使文本转语音的时间限制超过 2 分 36 秒，这样我就可以听 chatgpt 的完整故事</title>
      <link>https://community.openai.com/t/make-text-to-speech-have-more-limit-than-2-minutes-and-36-seconds-so-i-can-listen-full-story-from-chatgpt/654693#post_2</link>
      <description><![CDATA[您可以使用 www.make audio.app 将文本转换为音频。它构建在 OpenAI 的 TTS API 之上。
您最多可以输入 100,000 个字符的文本。]]></description>
      <guid>https://community.openai.com/t/make-text-to-speech-have-more-limit-than-2-minutes-and-36-seconds-so-i-can-listen-full-story-from-chatgpt/654693#post_2</guid>
      <pubDate>Wed, 27 Mar 2024 23:42:09 GMT</pubDate>
    </item>
    </channel>
</rss>