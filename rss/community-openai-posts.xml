<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Wed, 27 Mar 2024 18:23:12 GMT</lastBuildDate>
    <item>
      <title>AI专注于《街头霸王6》</title>
      <link>https://community.openai.com/t/ai-focused-on-street-fighter-6/699412#post_7</link>
      <description><![CDATA[好的，谢谢分享。
我认为您需要做的是为模型提供仅包含相关数据的精简版本。然后您可以通过常规脚本更轻松地及时分析。
换句话说，我看不到人工智能模型可以为分析添加任何额外价值。除非您将大量数据输入模型，该模型反过来会在数据中寻找您看不到的模式。
另一方面，您绝对可以使用法学硕士来帮助您剖析日志并创建分析输入。
最后，有时会每隔一帧截取一次屏幕截图，并将其输入视觉模型进行分析。但同样，这会很慢，模型需要知道要寻找什么，并且需要动态注释，在快节奏的游戏中，您会错过相关信息。
我会坚持经典的日志分析，并将数据输入到常规脚本中，以便为您提供有关常规 KPI 的实时反馈。
然后您可以保存所有数据，并在以后使用它向人工智能展示以寻找新的见解。
也许？到目前为止，这就是我的思考过程。]]></description>
      <guid>https://community.openai.com/t/ai-focused-on-street-fighter-6/699412#post_7</guid>
      <pubDate>Wed, 27 Mar 2024 18:21:35 GMT</pubDate>
    </item>
    <item>
      <title>这有发生在其他人身上吗？如果是，您是如何解决的？</title>
      <link>https://community.openai.com/t/has-this-happened-to-anyone-else-if-yes-how-did-you-resolve-it/699775#post_1</link>
      <description><![CDATA[取消计划
您确定要取消您的结算计划吗？
您将能够消耗帐户中的所有剩余积分，之后我们将开始拒绝您的 API 请求，并且不会再收取任何费用。]]></description>
      <guid>https://community.openai.com/t/has-this-happened-to-anyone-else-if-yes-how-did-you-resolve-it/699775#post_1</guid>
      <pubDate>Wed, 27 Mar 2024 18:21:12 GMT</pubDate>
    </item>
    <item>
      <title>将文本拆分为块与减少文本</title>
      <link>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_5</link>
      <description><![CDATA[


 Female.mystique:
&lt;块引用&gt;
我正在尝试使用“text-embedding-ada-002”检索使用 13,778 个令牌的文本的嵌入，这超出了 ada 的令牌限制。


您可以保持完整的 13,778 个令牌块，但仅嵌入其中的一部分，然后返回与较小的嵌入块相关的完整的 13,778 个令牌块。
这样你的块是连贯的，你可以将它输入到一个大的上下文模型中。
如上所述，人工智能可能无法完全消化较大的块，因为注意力被这个较大的令牌范围所稀释，并且一些细节可能会被掩盖。但至少你的检索中有一个连贯的块，并且希望随着时间的推移，法学硕士的注意力机制将会得到改善。
至于决定论，我不确定为什么你需要这个，只要余弦相似度在舍入误差之内。要使嵌入引擎完全确定，会导致大量延迟，因为计算机中的所有算术操作都必须以非常特定的同步序列完成。
这里的原因是，一个鲜为人知的事实是，计算机内部的浮点数的分布定律并不可靠，因此一般来说：
A(B + C) \neq AB + AC
所以这可以放松：
A(B + C) \大约 AB + AC
因此它不是确定性的。
这就是为什么永远不会有确定性，我也不会想要或渴望这样，仅仅是为了提高速度和降低延迟的好处。]]></description>
      <guid>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_5</guid>
      <pubDate>Wed, 27 Mar 2024 18:13:27 GMT</pubDate>
    </item>
    <item>
      <title>信用卡被拒绝并且不允许我添加新卡</title>
      <link>https://community.openai.com/t/credit-card-rejected-and-wont-allow-me-to-add-a-new-one/695509#post_3</link>
      <description><![CDATA[大约 24 小时后，我成功添加了一张新卡。不知道是固定的等待时间还是只是运气]]></description>
      <guid>https://community.openai.com/t/credit-card-rejected-and-wont-allow-me-to-add-a-new-one/695509#post_3</guid>
      <pubDate>Wed, 27 Mar 2024 18:04:16 GMT</pubDate>
    </item>
    <item>
      <title>不使用数据训练模型的选项从自定义 GPT 选项中消失</title>
      <link>https://community.openai.com/t/option-to-not-use-your-data-to-train-models-disappeared-from-custom-gpt-options/492391#post_10</link>
      <description><![CDATA[有人有关于此主题的任何其他信息可以分享吗？提前致谢！]]></description>
      <guid>https://community.openai.com/t/option-to-not-use-your-data-to-train-models-disappeared-from-custom-gpt-options/492391#post_10</guid>
      <pubDate>Wed, 27 Mar 2024 18:04:07 GMT</pubDate>
    </item>
    <item>
      <title>助理线程可以存储在我们的服务器上而不是 OpenAI 上吗</title>
      <link>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_10</link>
      <description><![CDATA[你看，朋友，你好像误会了。
没有人说你不能复制助手端点，我们说这不是重点，而且偏离了主题。
OP 询问如何使用带有本地存储的assistants 端点来保护数据隐私。这是不可能的。
正如 @vb 所说，甚至不可能通过重新发明助手来做到这一点 通过 chat/completions 端点，无需付出大量努力，也无需达成零保留协议。
此时，为什么不简单地使用具有零保留协议的助手。
提供替代方案很好，但是当你写作时，



 jmarlonbasayo：
&lt;块引用&gt;
从技术上讲，是的，但不是正式的或简单的。


您正在伤害您的社区成员，因为这根本不是事实。
您不能以官方方式或非正式地执行此操作，这根本不可能。您可以完全做其他事情并获得可比较的结果，但在任何情况下您仍然不能让



维克拉姆：
&lt;块引用&gt;
助理访问未存储在 OpenAI 中的消息线程

]]></description>
      <guid>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_10</guid>
      <pubDate>Wed, 27 Mar 2024 18:03:54 GMT</pubDate>
    </item>
    <item>
      <title>Assistant API - 使用了太多的“输入”令牌</title>
      <link>https://community.openai.com/t/assistant-api-way-too-much-input-tokens-used/699661#post_2</link>
      <description><![CDATA[等等。

运行 1：输入 1146 个令牌，输出 398 个令牌
运行 2：7 个令牌
运行两次后，线程控制台告诉我已经使用了 2705，这几乎正好是 1146 + 398 + 1146 + 7 = 2697

这意味着每次运行时都会重新发送初始消息？但为什么呢？]]></description>
      <guid>https://community.openai.com/t/assistant-api-way-too-much-input-tokens-used/699661#post_2</guid>
      <pubDate>Wed, 27 Mar 2024 17:59:46 GMT</pubDate>
    </item>
    <item>
      <title>助理线程可以存储在我们的服务器上而不是 OpenAI 上吗</title>
      <link>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_9</link>
      <description><![CDATA[@vikram 当我们讨论一些相关问题时：如果您需要零保留协议您需要联系销售人员。
sales@openai.com]]></description>
      <guid>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_9</guid>
      <pubDate>Wed, 27 Mar 2024 17:58:44 GMT</pubDate>
    </item>
    <item>
      <title>请求指导：将身份验证提供者 auth0 切换为 clerk</title>
      <link>https://community.openai.com/t/guidance-requested-switching-auth-provider-auth0-to-clerk/474999#post_3</link>
      <description><![CDATA[嘿麦克斯，你曾经走过这条路吗？很想听到有关此主题的任何知识。]]></description>
      <guid>https://community.openai.com/t/guidance-requested-switching-auth-provider-auth0-to-clerk/474999#post_3</guid>
      <pubDate>Wed, 27 Mar 2024 17:56:11 GMT</pubDate>
    </item>
    <item>
      <title>助理线程可以存储在我们的服务器上而不是 OpenAI 上吗</title>
      <link>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_8</link>
      <description><![CDATA[这允许您使用聊天完成，同时拥有类似于 OpenAI 助手的工作流程，但显然，它更复杂并且需要更多编码。 GitHub - langchain-ai/opengpts。]]></description>
      <guid>https://community.openai.com/t/can-assistant-threads-be-stored-on-our-server-instead-of-at-openai/697528#post_8</guid>
      <pubDate>Wed, 27 Mar 2024 17:51:46 GMT</pubDate>
    </item>
    <item>
      <title>自定义 GPT 如何收费？</title>
      <link>https://community.openai.com/t/how-to-charge-for-a-custom-gpt/594787?page=4#post_63</link>
      <description><![CDATA[让我重新表述一下：问题是我不能“租”。不卖。它应该像合作伙伴关系一样运作：OpenAI 提供平台和引擎，而我们则凭借我们的专业知识和客户群进入。
这很不幸，因为这个 GPT 平台拥有在企业界大卖的一切 - 至少对于中型到大型实施的 ERP 客户而言。]]></description>
      <guid>https://community.openai.com/t/how-to-charge-for-a-custom-gpt/594787?page=4#post_63</guid>
      <pubDate>Wed, 27 Mar 2024 17:47:50 GMT</pubDate>
    </item>
    </channel>
</rss>