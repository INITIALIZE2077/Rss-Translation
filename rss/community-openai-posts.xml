<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 30 Jan 2024 12:30:26 GMT</lastBuildDate>
    <item>
      <title>微调功能（不带直接答案）</title>
      <link>https://community.openai.com/t/fine-tuning-function-not-with-direct-answers/607248#post_4</link>
      <description><![CDATA[太棒了。如果出现更具体的问题，请随时返回此论坛。周围有很多嵌入专家。]]></description>
      <guid>https://community.openai.com/t/fine-tuning-function-not-with-direct-answers/607248#post_4</guid>
      <pubDate>Tue, 30 Jan 2024 12:21:21 GMT</pubDate>
    </item>
    <item>
      <title>有人尝试过使用预处理的 3D 体积数据来训练 LLM 吗？</title>
      <link>https://community.openai.com/t/anyone-ever-tried-feeding-preprocessed-3d-volumetric-data-for-training-llm/607308#post_3</link>
      <description><![CDATA[你好
用于对动画模型或动画体积形状进行分析和分类。所以法学硕士可以告诉用户它关注的是哪种运动风格。例如……用于运动表现的教育人工智能助手
一旦按顶点烘焙动画，并非所有 3D 模型都需要进行装配。]]></description>
      <guid>https://community.openai.com/t/anyone-ever-tried-feeding-preprocessed-3d-volumetric-data-for-training-llm/607308#post_3</guid>
      <pubDate>Tue, 30 Jan 2024 12:21:02 GMT</pubDate>
    </item>
    <item>
      <title>CHAT GPT 4 慢得令人痛苦，我知道为什么，有一个快速的解决方案</title>
      <link>https://community.openai.com/t/chat-gpt-4-painfully-slow-i-know-why-with-a-quick-solution/502218?page=4#post_80</link>
      <description><![CDATA[我可以确认问题仍然存在，切换到插件确实暂时解决了这个问题，但我需要 Dalle 功能，而且速度越来越慢。
另一个解决方法是在聊天开始时告诉它不要使用 Dall-e 或浏览。]]></description>
      <guid>https://community.openai.com/t/chat-gpt-4-painfully-slow-i-know-why-with-a-quick-solution/502218?page=4#post_80</guid>
      <pubDate>Tue, 30 Jan 2024 12:19:40 GMT</pubDate>
    </item>
    <item>
      <title>为什么我在 plus 帐户中找不到 GPT 商店？</title>
      <link>https://community.openai.com/t/why-i-can-not-find-gpt-store-in-my-plus-account/585128#post_15</link>
      <description><![CDATA[同意，我仍然无法访问，而且已经过去几周了。]]></description>
      <guid>https://community.openai.com/t/why-i-can-not-find-gpt-store-in-my-plus-account/585128#post_15</guid>
      <pubDate>Tue, 30 Jan 2024 12:15:25 GMT</pubDate>
    </item>
    <item>
      <title>自定义 gpt 与助手 api</title>
      <link>https://community.openai.com/t/custom-gpt-vs-assistant-api/493869?page=2#post_26</link>
      <description><![CDATA[我认为部分原因是 OpenAI 需要保持 ChatGPT 的竞争力。
他们本质上通过 Assistants API 为我们提供了相同或相似的后端框架，但我怀疑他们的“尖端”检索资源和方法是受限制的，或者至少优先用于 ChatGPT。
在我看来，由于可以访问代码解释器和自我管理的工具调用系统，Assistants API 仍然是值得的。但对于一般的 RAG 和检索，我认为助理使用自定义解决方案会做得更好。]]></description>
      <guid>https://community.openai.com/t/custom-gpt-vs-assistant-api/493869?page=2#post_26</guid>
      <pubDate>Tue, 30 Jan 2024 12:13:30 GMT</pubDate>
    </item>
    <item>
      <title>“不幸的是，我无法帮助处理包含个人信息的图像。”- Vision API 响应</title>
      <link>https://community.openai.com/t/unfortunately-i-am-not-able-to-assist-with-images-that-contain-personal-information-vision-api-response/607441#post_1</link>
      <description><![CDATA[# 图片路径
image_path_3 = &quot;数据/图像(6).png&quot;
image_path_4 = &quot;数据/图像 (7).png&quot;
image_path_5 = &quot;数据/图像(8).png&quot;

# 获取base64字符串
base64_image_3 = 编码_图像(image_path_3)
base64_image_4 = 编码_图像(image_path_4)
base64_image_5 = 编码_图像(image_path_5)

响应 = openai.chat.completions.create(
  型号=“gpt-4-vision-preview”，
  消息=[
    {
      “角色”：“用户”，
      “内容”： [
        {
          “类型”：“文本”，
          “文本”： ”””
                    对提供的图像集进行全面分析，其中包括各种形式的可视化数据表示形式，例如仪表板、报告和图表。每个图像可能因时间范围或所应用的特定过滤器而异。请按照以下步骤确保进行彻底检查，了解这些差异的影响，并提取有价值的数据科学家级别的见解：

                    1. **初步概述**：
                    - 对于每张图像，提供简短的描述，注明视觉表现的类型和主要焦点。此外，确定应用于数据的任何特定时间范围或过滤器（例如人口统计、地理、时间）。

                    2. **对每张图像进行深入分析**：
                    - **关键元素和数据点**：识别并描述每个图像中的关键元素、指标或指标，强调它们在所应用的时间范围或过滤器的上下文中的相关性。
                    - **趋势和模式识别**：考虑时间范围或过滤器的影响，突出可见的趋势、模式或异常。讨论这些观察结果的意义。
                    - **洞察提取**：根据分析生成洞察，考虑应用的过滤器或不同的时间范围可能如何影响数据解释。

                    3. **比较和过滤影响分析**：
                    - **跨图像比较**：如果适用，比较跨图像的见解或趋势，特别关注时间范围或应用的过滤器的差异如何改变解释或揭示新的见解。
                    - **过滤器和时间范围分析**：专门解决任何过滤器或时间范围对数据的影响。讨论这些差异揭示了随着时间的推移或不同细分市场发生的变化。
                    - **更广泛的见解**：结合个人分析和比较分析的见解，提供对情况或趋势的更广泛的看法，突出考虑过滤器和时间框架时出现的任何新的或微妙的理解。

                    4. **结论、建议和进一步问题**：
                    - 总结主要发现和见解，包括时间范围和过滤器对数据解释的具体影响。
                    - 根据分析提供可操作的建议，并根据利益相关者的需求量身定制。
                    - 提出进一步的问题或调查领域，以提供额外的见解，特别是与不同过滤器或时间段的影响相关的见解。

                    5. **数据呈现的评估和建议**：
                    - 批评每个图像中数据呈现的有效性和清晰度，考虑在给定过滤器和时间范围的情况下它允许分析的效果如何。
                    - 建议改进或额外的数据可视化，以增强理解或揭示额外的见解。

                    确保分析结构合理，能够解决每个步骤，提供清晰、可操作的见解，反映对数据的深刻理解，以及所应用的过滤器和不同时间范围的影响。
                ”“”
,
        },
        {
          “类型”：“图像_url”，
          “图像网址”：{
            “url”：f“数据：image/jpeg;base64，{base64_image_3}”，
            “细节”：“高”
          },
        },
        {
          “类型”：“图像_url”，
          “图像网址”：{
            “url”：f“数据：image/jpeg;base64，{base64_image_4}”，
            “细节”：“高”
          },
        },
        {
          “类型”：“图像_url”，
          “图像网址”：{
            “url”：f“数据：image/jpeg;base64，{base64_image_5}”，
            “细节”：“高”
          },
        },
      ],
    }
  ],
  最大令牌数=1000,
）

有时 GPT-4V 能够根据提示进行处理和回答，但有时会失败并输出“它无法帮助处理包含个人信息的图像......”之类的消息。是否有我在提示中提到的任何具体内容导致此问题，如果是的话，为什么它能够在几次尝试中处理。]]></description>
      <guid>https://community.openai.com/t/unfortunately-i-am-not-able-to-assist-with-images-that-contain-personal-information-vision-api-response/607441#post_1</guid>
      <pubDate>Tue, 30 Jan 2024 12:11:22 GMT</pubDate>
    </item>
    <item>
      <title>新的 gpt-3.5-turbo-1106 (API) 太可怕了</title>
      <link>https://community.openai.com/t/new-gpt-3-5-turbo-1106-api-is-horrific/496732?page=2#post_24</link>
      <description><![CDATA[我们使用 3.5-turbo 和我们自己的 RAG 来提供聊天机器人。上线的那天早上，我们接到了大量的电话，因为答案输出明显更差。
我们注意到的一个特别的事情是，它无法准确地重现提示中文档摘录中的参考链接。
就目前情况而言，它对我们来说基本上无法使用，但我们对 0613 非常满意，而且并非每个客户都有足够的业务案例来证明使用 GPT-4/GPT-4-turbo 的合理性。目前我们已将其修复为 0613，但我非常担心它可能会停产。]]></description>
      <guid>https://community.openai.com/t/new-gpt-3-5-turbo-1106-api-is-horrific/496732?page=2#post_24</guid>
      <pubDate>Tue, 30 Jan 2024 12:07:06 GMT</pubDate>
    </item>
    <item>
      <title>如何使用 GPT API 访问自定义知识库？</title>
      <link>https://community.openai.com/t/how-can-i-access-the-custom-knowledge-base-with-gpt-api/607402#post_2</link>
      <description><![CDATA[欢迎来到论坛！
在 OpenAI Discord 论坛上询问 kapa.ai 的问题。
&lt;小时/&gt;
问题
我有兴趣使用 GPT API 创建聊天应用程序，我可以在其中添加自己的知识库。是否可以将我的自定义数据上传到 GPT 的服务器并通过 API 访问它？我见过一些应用程序在做类似的事情，非常感谢您对此的意见。
回复
根据所提供的摘录中提供的信息，OpenAI 目前似乎不支持将自定义数据上传到 GPT 服务器并通过 API 访问它的功能。自定义 GPT 模型只能通过 ChatGPT Plus 获得，并且无法通过开发者 API 源 (https: //community.openai.com/t/545254）。
您可能需要使用提供类似技术的 API 模型开发自己的解决方案并自行处理语言数据源 (https://community.openai.com/t/545254)。
要创建聊天应用程序，您可能需要查看 Assistants API 源 (https:// /community.openai.com/t/589868）。
有关如何使用 API 的更详细说明，您可以参考 OpenAI 文档来源 (https: //platform.openai.com/docs）。如果您需要自定义聊天模型的行为，您可能会发现有关 ChatGPT 自定义说明的文章很有帮助来源 (https://help.openai.com/en/articles/8142208-chatgpt-android-app-faq#h_70d81691ec)。
请注意，此信息基于所提供的摘录，可能并不全面。要获得最准确和最新的信息，我建议查看官方 OpenAI 资源。
&lt;小时/&gt;
对于提供的摘录，kapa.ai 机器人可以访问

OpenAI 文档
OpenAI帮助中心
GitHub Cookbook
Discourse 论坛回复（仅限标记为“已回答”的回复） 
各种 SDK 问题（Python、Node 等）

GitHub - openai/openai-python：OpenAI API 的官方 Python 库 
GitHub - openai/openai-node：OpenAI API 的官方 Node.js / Typescript 库


API 参考
Whisper GitHub 讨论 + 自述文件

注意：我根据我的最佳理解添加了所提供摘录的链接。还有更多，有些可能是错误的。
&lt;小时/&gt;
简而言之，回答你的问题
&lt;块引用&gt;
是否可以将我的自定义数据上传到 GPT 的服务器并通过 API 访问它？

没有。]]></description>
      <guid>https://community.openai.com/t/how-can-i-access-the-custom-knowledge-base-with-gpt-api/607402#post_2</guid>
      <pubDate>Tue, 30 Jan 2024 11:57:50 GMT</pubDate>
    </item>
    </channel>
</rss>