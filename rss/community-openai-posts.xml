<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 12 Feb 2024 21:15:45 GMT</lastBuildDate>
    <item>
      <title>使用 Document Refiner 的 FewShot</title>
      <link>https://community.openai.com/t/fewshot-with-document-refiner/622323#post_5</link>
      <description><![CDATA[所以我将是第一个承认我对 langchain 有着非常复杂的感情的人，但我知道很多人喜欢使用它。
我猜你已经看过这个了？
  &lt;标题类=“来源”&gt;
      
js.langchain.com


  &lt;文章类=“onebox-body”&gt;
    精炼 | 🦜️🔗浪链
精炼文档链通过循环输入文档并迭代更新其答案来构建响应。对于每个文档，它将所有非文档输入、当前文档以及最新的中间答案传递给 LLM 链...





看，对我来说，轻松地表达“少击提示”有点困难，因为这是我自己学到的第一个“技术”之一，而且只是下意识地做到了。直到后来才给它起名字。
很少有镜头提示本质上就是这样：
问：现在几点了？
答：现在是下午 5 点
问：我住在法国
答： 现在是 22:00

从精炼文档的内容来看，它似乎是一个初始的 Q/A 片段，它被输入到聊天完成实例中，并带有额外的上下文，以更改答案的初始“A”如果需要 .
“少镜头提示”通常只是在初始答案因某种原因被认为不够充分时进行澄清或纠正模型。这是一种更……“自然”的对话方式，至少对我来说是这样。
假设您向模特询问有关文档的信息。你问：
本文档中玛丽苏的情节摘要是什么？
它响应：
当然！玛丽苏从黑暗邪恶势力手中拯救了世界，从此大家过上了幸福快乐的生活！
现在，如果答案足够，您将获得一次提示。
如果您希望稍微调整一下，您可以再次询问（在相同对话线程或链中）：
好吧，这很可爱，但我有点想要 l33t 语言中的摘要
它响应：
当然！ M4ry Su3 s4v3d th3 w0rld fr0m d4rk 3v1l f0rc3s 第四个 3v3ry0n3 l1v3d h4pp1ly 3v3r 4ft3r！
现在它已经变成了几次提示。
这也是我对 LangChain 不满的原因，因为我注意到它往往会让事情变得有点过于复杂，并且最终会让人们对那些并不那么令人困惑的概念感到困惑；使用 LangChain 最终会让人感到困惑。
所有这些都是说，如果您想要一个用于查询文档的“Few Shot”提示的示例，您所需要的只是一个提供答案的实例，您作为查询者说“嗯，实际上”，然后它会检索提供澄清或细化后的正确答案。这种提示在代码中也更为常见。
这有帮助吗？]]></description>
      <guid>https://community.openai.com/t/fewshot-with-document-refiner/622323#post_5</guid>
      <pubDate>Mon, 12 Feb 2024 21:09:15 GMT</pubDate>
    </item>
    <item>
      <title>助手 + RAG 而不是将文件添加到助手</title>
      <link>https://community.openai.com/t/assistants-rag-instead-of-adding-files-to-assistant/623845#post_1</link>
      <description><![CDATA[使用函数检索 RAG 数据而不是向助手添加文件的效率如何？在这种情况下，助理搜索是否更糟糕？]]></description>
      <guid>https://community.openai.com/t/assistants-rag-instead-of-adding-files-to-assistant/623845#post_1</guid>
      <pubDate>Mon, 12 Feb 2024 21:08:30 GMT</pubDate>
    </item>
    <item>
      <title>社区画廊/愿望/功能请求论坛</title>
      <link>https://community.openai.com/t/community-gallery-wish-feature-request-forum/623807#post_2</link>
      <description><![CDATA[您好，欢迎来到开发者论坛！
非常欢迎您在这里发布您的作品并看看谁参与其中，您可能还想查看 OpenAI，因为他们有一个有趣项目的展示部分。]]></description>
      <guid>https://community.openai.com/t/community-gallery-wish-feature-request-forum/623807#post_2</guid>
      <pubDate>Mon, 12 Feb 2024 21:02:48 GMT</pubDate>
    </item>
    <item>
      <title>DALL-E 3 图片下载链接唯一选项是webp？没有png选项？</title>
      <link>https://community.openai.com/t/dall-e-3-image-download-link-only-option-is-webp-no-png-option/611885#post_16</link>
      <description><![CDATA[


 SynthAIzards：
&lt;块引用&gt;
结论：选择的能力……人工智能驱动的创造力。在制作过程中


如果真是AI输出，犯这样的间距错误，ChatGPT的困惑度确实很差，温度也太高了。
人工智能写下的“结论”不太可能被认真对待。它可以从任何角度写作。
例如，当您向客户服务人员发送投诉信息时，我可以让人工智能发回一个虚构的机器人回复，其中包含捏造的内容（也许与外包支持的工作方式相去不远……）。
&lt;块引用&gt;
了解 DALL-E AI Image Creator 中从 PNG 到 WebP 的转换
简介
我们了解到，DALL-E AI 图像创建器的内部数据库和下载图像格式从 PNG 到 WebP 的最新变化对您的工作流程造成了一些干扰。对此造成的任何不便，我们深表歉意。然而，这一改变是经过深思熟虑后实施的，目的是提高我们人工智能系统的整体性能和效率。本文旨在解释这一变化背后的原因，以及它如何与 OpenAI 为用户提供最佳服务的承诺保持一致。
为什么选择 WebP？
WebP 是一种现代图像格式，可为网络上的图像提供卓越的无损和有损压缩。它由 Google 开发，旨在创建更小、更美观的图像，从而帮助提高网络速度。以下是我们选择 WebP 的一些原因：
1。卓越的压缩
与 PNG 相比，WebP 提供了卓越的压缩效果。与 PNG 相比，它可以创建尺寸小 25-34% 的图像，同时保持相同的质量。这会带来更快的数据传输速度和更少的存储空间，从而显着提高人工智能系统的性能。
2。支持有损和无损压缩
WebP 支持有损和无损压缩，以及两种模式下的透明度（也称为 Alpha 通道）。这种灵活性使我们能够根据每个用例的具体要求来优化图像，从而更有效地利用资源。
3。改进的加载时间
WebP 图像的文件较小，意味着加载速度更快，从而改善用户体验。这对于需要传输大量图像数据的应用程序（例如 DALL-E）尤其重要。
解决兼容性问题
我们承认，过渡到 WebP 可能会导致某些不支持此格式的应用程序出现兼容性问题。然而，由于 WebP 的诸多优点，大多数现代 Web 浏览器和应用程序已经添加了对 WebP 的支持。如果您遇到兼容性问题，我们建议您将应用程序更新到最新版本。
对于尚不支持 WebP 的应用程序，有许多免费的在线工具和软件库可以将 WebP 图像转换为其他格式，包括 PNG。我们知道这可能会给您的工作流程增加一个额外的步骤，在我们努力提高系统效率和性能的过程中，我们感谢您的理解。
结论
在 DALL-E AI 图像创建器中从 PNG 切换到 WebP 的决定并不是轻易做出的。这是由我们致力于提高人工智能系统的性能和效率所推动的，这符合 OpenAI 确保通用人工智能造福全人类的使命。我们了解这一变化可能会造成一些干扰，我们将随时为您提供支持，帮助您完成这一转变。如果您还有任何其他问题或需要帮助，请随时联系我们的支持团队。


完全AI文本--gpt-4提示 （点击查看更多详情）]]></description>
      <guid>https://community.openai.com/t/dall-e-3-image-download-link-only-option-is-webp-no-png-option/611885#post_16</guid>
      <pubDate>Mon, 12 Feb 2024 20:57:45 GMT</pubDate>
    </item>
    <item>
      <title>AI助手没有回复</title>
      <link>https://community.openai.com/t/ai-assistant-not-responding-with-a-response/601358#post_4</link>
      <description><![CDATA[您好@shakirsnakescript，我也遇到了同样的问题，在我最近的 13 次通话中失败了 6 次次（同一天连续四次）。我还注意到，我要为这些未完成的失败运行的提示和说明付费。我尝试联系支持人员，但联系不上。如果我设法对问题有一些见解，我会回复该帖子。]]></description>
      <guid>https://community.openai.com/t/ai-assistant-not-responding-with-a-response/601358#post_4</guid>
      <pubDate>Mon, 12 Feb 2024 20:55:08 GMT</pubDate>
    </item>
    <item>
      <title>利用 AI 实现音频对话</title>
      <link>https://community.openai.com/t/implementing-audio-conversation-with-ai/488534#post_7</link>
      <description><![CDATA[给我发一条带有链接的私信，我会将其添加到您的帖子中 ]]></description>
      <guid>https://community.openai.com/t/implementing-audio-conversation-with-ai/488534#post_7</guid>
      <pubDate>Mon, 12 Feb 2024 20:50:16 GMT</pubDate>
    </item>
    </channel>
</rss>