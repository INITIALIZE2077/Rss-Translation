<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Thu, 04 Jan 2024 15:20:32 GMT</lastBuildDate>
    <item>
      <title>（模组说明：本地化错误，限制为 40/3 小时）每 3 天 40 条消息（！）</title>
      <link>https://community.openai.com/t/mod-note-localization-error-limit-is-40-3-hours-40-messages-every-3-days/548699#post_18</link>
      <description><![CDATA[刚刚关闭这里的循环，现在应该修复这个问题！如果您发现任何其他问题，请告诉我。]]></description>
      <guid>https://community.openai.com/t/mod-note-localization-error-limit-is-40-3-hours-40-messages-every-3-days/548699#post_18</guid>
      <pubDate>Thu, 04 Jan 2024 15:19:11 GMT</pubDate>
    </item>
    <item>
      <title>有哪些选项可以防止用户尝试在生产中越狱聊天机器人？</title>
      <link>https://community.openai.com/t/what-are-the-options-to-prevent-users-attempt-to-jailbreak-chatbot-in-production/575766#post_8</link>
      <description><![CDATA[我听取了 @cyzgab 的建议，将 OpenAI 提供的审核模块与聊天完成功能配对屏幕提示。
我得到的结果非常有希望，我的解决方案能够抵抗所有 DAN 越狱提示。这种方法还可以防止有毒提示污染我的主要模型。因此，我认为较高的成本是合理的。]]></description>
      <guid>https://community.openai.com/t/what-are-the-options-to-prevent-users-attempt-to-jailbreak-chatbot-in-production/575766#post_8</guid>
      <pubDate>Thu, 04 Jan 2024 15:11:50 GMT</pubDate>
    </item>
    <item>
      <title>响应具有有效的 json，但它嵌套在损坏的 json 中</title>
      <link>https://community.openai.com/t/response-has-valid-json-but-its-nested-in-broken-json/578322#post_1</link>
      <description><![CDATA[我有一个与 gpt-4-1106-preview 和 response_format 设置类似的提示：
&lt;检查之前输入是否有错误的提示&gt;
输出为 JSON：{
  “简介”：“字符串”，
  &quot;更正1&quot;: &quot;字符串&quot;,
  &quot;解释1&quot;: &quot;字符串&quot;,
  “摘要”：“字符串”
}

通常这会返回一个有效的 json，但在 20% 的情况下，我会得到这样的结果，它将有效的 json 输出发布到损坏的 json 模式中。 （在此处作为图像发布以避免格式错误。）

有人见过这个吗？]]></description>
      <guid>https://community.openai.com/t/response-has-valid-json-but-its-nested-in-broken-json/578322#post_1</guid>
      <pubDate>Thu, 04 Jan 2024 15:08:24 GMT</pubDate>
    </item>
    <item>
      <title>Streamlit 使用 OpenAI 查询多个 Snowflake 表的元数据</title>
      <link>https://community.openai.com/t/streamlit-using-a-openai-for-querying-metadata-for-multiple-snowflake-tables/578321#post_1</link>
      <description><![CDATA[我正在使用一个快速入门指南，其中包含一个提示文件，让我们添加有关 2 个 Snowflake 表的顶级信息，我通过我创建的函数将这些信息发送到 OpeanAi：get_system_prompt
其用法如下：
st.session_state.messages = [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: get_system_prompt()}]
在此函数中，我对一个表描述变量进行了硬编码，该变量是我编写的用于描述 2 个表的变量。
不幸的是，我无法附加链接，但我正在使用的快速入门的名称是“Frosty：在您的 Snowflake 数据上在 Streamlit 中构建 LLM 聊天机器人”
我正在寻找一些关于如何使其更加动态的建议，这样我就不必对每个表名称进行硬编码，以及如何为每个表制作表描述？是否有必要包含表格描述，大约 100 个表格需要大量打字……欢迎任何/所有建议！]]></description>
      <guid>https://community.openai.com/t/streamlit-using-a-openai-for-querying-metadata-for-multiple-snowflake-tables/578321#post_1</guid>
      <pubDate>Thu, 04 Jan 2024 15:07:09 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI 可以用于长期记忆吗？</title>
      <link>https://community.openai.com/t/can-openai-be-used-for-long-term-memory/574581#post_7</link>
      <description><![CDATA[我的建议是创建嵌入并存储在向量数据库中。我发现这种方法迄今为止最具前瞻性且最具成本效益。如果您有矢量数据库中知识的 OpenAPI 架构，您也可以通过操作将它们连接到 GPT。]]></description>
      <guid>https://community.openai.com/t/can-openai-be-used-for-long-term-memory/574581#post_7</guid>
      <pubDate>Thu, 04 Jan 2024 14:58:10 GMT</pubDate>
    </item>
    <item>
      <title>处理不一致的结果</title>
      <link>https://community.openai.com/t/coping-with-inconsistent-results/576342#post_9</link>
      <description><![CDATA[大概 99.9%。我在 Midjourney 中使用种子有一段时间了，除了少数几个之外，几乎每个像素都是相同的。因此，在这种情况下，您应该期望响应中的几乎每个字符都是相同的。]]></description>
      <guid>https://community.openai.com/t/coping-with-inconsistent-results/576342#post_9</guid>
      <pubDate>Thu, 04 Jan 2024 14:55:30 GMT</pubDate>
    </item>
    <item>
      <title>我可以通过 api 从 GPT-4 获得与从自定义 GPT 获得的相同类型的响应吗？</title>
      <link>https://community.openai.com/t/can-i-get-same-kind-of-responses-from-gpt-4-through-api-as-i-get-from-custom-gpts/576730#post_7</link>
      <description><![CDATA[只是好奇，从自定义 GPT 切换到 API 的原因是什么？我发现 GPT 更容易构建、维护，而且使用起来更便宜。]]></description>
      <guid>https://community.openai.com/t/can-i-get-same-kind-of-responses-from-gpt-4-through-api-as-i-get-from-custom-gpts/576730#post_7</guid>
      <pubDate>Thu, 04 Jan 2024 14:54:13 GMT</pubDate>
    </item>
    <item>
      <title>使用聊天 GPT 自定义生成器时丢失数据</title>
      <link>https://community.openai.com/t/lost-data-when-using-chat-gpt-custom-builder/577748#post_6</link>
      <description><![CDATA[很好的问题。为了缓解这个问题，我为所有 GPT 构建了一个简单的版本控制系统，以便在 GPT Builder 界面意外覆盖的情况下，只需单击一下即可恢复说明、知识和操作。这很有帮助。]]></description>
      <guid>https://community.openai.com/t/lost-data-when-using-chat-gpt-custom-builder/577748#post_6</guid>
      <pubDate>Thu, 04 Jan 2024 14:52:24 GMT</pubDate>
    </item>
    <item>
      <title>有哪些选项可以防止用户尝试在生产中越狱聊天机器人？</title>
      <link>https://community.openai.com/t/what-are-the-options-to-prevent-users-attempt-to-jailbreak-chatbot-in-production/575766#post_7</link>
      <description><![CDATA[利用 OpenAPI 架构作为操作并将其用作中间件会有所帮助。尽管这确实增加了令牌数量并减少了响应时间。
这里还有一些关于说明和知识的其他主题。
也就是说，我发现更有效的做法是向客户设定期望，即公共 GPT 是公开的，并且您添加的任何指令、知识和操作都能够被完全阅读。这有助于重新构建对话并重新思考 GPT 可以做什么。
这对安全和隐私密集型用例没有帮助。但无论如何，我认为 GPT 目前还没有为这些用例做好准备。
如果客户（或您）拥有 GPT Enterprise，则可以通过将使用限制为仅有权访问 GPT 的组织来提供帮助。]]></description>
      <guid>https://community.openai.com/t/what-are-the-options-to-prevent-users-attempt-to-jailbreak-chatbot-in-production/575766#post_7</guid>
      <pubDate>Thu, 04 Jan 2024 14:50:39 GMT</pubDate>
    </item>
    <item>
      <title>关于自定义 GPT 的问题</title>
      <link>https://community.openai.com/t/question-about-custom-gpts/573906#post_8</link>
      <description><![CDATA[我也对其中的一些感到困惑。我手边有一张便条，提醒我 Knowledge 的限制和最佳实践。
 ### 知识文件

        1. 将所有文本文件（.pdf、.docx 等）转换为文本文件。理想的格式为 Markdown (.md)。 .txt 也很好。
        2. 将所有表格文件（.csv、Google Sheet 等）转换为 .xlsx，因为 ChatGPT 特别适用于 Excel 文件。
        3. 每个 GPT 限制：10 个文件
        4. 每个文件限制：512MB（图像文件20MB，.xlsx无限制），2M令牌
        5. 每个用户限制：10 GB。每个组织限制：100 GB。
        6. 为了提高性能，建议直接上传到 Knowledge。
        7. 将内容分成较小的文件，以提高搜索效率。
        8. 如果知识更新频繁，请勿上传文件。相反，使用系统来存储文件或 url 并创建 OpenAPI 端点以通过 Action 获取内容
]]></description>
      <guid>https://community.openai.com/t/question-about-custom-gpts/573906#post_8</guid>
      <pubDate>Thu, 04 Jan 2024 14:44:25 GMT</pubDate>
    </item>
    <item>
      <title>请求上限使得构建 GPT 变得不可能</title>
      <link>https://community.openai.com/t/request-cap-makes-impossible-to-build-gpts/575136#post_6</link>
      <description><![CDATA[总的来说，稳定使用 ChatGPT 一年了，我的经验如下。

这种情况每隔几个月就会发生一次，可能会持续一两周。总的来说，我花了大约 5% 的时间达到上限，而 95% 的时间没有达到上限。所以它会消失。
这可能是由于新的 GPT 功能以及知识和操作与后端的交互方式所致。也许使用知识的一个响应算作“2”，而使用知识和行动的一个响应算作“3”。这可能有些偏离事实，但根据我的经验，这感觉是对的。
切换到 GPT-4 可以降低达到上限的可能性。事实上，有几次我用 GPT 达到了上限，但它仍然允许我用 GPT-4（普通 ChatGPT）开始一个新线程。为了清楚起见，我多次使用 GPT Builder 达到上限，打开一个新窗口，并使用普通 GPT-4，并且不受上限限制。
3.5版本实际上非常强大，而且完全没有上限。您无法使用 GPT 或 GPT-4 完成您能做的所有事情，但您可以用它做很多事情，而且速度很快。如果您批处理其他一些任务并与 3.5 进行一些交互，这可能是打发停机时间的有效方法。

这肯定会令人沮丧。
总的来说，我真的很喜欢 @former.token 和 @_j 使自定义 GPT 开发人员可以轻松请求更高的上限，或使 GPT 创建“无上限” ”。无论如何，这都是一个手动过程，并且确实是一个需要周期的开发人员工作流程。希望 OpenAI 能够注意到这一请求。]]></description>
      <guid>https://community.openai.com/t/request-cap-makes-impossible-to-build-gpts/575136#post_6</guid>
      <pubDate>Thu, 04 Jan 2024 14:42:03 GMT</pubDate>
    </item>
    <item>
      <title>帐户已停用 - 验证我的年龄</title>
      <link>https://community.openai.com/t/account-disabled-verify-my-age/572913#post_7</link>
      <description><![CDATA[大家好，我联系了我们的支持团队，要求创建一个包含更多详细信息的帮助中心。坚持住！编辑，我们有一篇文章： https:// /help.openai.com/en/articles/8411987-why-am-i-being-asked-to-verify-my-age]]></description>
      <guid>https://community.openai.com/t/account-disabled-verify-my-age/572913#post_7</guid>
      <pubDate>Thu, 04 Jan 2024 14:35:55 GMT</pubDate>
    </item>
    <item>
      <title>开发LLM应用程序的最大困难</title>
      <link>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=3#post_59</link>
      <description><![CDATA[很好的问题。我的是知识“新鲜度”。大规模索引当前知识是可以实现的。但“修剪”知识，只索引必要的元素，并保持新鲜（随着知识生成速度的加快）是我正在深入思考的问题。]]></description>
      <guid>https://community.openai.com/t/biggest-difficulty-in-developing-llm-apps/571180?page=3#post_59</guid>
      <pubDate>Thu, 04 Jan 2024 14:34:02 GMT</pubDate>
    </item>
    <item>
      <title>插件是通过 API 工作还是仅通过 ChatGPT 工作？</title>
      <link>https://community.openai.com/t/do-plugins-work-via-api-or-only-chatgpt/203701#post_14</link>
      <description><![CDATA[至此结束，插件现已演变成 GPT。目前还没有用于插件的 API，也没有 GPT，但这绝对是我们从想要更多控制的开发人员那里听到的反馈。]]></description>
      <guid>https://community.openai.com/t/do-plugins-work-via-api-or-only-chatgpt/203701#post_14</guid>
      <pubDate>Thu, 04 Jan 2024 14:32:36 GMT</pubDate>
    </item>
    <item>
      <title>您对 2024 年人工智能领域有何预测？</title>
      <link>https://community.openai.com/t/what-are-your-predictions-for-2024-in-ai/577161#post_12</link>
      <description><![CDATA[好话题。我把这三个扔进汤里。

即将发布一款类似 Alexa 的设备，将语音转变为 ChatGPT 的关键交互方式
随着“天生人工智能”初创公司大规模颠覆，裁员、合并以及从中型企业到大型企业的持续裁员、合并。
随着创新步伐不断加快，生成式 AI 带来更多乐趣。

老实说，我认为创新的步伐将会如此之快，以至于很难预测会发生什么。]]></description>
      <guid>https://community.openai.com/t/what-are-your-predictions-for-2024-in-ai/577161#post_12</guid>
      <pubDate>Thu, 04 Jan 2024 14:27:41 GMT</pubDate>
    </item>
    </channel>
</rss>