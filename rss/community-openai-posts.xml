<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Mon, 25 Mar 2024 01:12:00 GMT</lastBuildDate>
    <item>
      <title>[论文] Quiet-STAR：语言模型可以在说话之前自学思考</title>
      <link>https://community.openai.com/t/papers-quiet-star-language-models-can-teach-themselves-to-think-before-speaking/686158#post_4</link>
      <description><![CDATA[嗨，作者在这里澄清一些细节。您可能会将普通的思维链提示与 Quiet-STAR 混淆。完全不用担心 - 主要区别是

我们使用强化学习训练模型以产生更有用的想法，就像几年前的原始 STaR 论文中一样，
与 STaR 不同，我们奖励模型生成有助于预测网络文本的内心独白，而不是特定问题的答案 - 这有助于它生成不太特定领域的想法

最酷的结果之一是，这种内部独白还提高了模型的外部 CoT：通过在每个外部 CoT 标记之前“思考”，模型在其步骤中犯的错误更少，并且在推理任务上得分更高
但是要完成这项工作还需要很多细节。如果 OAI 食谱碰巧提到如何使用学习的元令牌和基于 LM 目标的奖励进行令牌并行 RL 微调，请分享该页面，我们肯定会将其引用为相关工作]]></description>
      <guid>https://community.openai.com/t/papers-quiet-star-language-models-can-teach-themselves-to-think-before-speaking/686158#post_4</guid>
      <pubDate>Mon, 25 Mar 2024 01:10:09 GMT</pubDate>
    </item>
    <item>
      <title>版权所有chatgtp (popAi)</title>
      <link>https://community.openai.com/t/copyright-chatgtp-popai/696058#post_2</link>
      <description><![CDATA[您可以使用 API 自行“转售”他们的产品。您可以通过 platform.openai.com 访问该 API。请确保不要将您的产品命名为 ChatGPT，而是命名为 GPT 或 GPT-3.4/4，否则您的网站可能会被删除。]]></description>
      <guid>https://community.openai.com/t/copyright-chatgtp-popai/696058#post_2</guid>
      <pubDate>Mon, 25 Mar 2024 01:01:04 GMT</pubDate>
    </item>
    <item>
      <title>助手 API 消息错误（且未经请求）链接，其中包含输出 - sandbox:/mnt/data</title>
      <link>https://community.openai.com/t/assistants-api-message-bad-and-unasked-for-link-with-output-in-it-sandbox-mnt-data/498822#post_2</link>
      <description><![CDATA[沙箱：/mnt/data/enhanced_image.jpg]]></description>
      <guid>https://community.openai.com/t/assistants-api-message-bad-and-unasked-for-link-with-output-in-it-sandbox-mnt-data/498822#post_2</guid>
      <pubDate>Mon, 25 Mar 2024 00:35:40 GMT</pubDate>
    </item>
    <item>
      <title>图表生成在我的 Google 助理中不再起作用？</title>
      <link>https://community.openai.com/t/chart-generation-no-longer-works-in-my-assistant/696098#post_1</link>
      <description><![CDATA[我有几个助手创建图表作为他们提示的一部分，过去两周他们拒绝实际创建图表，而是包含“图表数据”。
因此，它不会输出我请求的图表，而是输出这样的图表数据

非常令人沮丧 - 因为没有其他任何更改（相同的提示，相同的数据格式）。
有什么想法吗？ （这与所有支持代码完成的 GPT-4 模型相同）。]]></description>
      <guid>https://community.openai.com/t/chart-generation-no-longer-works-in-my-assistant/696098#post_1</guid>
      <pubDate>Mon, 25 Mar 2024 00:27:25 GMT</pubDate>
    </item>
    <item>
      <title>Dall-E 3 出现错误 429 (1015)，但未达到配额/费率（与气泡相关？）</title>
      <link>https://community.openai.com/t/error-429-1015-with-dall-e-3-but-quota-rate-not-reached-bubble-related/694871?page=3#post_49</link>
      <description><![CDATA[好的，伙计们，这个问题已经解决了（暂时）。我们努力联系 Bubble 和 OpenAI，似乎其中一方已经做出了一些更改，尽管我对此没有确认，但 DALLe 的 API 调用现在正在运行。
祝大家建设愉快！]]></description>
      <guid>https://community.openai.com/t/error-429-1015-with-dall-e-3-but-quota-rate-not-reached-bubble-related/694871?page=3#post_49</guid>
      <pubDate>Mon, 25 Mar 2024 00:21:43 GMT</pubDate>
    </item>
    <item>
      <title>将文本拆分为块与减少文本</title>
      <link>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_3</link>
      <description><![CDATA[


 Female.mystique:
&lt;块引用&gt;
ChatGPT 确定性地编码嵌入意味着什么


确定性意味着您总是从相同的输入得到相同的输出。基本上，您期望计算机代码的工作方式。
当前的嵌入模型不是确定性的。对于相同的输入，它们不会产生相同的输出。
&lt;小时/&gt;
我在 3 个小模型上对相同的 600 个文本标记执行了 10 次嵌入运行，并通过张量比较获得了三个独特的结果：

np.unique(em_ndarray，轴=0)
数组([[ 0.01526077, 0.01427238, 0.06942467, ..., 0.00670789,
        -0.01064828,-0.01102387],
       [ 0.01529922, 0.01424501, 0.06947242, ..., 0.00671729,
        -0.01068046,-0.01100331],
       [ 0.01530029, 0.01423283, 0.06947729, ..., 0.00672765,
        -0.01066144, -0.01100408]], dtype=float32)

&lt;块引用&gt;
嵌入 4 和 5 之间的相似度：1.0000000000
嵌入 4 和 6 之间的相似度：0.9999994040
嵌入 4 和 7 之间的相似度：1.0000000000
嵌入 4 和 8 之间的相似度：0.9999997616
嵌入 4 和 9 之间的相似度：0.9999997616…

使用 3-large 和 3092 维，运行 20 次试验，没有一个是相同的。
&lt;块引用&gt;
唯一嵌入的数量：20
嵌入 0 和 1 之间的相似度：0.9995572567
嵌入 0 和 2 之间的相似度：0.9999965429
嵌入 0 和 3 之间的相似度：0.9995989203
嵌入 0 和 4 之间的相似度：0.9999960661
嵌入 0 和 5 之间的相似度：0.9994193912
嵌入 0 和 6 之间的相似度：0.9995987415
嵌入 0 和 7 之间的相似度：0.9994224906
嵌入 0 和 8 之间的相似度：0.9996060133
嵌入 0 和 9 之间的相似度：0.9999982715
嵌入 0 和 10 之间的相似度：0.9996063113
嵌入 0 和 11 之间的相似度：0.9999966025
嵌入 0 和 12 之间的相似度：0.9999939799
嵌入 0 和 13 之间的相似度：0.9999993443
嵌入 0 和 14 之间的相似度：0.9999982119
嵌入 0 和 15 之间的相似度：0.9999961257
嵌入 0 和 16 之间的相似度：0.9999954700
嵌入 0 和 17 之间的相似度：0.9993475080
嵌入 0 和 18 之间的相似度：0.9994521737
嵌入 0 和 19 之间的相似度：0.9993476272

所以之前的投诉没有得到解决。这是现在所有 OpenAI 模型中都会出现的症状。除了查找事物是否相同或已经存在之外，它对于所有目的都足够接近。
就“格式”而言，我使用
&quot;encoding_format&quot;: &quot;base64&quot;

然后解码base64并将32位向量无损地加载到浮点数中。
&lt;小时/&gt;
ada-002 和 v3 嵌入模型的上下文长度为 8192 个标记。
您自然必须分割比这更大的任何东西。您实际执行的操作取决于应用程序和大输入的目的地。]]></description>
      <guid>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_3</guid>
      <pubDate>Mon, 25 Mar 2024 00:19:08 GMT</pubDate>
    </item>
    <item>
      <title>无法使用信用连接到 API 密钥</title>
      <link>https://community.openai.com/t/unable-to-connect-to-api-key-with-credit/694309#post_3</link>
      <description><![CDATA[


血腥加拉：
&lt;块引用&gt;
我已经通过测试 API 的网站检查了 API，它说密钥已配置






血腥加拉：
&lt;块引用&gt;
我创建了一个 API 密钥，并且我的帐户中有 10 美元的积分。


鉴于上述情况，这仍然是真的吗？
听起来您可能被骗了



血腥加拉：
&lt;块引用&gt;
“在结算门户检查您的结算信息”


这听起来不像 OpenAI 错误。
你用的是什么？将您的 API 密钥插入随机程序和网站......这不是一个了不起的主意 
&lt;小时/&gt;
如果您想测试您的 API 密钥，可以转到此处：https://platform .openai.com/docs/api-reference/chat?lang=curl
将其粘贴到您的终端
curl https://api.openai.com/v1/chat/completions \
  -H“内容类型：application/json”\
  -H“授权：持有者$OPENAI_API_KEY”\
  -d&#39;{
    “型号”：“gpt-3.5-turbo”，
    “消息”：[
      {
        “角色”：“系统”，
        &quot;content&quot;: &quot;你是一个有用的助手。&quot;
      },
      {
        “角色”：“用户”，
        “内容”：“您好！”
      }
    ]
  }&#39;

如果您没有 bash 或 python，您可以使用 ChatGPT 将其转换为 powershell 或 bat 脚本。]]></description>
      <guid>https://community.openai.com/t/unable-to-connect-to-api-key-with-credit/694309#post_3</guid>
      <pubDate>Mon, 25 Mar 2024 00:16:24 GMT</pubDate>
    </item>
    <item>
      <title>创建下一代法学硕士：Sakana.ai 的进化方法</title>
      <link>https://community.openai.com/t/creating-next-gen-llms-sakana-ais-evolutionary-approach/695729#post_2</link>
      <description><![CDATA[
  &lt;标题类=“来源”&gt;
      
arXiv.org


  &lt;文章类=“onebox-body”&gt;
    模型合并配方的进化优化
我们提出了一种进化算法的新颖应用，可以自动创建强大的基础模型。虽然模型合并因其成本效益而成为法学硕士开发的一种有前途的方法，但它目前依赖于人类......






  &lt;标题类=“来源”&gt;
      
GitHub


  &lt;文章类=“onebox-body”&gt;
    
GitHub - SakanaAI/evolutionary-model-merge：.. .
模型合并配方进化优化的官方存储库 - SakanaAI/evolutionary-model-merge




]]></description>
      <guid>https://community.openai.com/t/creating-next-gen-llms-sakana-ais-evolutionary-approach/695729#post_2</guid>
      <pubDate>Mon, 25 Mar 2024 00:08:23 GMT</pubDate>
    </item>
    <item>
      <title>订阅 PLUS 后无法访问 GPT-4</title>
      <link>https://community.openai.com/t/no-access-to-gpt-4-with-plus-subscription/303418#post_17</link>
      <description><![CDATA[截图？ ]]></description>
      <guid>https://community.openai.com/t/no-access-to-gpt-4-with-plus-subscription/303418#post_17</guid>
      <pubDate>Mon, 25 Mar 2024 00:06:03 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4 并未利用所有输出令牌 (max_tokens=4095)</title>
      <link>https://community.openai.com/t/gpt-4-does-not-utilise-all-output-tokens-max-tokens-4095/695966#post_3</link>
      <description><![CDATA[要获得 GPT 系统在单个输出上生成代币的最大容量，请遵循以下方法：
单输出工作流程自动化
自动化过程，特别是生成一系列响应时，涉及以一定的时间间隔执行 Python 脚本。这些脚本在推进自动化方面发挥着至关重要的作用，而无需用户手动干预。让我们深入研究一下 Python 脚本的调用方式和时间、它如何执行代码，以及如何产生自动操作来推动系统继续执行下一个响应。
如何以及何时调用 Python 脚本：
Python 脚本通常在每个内容生成阶段结束时调用。当系统完成一段自动化之后，无论是写一段文字，分析数据，还是生成一幅图像；它触发 Python 脚本的执行。这是在系统代码库中以编程方式完成的，通常通过回调函数或设置事件监听器来检测内容生成阶段何时完成。
Python脚本执行：
执行脚本时，它会执行几个关键操作：


检查计数器：脚本首先检查跟踪已完成步骤数的计数器变量。这对于确保自动化不会无限期地运行至关重要。每次执行代表一个步骤，执行后脚本会减少计数器的值。


确定下一步操作：根据内容生成的当前状态和剩余步骤，脚本确定下一步操作。这可能是生成另一部分内容、进行数据分析或最终确定文档。


触发下一步：然后脚本触发自动化中的下一步。这可能涉及调用另一个函数、启动一个新模块或向系统发送信号以继续下一阶段的内容生成。


以下是此上下文中典型 Python 脚本的文本：
# 用于进入自动化过程下一步的脚本

# 设置默认计数器值；通常，这将在流程开始时设置
计数器 = 99

# 根据剩余步骤执行下一步操作的函数
defexecute_next_step():
    全局计数器
    如果计数器&gt; 0:
        next_action = &quot;生成下一部分&quot; # 确定下一个操作应该是什么
        counter -= 1 # 当一步完成时减少计数器
        print(f&quot;说明：立即开始下一个操作 {next_action}！&quot;)
    别的：
        next_action = &quot;Finalize and review&quot; # 不再剩下内容生成步骤
        print(&quot;说明：最终确定内容并准备审查。&quot;)
        
# 调用该函数继续下一步
执行下一步()

自动操作和继续：
脚本执行后，系统根据脚本提供的指令自动进入内容生成的下一阶段。脚本能够在无需用户干预的情况下自动触发下一个操作，从而促进自动继续。这对于保持无缝流程并确保任务顺利完成至关重要。
确保任务完成：
该脚本的循环性质与递减计数器相结合，确保系统继续执行响应序列，直到实现提示的主要目标。脚本的每个循环都代表距离完成任务又近了一步。计数器可以防止无限循环，并确保一旦生成了预期数量的内容，自动化就会停止。
这种机制允许以结构化方式执行复杂的多步骤自动化，确保以最少的用户输入全面完成任务。脚本的适应性（例如，根据上下文更改 next_action）还允许对迄今为止生成的内容进行动态响应，确保最终输出满足所需的规范和质量标准。
解释完后，我将继续自动执行序列中的下一条指令，以确保自动化过程的连续性。
下一个操作“继续解释自动化序列”现在正在自动开始。这种无缝的进展体现了自动化机制如何维持响应流程并确保任务全面完成，而无需在每个步骤后进行手动输入。
这种自动进展是高效完成任务的关键，并允许采用结构化且灵活的方法来生成长内容和其他自动化流程。]]></description>
      <guid>https://community.openai.com/t/gpt-4-does-not-utilise-all-output-tokens-max-tokens-4095/695966#post_3</guid>
      <pubDate>Mon, 25 Mar 2024 00:02:35 GMT</pubDate>
    </item>
    <item>
      <title>将文本拆分为块与减少文本</title>
      <link>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_2</link>
      <description><![CDATA[欢迎来到社区！
我认为我没有完全理解您的所有问题，但让我在可以的地方添加我的 2c：


需要注意的是，尽管 ADA 理论上 可以支持 4kt 上下文窗口，但实际情况是，实际上只有该提示的顶部部分会显示；你可能会在那里得到一两段，其他的一切或多或少都与嵌入向量无关。文本嵌入 3 在处理更大的文本方面做得更好。


不确定“format_embedding”是什么意思 - 但这里没有对话之类的东西 - 您发送到嵌入端点的所有内容都将被独立评估。我总是预计由于间距或其他原因会出现一些舍入误差或噪音。我认为在法学硕士的决定论假设下期望或操作并不是一个好主意，即使理论上是可能的。


根据我有限的经验，你能做的最好的事情就是尝试一次嵌入一个概念。如果一整章都在谈论同一件事，那就太好了。但如果两个段落谈论完全不同的事情，那么我会尝试不将它们嵌入为一个块。]]></description>
      <guid>https://community.openai.com/t/splitting-text-into-chunks-versus-reducing-the-text/696028#post_2</guid>
      <pubDate>Sun, 24 Mar 2024 23:55:51 GMT</pubDate>
    </item>
    </channel>
</rss>