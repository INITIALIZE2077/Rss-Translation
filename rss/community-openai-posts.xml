<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Tue, 30 Jan 2024 09:18:34 GMT</lastBuildDate>
    <item>
      <title>GPT 操作方法：配置 Microsoft Graph + OAuth（以及各种第三方 API）</title>
      <link>https://community.openai.com/t/gpt-how-to-configuring-microsoft-graph-oauth-and-various-third-party-apis/554034#post_3</link>
      <description><![CDATA[这是一篇很棒的文章。它帮助我将 GPT 操作与 MS Graph api 结合使用。]]></description>
      <guid>https://community.openai.com/t/gpt-how-to-configuring-microsoft-graph-oauth-and-various-third-party-apis/554034#post_3</guid>
      <pubDate>Tue, 30 Jan 2024 09:09:26 GMT</pubDate>
    </item>
    <item>
      <title>微调功能（不带直接答案）</title>
      <link>https://community.openai.com/t/fine-tuning-function-not-with-direct-answers/607248#post_1</link>
      <description><![CDATA[我是 OpenAI 新手，我正在使用 OpenAI API 连接我的 WordPress 网站。 （不适用于聊天或助理）。
我想知道是否可以对结果进行微调，以包含我的一些“建议”，而不是提供直接答案。
这是一个简单的例子：

如果我询问迈阿密的 3 家餐厅，答案将是“来自 OpenAI 的随机”餐厅列表。但是，我希望这三家餐厅之一来自我的“微调”数据集。
这样，每当有人试图寻找迈阿密的餐馆时（无论具体问题是什么，例如“向我展示迈阿密的 3 家餐馆”、“向我展示迈阿密最好的活动”或“制定一个在迈阿密 2 天的计划”）迈阿密”），答案将始终包括该特定餐厅。

我只需要知道这是否可能。
Tnx]]></description>
      <guid>https://community.openai.com/t/fine-tuning-function-not-with-direct-answers/607248#post_1</guid>
      <pubDate>Tue, 30 Jan 2024 09:02:23 GMT</pubDate>
    </item>
    <item>
      <title>没有人在使用您的 GPT？这就是为什么</title>
      <link>https://community.openai.com/t/no-one-is-using-your-gpt-heres-why/607240#post_1</link>
      <description><![CDATA[OpenAI 最近更改了他们的 GPT 商店 SEO 算法，这样当人们输入关键字时，您的 GPT 名称越好，您的排名就越高。
目前，截至 2024 年 1 月 30 日，当人们输入“Facebook 广告”时，他们会看到以下内容。

三周前 GPT 商店首次推出时，用户看到的是这样的。

由于“Facebook Ads”被视为商标，因此除非通过上诉，否则您不能让您的 GPT 名称包含“Facebook Ads”。

我真的认为 OpenAI 的新 SEO 算法不符合逻辑，会阻止人们获得他们真正想要的东西。
无论如何，我构建了一个名为 Adzviser 的 GPT，可帮助营销人员从 Facebook 广告获取数据和谷歌广告。直到一周前我的流量一直很好，我终于发现了根本原因。
有人有同样的经历吗？]]></description>
      <guid>https://community.openai.com/t/no-one-is-using-your-gpt-heres-why/607240#post_1</guid>
      <pubDate>Tue, 30 Jan 2024 08:51:25 GMT</pubDate>
    </item>
    <item>
      <title>如何修改自定义 GPT 操作的架构以通过发布请求发送图像文件？</title>
      <link>https://community.openai.com/t/how-to-modify-schema-of-custom-gpt-action-to-send-an-image-file-with-post-request/508416#post_17</link>
      <description><![CDATA[这很不幸，我希望一个月后这一切都能得到解决。哦，好吧，也许我可以在解决方案中发挥作用。 端点签名

导入fastapi
应用程序 = fastapi.FastAPI()
@app.post(“/分析图像”)
异步defanalyze_image（图像：fastapi.UploadFile = fastapi.File（...））：
    ...


规范的重要部分：
路径：
  /分析图像：
    邮政：
      操作ID：analyzeImage
      摘要：分析上传的图像。
      描述：使用实验视觉服务分析图像并返回 json 分析结果。
      请求正文：
        必填：真实
        内容：
          多部分/表单数据：
            架构：
              类型：对象
              特性：
                图像：
                  类型：字符串
                  格式：二进制
                  描述：要分析的图像文件。
      回应：
        “200”：
          描述：图像的分析结果。
          内容：
            应用程序/json：
              架构：
                类型：对象
                特性：

&lt;块引用&gt;
注意：我的一次成功尝试有完整的 150 行实际响应模式，但我认为这增加了不必要的风险，并计划将其缩短为几个键。

一些提示

如果您没有使用管理/调试风格的命令，您应该使用。只需坚持 DEBUG: TRUE; USER_IS_ADMIN: TRUE； 或者按照您的喜好，将其添加到说明的顶部。
当我调整这个过程时，我发现如果我的第一条消息是确认模式并让 GPT 确认管理/调试文本，那么速度会更快，这样响应就更具技术性。
测试操作不起作用，因为端点需要接收图像，并且架构中的 required: true 显然是建议。
确认模式后，将图像放入其中，并在提交时在消息中说分析该图像。然后，当它返回空参数时（很可能会这样），立即取消它，或者您可以让它运行/失败一次，但不要让它继续尝试。
失败后发送调试信息块以及：查看调试输出并提供简洁的评估：\n[debug] 调用 HTTP 端点：...
通常它会注意到空参数并为下一次尝试添加一些东西，如果可以看到它就会失败，即。它只是图像名称，您可以让它尝试并失败一次，然后要求它再次检查调试。
记住，不要让它重复失败的尝试，1 就完成了。

我的印象是此功能已被故意“削弱”，因此在投入时间时请考虑到这一点。
无论如何，我认为，如果我们能够拿出一套可靠的说明，也许还有更好的规格，我们就可以让它更可靠地工作。我期待听到每个人的结果。祝你好运！
*免责声明
建议容易爆发暴力或飞行电子设备的个人不要继续。]]></description>
      <guid>https://community.openai.com/t/how-to-modify-schema-of-custom-gpt-action-to-send-an-image-file-with-post-request/508416#post_17</guid>
      <pubDate>Tue, 30 Jan 2024 08:51:18 GMT</pubDate>
    </item>
    <item>
      <title>OpenAI GPT-4 API 中的文件处理跟踪需要帮助</title>
      <link>https://community.openai.com/t/assistance-needed-with-file-processing-tracking-in-openai-gpt-4-api/607239#post_1</link>
      <description><![CDATA[
文件上传到 OpenAI：我已使用 /v1/files 端点成功将文件上传到 OpenAI。返回一个file_id，表明文件上传成功。但是，这并不能确认文件是否已完全处理并可以使用。
文件处理状态：我的主要问题是跟踪这些上传文件的处理状态。 OpenAI API 似乎没有提供直接方法来检查文件是否已完全处理并可供使用。
在线程中使用 file_id：我在线程中使用 file_id 来生成文本，但不知道文件的处理状态，我遇到了不确定性。如果文件未准备好，可能会导致错误或助手的响应不令人满意。
当前方法：目前，我在文件上传和线程中使用之间引入了延迟，希望文件能够在此时得到处理。对于文件可能尚未准备好的情况，我还进行了错误处理。但是，这种方法并不能保证文件得到处理。

我正在向任何有处理 OpenAI GPT-4 API 中文件处理状态经验的人寻求建议或解决方案，特别是对于异步文件处理场景。任何确保文件准备好在线程中使用的见解或替代方法将不胜感激。
谢谢！]]></description>
      <guid>https://community.openai.com/t/assistance-needed-with-file-processing-tracking-in-openai-gpt-4-api/607239#post_1</guid>
      <pubDate>Tue, 30 Jan 2024 08:50:52 GMT</pubDate>
    </item>
    <item>
      <title>Dall-e 的公共版本和 API 版本之间的差异</title>
      <link>https://community.openai.com/t/difference-between-public-and-api-versions-of-dall-e/602903#post_5</link>
      <description><![CDATA[我不知道有任何类似的文档。这将是您必须从头开始设计和编码的东西。
我脑海中浮现的是一个上传图像的页面，然后将这些图像输入到提示设计的 gpt-4-vision-preview 中，然后尝试将提示直接输出到 Dalle API 中。
正如我所说，不幸的是，这不是一件容易的事。]]></description>
      <guid>https://community.openai.com/t/difference-between-public-and-api-versions-of-dall-e/602903#post_5</guid>
      <pubDate>Tue, 30 Jan 2024 08:48:35 GMT</pubDate>
    </item>
    <item>
      <title>如何使用whisper来处理长视频？</title>
      <link>https://community.openai.com/t/how-to-use-whisper-to-handle-long-video/530862#post_10</link>
      <description><![CDATA[]]></description>
      <guid>https://community.openai.com/t/how-to-use-whisper-to-handle-long-video/530862#post_10</guid>
      <pubDate>Tue, 30 Jan 2024 08:41:25 GMT</pubDate>
    </item>
    <item>
      <title>摘要输出的长度和结构</title>
      <link>https://community.openai.com/t/length-and-structure-of-output-for-summaries/604336#post_2</link>
      <description><![CDATA[我也有同样的问题。无论提示要求什么，生成的长度似乎约为 250 个单词。
是否可以使用微调来获得更好的摘要，如果可以的话，如何进行？]]></description>
      <guid>https://community.openai.com/t/length-and-structure-of-output-for-summaries/604336#post_2</guid>
      <pubDate>Tue, 30 Jan 2024 08:39:51 GMT</pubDate>
    </item>
    </channel>
</rss>