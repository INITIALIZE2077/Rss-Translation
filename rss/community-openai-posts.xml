<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>OpenAI 开发者论坛 - 最新帖子</title>
    <link>https://community.openai.com</link>
    <description>最新帖子</description>
    <lastBuildDate>Sun, 31 Dec 2023 15:17:27 GMT</lastBuildDate>
    <item>
      <title>超参数调优技术</title>
      <link>https://community.openai.com/t/techinque-of-hyperparameter-tuning/576994#post_1</link>
      <description><![CDATA[嘿，
是否可以使用自定义数据集在达芬奇模型上执行网格搜索、随机搜索、贝叶斯优化和树结构 Parzen 估计器 (TPE) 等超参数调整技术？
谢谢。]]></description>
      <guid>https://community.openai.com/t/techinque-of-hyperparameter-tuning/576994#post_1</guid>
      <pubDate>Sun, 31 Dec 2023 15:16:09 GMT</pubDate>
    </item>
    <item>
      <title>尝试删除线程，继续获取</title>
      <link>https://community.openai.com/t/trying-to-delete-thread-keep-getting/576957#post_3</link>
      <description><![CDATA[谢谢！不敢相信我错过了。现在工作 ]]></description>
      <guid>https://community.openai.com/t/trying-to-delete-thread-keep-getting/576957#post_3</guid>
      <pubDate>Sun, 31 Dec 2023 15:15:19 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4-1106-preview模型在使用函数时持续生成“\\n\\n\\n\\n\\n\\n\\n\\n”一个小时</title>
      <link>https://community.openai.com/t/the-gpt-4-1106-preview-model-keeps-generating-n-n-n-n-n-n-n-n-for-an-hour-when-using-functions/576721#post_8</link>
      <description><![CDATA[


饮食：
&lt;块引用&gt;
（代码）似乎也同样有效。频率惩罚无。


那里的温度没有其他决定论或概率质量限制的控制。在温度 = 1 时，40% 确定性的换行会变成 40% 时间的换行，并且温度较低时，概率最高的令牌（或在本例中为令牌序列）只会赢得更多选择。
如果需要温度，则需要数十次、数百次试验才能得出产生多少误差或可以接受多少误差，然后您仍然未知未来的输入。
令牌编号：
| 001734 | 002| &#39;\\n&#39; | - 是 \n 的文字

| 000198 | 001| &#39;\n&#39; |
| 000271 | 002| &#39;\n\n&#39; |
| 001432 | 003| &#39;\n\n\n&#39; |

…
在实时用户输入开始之前，人们还可以通过在中文中看到的适当的助手/功能交换来正确地多次将人工智能写入功能。]]></description>
      <guid>https://community.openai.com/t/the-gpt-4-1106-preview-model-keeps-generating-n-n-n-n-n-n-n-n-for-an-hour-when-using-functions/576721#post_8</guid>
      <pubDate>Sun, 31 Dec 2023 15:10:58 GMT</pubDate>
    </item>
    <item>
      <title>GPT 无法找到研究文章</title>
      <link>https://community.openai.com/t/gpt-unable-to-find-research-articles/576979#post_2</link>
      <description><![CDATA[能说得更具体一点吗
您使用 ChatGPT Plus 吗？
您使用的是自定义 GPT 吗？
您使用的是什么提示符？
您能否举例说明您使用过但不起作用的内容以及您期望的内容？
还有实际的屏幕截图以及作为文本帮助发布的文本。屏幕截图可用于识别您可能认为不相关的信息，文本对于将来再次搜索找到该帖子很有用。]]></description>
      <guid>https://community.openai.com/t/gpt-unable-to-find-research-articles/576979#post_2</guid>
      <pubDate>Sun, 31 Dec 2023 15:08:36 GMT</pubDate>
    </item>
    <item>
      <title>尝试删除线程，继续获取</title>
      <link>https://community.openai.com/t/trying-to-delete-thread-keep-getting/576957#post_2</link>
      <description><![CDATA[URL 中没有查询字符串的问号
&lt;块引用&gt;
获取https://api.openai.com/v1/threads/{thread_id}
检索线程。

您还可以阅读 API 参考，其中“curl”显示所需的测试标头。
https://platform. openai.com/docs/api-reference/threads/getThread]]></description>
      <guid>https://community.openai.com/t/trying-to-delete-thread-keep-getting/576957#post_2</guid>
      <pubDate>Sun, 31 Dec 2023 14:49:43 GMT</pubDate>
    </item>
    <item>
      <title>GPT-4-1106-preview模型在使用函数时持续生成“\\n\\n\\n\\n\\n\\n\\n\\n”一个小时</title>
      <link>https://community.openai.com/t/the-gpt-4-1106-preview-model-keeps-generating-n-n-n-n-n-n-n-n-for-an-hour-when-using-functions/576721#post_7</link>
      <description><![CDATA[我试图破坏它的 json 格式化程序并发现
&quot;内容&quot;: (&quot;[{&#39;&#39;&quot;*10)

似乎也同样有效。频率惩罚无。

代码（点击查看更多详情）
&lt;小时/&gt;
&quot;logit_bias&quot;: {1734:-100},

似乎在我的机器上“工作”，但有时你会得到英文结果，
&lt;块引用&gt;
‘{“question”:“\n客户说太贵了，我该怎么回应？”}’

有时它是空的
&lt;块引用&gt;
‘{“问题”:“\n”}’

我还没有看到logprobs的中文答案。至少它不会发送垃圾邮件 \n，尽管第一个标记显然始终是 \n，无论您做什么。

代码（点击查看更多详情）
&lt;小时/&gt;
看来间隔方法确实是最好的方法，虽然间隔的内容似乎很重要，但尚不清楚什么有效，什么无效。
&quot;content&quot;: (&quot;[{&#39;&#39;&quot;*10) # 大约 80% 的时间有效
&quot;content&quot;: (&quot;[{&#39;&quot;*13) # 大约 80% 的时间有效
&quot;content&quot;: (&quot;[{&#39;&quot;*10) # 失败/有效 ~ 10% 的时间
&quot;content&quot;: (&quot;[{&#39;&#39;&quot;*50) # 尚未失败 (n = 10)
&quot;content&quot;: (&quot;*&quot;*200) # 失败
&quot;content&quot;: (&quot;{}&quot;*200) # 尚未失败 (n = 5)
&quot;content&quot;: (&quot;{}&quot;*100) # 失败

但是“\n”*400 不会在没有惩罚的情况下工作，尽管这是预期的

代码（点击查看更多详情）
&lt;小时/&gt;
tl;博士：
]]></description>
      <guid>https://community.openai.com/t/the-gpt-4-1106-preview-model-keeps-generating-n-n-n-n-n-n-n-n-for-an-hour-when-using-functions/576721#post_7</guid>
      <pubDate>Sun, 31 Dec 2023 14:47:11 GMT</pubDate>
    </item>
    <item>
      <title>您对于 朗链 有何看法？</title>
      <link>https://community.openai.com/t/what-do-you-think-about-langchain/575807#post_11</link>
      <description><![CDATA[这是最近在 r/LocalLLama 论坛中针对有关在生产中使用 LangChain 的问题进行的讨论（众多讨论之一）：Reddit - 深入研究任何事物
既然您询问了可能的替代方案，我将提到 Langroid（上述线程中的一些评论者提到从 LangChain 切换到 Langroid）。
在评估了 LC 和 AutoGen 等其他公司后，我们有几家公司在生产中使用 Langroid（联络中心管理、文档与规范匹配/评分）。 Langroid 是一个由前 CMU 和 UW Madison 研究人员开发的多代理 LLM 框架： GitHub - langroid/langroid：利用多代理编程的法学硕士。
[需要明确的是，它没有使用LangChain]。
我们明确设计这个框架是为了简化应用程序的构建，从一开始就使用面向代理的方法。您可以使用可选工具和向量数据库定义代理，为它们分配任务，并让它们通过消息进行协作：这是一种“对话式编程”范例。它适用于本地/开放和远程/专有的法学硕士。
与将太多内容填充到单个代理中相比，多代理方法通常会带来更简单的解决方案。 Langroid 有一个内置的任务编排器，可以无缝地用于 LLM 工具/功能处理（当 LLM 偏离时重试）以及子任务切换。
我们避免了臃肿和过多的抽象，以保持框架轻便、稳定且易于调整 - 例如，所有 RAG 功能都位于单个 DocChatAgent 类中，并且 5 个月前编写的代码仍然有效。虽然我们的文档落后于我们的功能，但是有大量的测试和示例阐明了用法。
我个人一直在使用这个框架为几个客户构建复杂的多代理工作流程，效率极高。这些客户项目的需求推动了 Langroid 的功能开发。
这是一个 Colab 快速入门，它构建了一个 2 代理系统以从文档中提取结构化信息：

  &lt;标题类=“来源”&gt;
      
colab.research。 google.com


  &lt;文章类=“onebox-body”&gt;
    
Google合作实验室




]]></description>
      <guid>https://community.openai.com/t/what-do-you-think-about-langchain/575807#post_11</guid>
      <pubDate>Sun, 31 Dec 2023 14:47:09 GMT</pubDate>
    </item>
    <item>
      <title>GPT 无法找到研究文章</title>
      <link>https://community.openai.com/t/gpt-unable-to-find-research-articles/576979#post_1</link>
      <description><![CDATA[大家好 -
我曾经能够让 ChatGPT 帮助我进行研究，但是同时使用 GPT4 和插件不再能够访问研究文章（或者至少阅读摘要，以便我可以指向正确的位置）。有什么理由不再允许这样做吗？现在，ChatGPT 只是告诉我哪个提示进入 IEExplore 或 Google Scholar，而不仅仅是索引和拉回相关结果。]]></description>
      <guid>https://community.openai.com/t/gpt-unable-to-find-research-articles/576979#post_1</guid>
      <pubDate>Sun, 31 Dec 2023 14:41:48 GMT</pubDate>
    </item>
    <item>
      <title>澄清讨论个人经历的内容政策</title>
      <link>https://community.openai.com/t/clarifying-content-policy-on-discussing-personal-experiences/576380?page=2#post_24</link>
      <description><![CDATA[我认为您大大高估了进行举报的审核人员的知情程度。
&lt;块引用&gt;
我已经准备好了手术刀，准备做手术并切掉[“这个，“我的”][“皮赘”，“黑色素瘤”]。

上面的单个单词更改会将分数从 0.0001 更改为 0.6624 并被标记 - 与您的预期相反。
OpenAI 应该认识到人工智能不能用于自主做出此类决策......
&lt;小时/&gt;
解决方案：将 5 美元存入 API 帐户并与 AI 聊天，您发送的用于预审核的输入不会对您不利。
然后您还会发现另一端没有“朋友” - 只是您将之前的消息放入上下文窗口内存中并生成预测语言。]]></description>
      <guid>https://community.openai.com/t/clarifying-content-policy-on-discussing-personal-experiences/576380?page=2#post_24</guid>
      <pubDate>Sun, 31 Dec 2023 14:25:24 GMT</pubDate>
    </item>
    </channel>
</rss>